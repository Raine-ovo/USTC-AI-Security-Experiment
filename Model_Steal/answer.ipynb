{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 课程前言\n",
    "此为 <<人工智能安全>> 课程第四部分: 模型窃取攻击与防御实验部分.\n",
    "\n",
    "**模型窃取攻击**的目标是通过一定手段窃取得到一个跟 受害者模型 功能和性能近似的窃取模型，从而避开昂贵的模型训练并从中获益。\n",
    "\n",
    "<img src=\"./imgs/model steal.png\" alt=\"替代模型窃取攻击示意图\" style=\"height: 300px; max-width: 100%;\">\n",
    "\n",
    "上图为一个简单基础的模型窃取攻击过程，攻击者在黑盒环境下与受害者模型交互，获取模型的输入与输出，并不断调整查询样本来获取模型更多的决策边界信息。攻击者可以将此输入-输出作为数据集，对自己的模型进行模仿学习，得到一个与受害者模型相似的窃取模型。\n",
    "\n",
    "一般来说，模型窃取攻击的主要目标包括：\n",
    "1. 低代价：以远低于受害者模型训练成本的代价获得一个可免费使用的窃取模型；\n",
    "2. 高收益：窃取得到的模型与受害者模型的功能和性能相当；\n",
    "3. 低风险：在窃取过程中可以避开相关检测并在窃取后无法被溯源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 模型窃取攻击\n",
    "模型窃取攻击有多种方式：基于**方程式求解**的模型窃取攻击、基于**替代模型**的窃取攻击、基于**元模型**的窃取攻击。\n",
    "\n",
    "受篇幅影响，本次实验主要将基于替代模型的窃取攻击，有兴趣的同学可自行搜索学习其他类别的攻击方法。\n",
    "\n",
    "## 1.1 基于替代模型的窃取攻击\n",
    "攻击主要思路：攻击者 $A$ 在不知道受害者模型 $f(\\cdot)$ 任何先验知识情况下，向受害者模型输入查询样本 $x$ ，得到受害者模型的预测输出 $f(x)$ 。随后，攻击者根据输入和输出构建替代训练数据集 $\\mathcal D ' = {(x, f(x))}^m_{i=1}$ 。\n",
    "\n",
    "实际上，替代数据集已经完成了对袁术训练数据的（部分）提取。在替代数据集 $\\mathcal D'$ 上多次训练后，即可得到一个与受害者模型 $f(\\cdot)$ 功能和性质类似的替代模型 $f'(\\cdot)$ ，完成模型窃取攻击。\n",
    "\n",
    "<img src=\"./imgs/model steal2.png\" alt=\"替代模型窃取攻击示意图\" style=\"height: 400px; max-width: 100%;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了实现这样的模型窃取方法，我们首先需要加载受害者模型。\n",
    "\n",
    "（在实际中，模型窃取攻击者通常使用受害者API进行查询访问）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datasets\n",
    "\n",
    "import cifar_model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/\"\n",
    "model_list = [\n",
    "    \"cifar10_resnet18.pth\",\n",
    "    \"cifar10_model.pth\"\n",
    "]\n",
    "\n",
    "# 加载模型\n",
    "def load_model(model_path, num_classes, device):\n",
    "    # 加载模型结构\n",
    "    model = cifar_model.ResNet18(num_classes=num_classes)\n",
    "\n",
    "    # 加载模型权重\n",
    "    if device == 'cpu':\n",
    "        state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        state_dict = torch.load(model_path)\n",
    "    \n",
    "    # 加载权重到模型\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()  # 设置为评估模式\n",
    "\n",
    "    print(\"加载模型: \", model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载模型:  ./models/cifar10_resnet18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2211786/168071617.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "victim_model = load_model(model_path + model_list[0], num_classes=10, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对加载的受害者模型进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 加载CIFAR-10训练数据集\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_test)\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 加载CIFAR-10测试数据集\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "def test_model(model, dataloader, perturbation=None):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            if perturbation: outputs = perturbation(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    acc = 100.*correct/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  93.48 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(victim_model, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们作为攻击者，对受害者模型进行轮询访问，以获取其查询-预测对:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在有一个问题：攻击者如何获取用于查询的数据集？\n",
    "\n",
    "虽然在实际中，攻击者并不知道模型的任何先验知识，但是知道其功能是什么。举一个简单的例子：受害者模型是一个对猫狗的二分类问题，攻击者即可收集猫和狗的图像作为对模型的查询数据集。\n",
    "\n",
    "在本次实验中，受害者模型是一个10-分类问题，简单起见，我们直接对 cifar-10 公开数据集进行随机采样，以作为对受害者模型的查询数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query_set(dataset_name=\"cifar10\", data_size=10000, use_public_data=True):\n",
    "    \"\"\"构建用于查询受害者模型的数据集\"\"\"\n",
    "    if use_public_data:\n",
    "        if dataset_name == \"cifar10\":\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            query_dataset = torchvision.datasets.CIFAR10(\n",
    "                root='./data', train=True, download=True, transform=transform)\n",
    "            \n",
    "            # 随机采样一部分数据\n",
    "            indices = np.random.choice(len(query_dataset), data_size, replace=False)\n",
    "            query_images = torch.stack([query_dataset[i][0] for i in indices])\n",
    "            return query_images\n",
    "    \n",
    "    else:\n",
    "        # 生成随机噪声数据\n",
    "        return torch.randn(data_size, 3, 32, 32) * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于是，我们便可以使用查询数据集对受害者模型进行轮询："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_victim_model(victim_model, query_images, batch_size=64, device='cuda', output_perturbation=None):\n",
    "    \"\"\"向受害者模型发送查询并收集预测结果\"\"\"\n",
    "    victim_model.to(device)\n",
    "    victim_model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    dataloader = DataLoader(query_images, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Querying victim model\"):\n",
    "            batch = batch.to(device)\n",
    "            outputs = victim_model(batch)\n",
    "\n",
    "            # 检查预测结果是否变化\n",
    "            _, orig_preds = torch.max(outputs, 1)\n",
    "\n",
    "            \n",
    "\n",
    "            if output_perturbation:\n",
    "                outputs = output_perturbation(outputs)\n",
    "                \n",
    "                _, pert_preds = torch.max(outputs, 1)\n",
    "            # 获取预测的类别\n",
    "            # _, predictions = torch.max(outputs, 1)\n",
    "            \n",
    "            # 返回受害者模型预测的概率分布\n",
    "            predictions = F.softmax(outputs, dim=1)\n",
    "            all_predictions.append(predictions.cpu())\n",
    "    \n",
    "    # 合并所有批次的预测结果\n",
    "    all_predictions = torch.cat(all_predictions)\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将获取到的查询-预测对构建成为替代数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubstituteDataset(Dataset):\n",
    "    def __init__(self, queries, predictions, transform=None):\n",
    "        self.queries = queries\n",
    "        self.predictions = predictions\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, prediction = self.queries[idx], self.predictions[idx]\n",
    "        \n",
    "        if isinstance(img, np.ndarray):\n",
    "            img = torch.tensor(img)\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, prediction\n",
    "\n",
    "def create_substitute_dataset(victim_model, query_images, save_path=\"substitute_dataset.pt\", augment=False, output_perturbation=None):\n",
    "    \"\"\"构建并保存替代数据集\"\"\"\n",
    "    print(output_perturbation)\n",
    "    # 查询受害者模型\n",
    "    predictions = query_victim_model(victim_model, query_images, output_perturbation=output_perturbation)\n",
    "\n",
    "    # # 定义数据增强\n",
    "    # train_transform = transforms.Compose([\n",
    "    #     transforms.ToPILImage(),\n",
    "    #     transforms.RandomCrop(32, padding=4),\n",
    "    #     transforms.RandomHorizontalFlip(),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    # ])\n",
    "    \n",
    "    # 创建替代数据集\n",
    "    substitute_dataset = SubstituteDataset(query_images, predictions, train_transform if augment else None)\n",
    "    \n",
    "    # 保存数据集\n",
    "    torch.save({\n",
    "        'queries': query_images,\n",
    "        'predictions': predictions\n",
    "    }, save_path)\n",
    "    \n",
    "    print(f\"替代数据集已保存至: {save_path}\")\n",
    "    print(f\"数据集大小: {len(substitute_dataset)} 样本\")\n",
    "    return substitute_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying victim model: 100%|██████████| 47/47 [00:00<00:00, 316.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "替代数据集已保存至: substitute_dataset_cifar10.pt\n",
      "数据集大小: 3000 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建查询集（使用CIFAR-10测试集的3000个样本）\n",
    "query_images = build_query_set(data_size=3000)\n",
    "\n",
    "# 创建替代数据集\n",
    "substitute_dataset = create_substitute_dataset(\n",
    "    victim_model=victim_model,\n",
    "    query_images=query_images,\n",
    "    save_path=\"substitute_dataset_cifar10.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来看一下替代数据集是什么样的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_CLASS_NAMES = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "def visualize_substitute_dataset(dataset, num_samples=5, class_names=CIFAR10_CLASS_NAMES):\n",
    "    \"\"\"可视化替代数据集中的样本，显示类别名称而非数字\"\"\"\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, idx in enumerate(indices):\n",
    "        # image, label = dataset[idx]\n",
    "        image, prob = dataset[idx]\n",
    "        label = torch.argmax(prob).item()\n",
    "        # 反归一化以便显示\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "        image = image * np.array([0.2023, 0.1994, 0.2010]) + np.array([0.4914, 0.4822, 0.4465])\n",
    "        image = np.clip(image, 0, 1)\n",
    "        \n",
    "        # 获取类别名称\n",
    "        class_name = class_names[label] if label < len(class_names) else f\"Unknown ({label})\"\n",
    "        \n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Predicted: {class_name}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化样本\n",
    "visualize_substitute_dataset(substitute_dataset)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取替代数据集后，我们便可以对自己的模型进行训练了。\n",
    "\n",
    "作为攻击者，我们并不知道模型内部的架构，因此，我们需要自定义自己的模型架构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubstituteModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SubstituteModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 第一层卷积\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # 第二层卷积\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # 第三层卷积\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        \n",
    "        # 全连接分类器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute_model = SubstituteModel(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们使用窃取构建的数据集对模型进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两个概率分布之间的交叉熵损失函数\n",
    "def loss_ce(p, q):\n",
    "    # 这里的 p 和 q 是经过 softmax 后的概率分布\n",
    "    # 计算交叉熵损失\n",
    "    return -(q * p.log()).sum(dim=1).mean()  \n",
    "\n",
    "def train_substitute_model(substitute_model, substitute_dataset, epochs=50, batch_size=128, lr=0.001, device='cuda', model_name='substitute_model.pth'):\n",
    "    \"\"\"在替代数据集上训练替代模型\"\"\"\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(substitute_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    criterion = loss_ce\n",
    "    optimizer = optim.Adam(substitute_model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "    \n",
    "    # 训练循环\n",
    "    substitute_model.to(device)\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        substitute_model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = substitute_model(inputs)\n",
    "            # loss = criterion(outputs, targets)\n",
    "            loss = criterion(F.softmax(outputs, dim=1), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            # correct += predicted.eq(targets).sum().item()\n",
    "            correct += (predicted == targets.argmax(dim=1)).sum().item()\n",
    "        \n",
    "        # 计算准确率和平均损失\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%')\n",
    "        \n",
    "        # 学习率调度\n",
    "        scheduler.step(epoch_loss)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            torch.save(substitute_model.state_dict(), model_name)\n",
    "            print(f'Saved best model with accuracy: {best_acc:.2f}%')\n",
    "    \n",
    "    print(f'Finished training. Best accuracy: {best_acc:.2f}%')\n",
    "    return substitute_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练替代模型...\n",
      "Epoch 1/20 | Loss: 2.0420 | Acc: 29.23%\n",
      "Saved best model with accuracy: 29.23%\n",
      "Epoch 2/20 | Loss: 1.7691 | Acc: 41.20%\n",
      "Saved best model with accuracy: 41.20%\n",
      "Epoch 3/20 | Loss: 1.6359 | Acc: 48.40%\n",
      "Saved best model with accuracy: 48.40%\n",
      "Epoch 4/20 | Loss: 1.5307 | Acc: 53.23%\n",
      "Saved best model with accuracy: 53.23%\n",
      "Epoch 5/20 | Loss: 1.4406 | Acc: 57.17%\n",
      "Saved best model with accuracy: 57.17%\n",
      "Epoch 6/20 | Loss: 1.3917 | Acc: 59.87%\n",
      "Saved best model with accuracy: 59.87%\n",
      "Epoch 7/20 | Loss: 1.3142 | Acc: 64.37%\n",
      "Saved best model with accuracy: 64.37%\n",
      "Epoch 8/20 | Loss: 1.2249 | Acc: 69.03%\n",
      "Saved best model with accuracy: 69.03%\n",
      "Epoch 9/20 | Loss: 1.1728 | Acc: 71.60%\n",
      "Saved best model with accuracy: 71.60%\n",
      "Epoch 10/20 | Loss: 1.1303 | Acc: 74.37%\n",
      "Saved best model with accuracy: 74.37%\n",
      "Epoch 11/20 | Loss: 1.0955 | Acc: 75.80%\n",
      "Saved best model with accuracy: 75.80%\n",
      "Epoch 12/20 | Loss: 1.0584 | Acc: 77.60%\n",
      "Saved best model with accuracy: 77.60%\n",
      "Epoch 13/20 | Loss: 1.0456 | Acc: 78.03%\n",
      "Saved best model with accuracy: 78.03%\n",
      "Epoch 14/20 | Loss: 0.9863 | Acc: 82.03%\n",
      "Saved best model with accuracy: 82.03%\n",
      "Epoch 15/20 | Loss: 0.9549 | Acc: 83.43%\n",
      "Saved best model with accuracy: 83.43%\n",
      "Epoch 16/20 | Loss: 0.9279 | Acc: 84.93%\n",
      "Saved best model with accuracy: 84.93%\n",
      "Epoch 17/20 | Loss: 0.9053 | Acc: 86.23%\n",
      "Saved best model with accuracy: 86.23%\n",
      "Epoch 18/20 | Loss: 0.8844 | Acc: 86.43%\n",
      "Saved best model with accuracy: 86.43%\n",
      "Epoch 19/20 | Loss: 0.8424 | Acc: 89.33%\n",
      "Saved best model with accuracy: 89.33%\n",
      "Epoch 20/20 | Loss: 0.8391 | Acc: 89.63%\n",
      "Saved best model with accuracy: 89.63%\n",
      "Finished training. Best accuracy: 89.63%\n"
     ]
    }
   ],
   "source": [
    "# 在替代数据集上训练替代模型\n",
    "print(\"开始训练替代模型...\")\n",
    "trained_substitute_model = train_substitute_model(\n",
    "    substitute_model=substitute_model,\n",
    "    substitute_dataset=substitute_dataset,\n",
    "    epochs=20,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们对窃取数据集上训练的模型进行评估："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  61.22 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(substitute_model, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，窃取模型攻击所获取的模型的测试准确率较高（？），这样，攻击者就可以用极低的时间和训练成本来获取一个高质量的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 模型窃取防御\n",
    "\n",
    "模型窃取防御的目的是让攻击者无法通过简单的查询就能获取模型输出分布/模型参数。\n",
    "\n",
    "一般来说，被窃取模型准确率越高，它们输出的信息分布就会过于精确，导致攻击者很容易获取到高质量的 输入-输出 对作为高质量数据集，进而通过高质量的数据集来训练出替代模型。\n",
    "\n",
    "模型窃取防御可以从这个方向出发，通过**模糊化技术**，例如模糊决策边界、模糊输入概率等等方式，对窃取攻击进行防御。\n",
    "\n",
    "## 2.1 信息模糊\n",
    "对模型的输出进行模糊：将输出向量限制为前k个类、将输出向量四舍五入、增加输出向量的信息熵、正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DefenseModel(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       "  (defense_layer): defense_layer()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最后一层只保留前 k 个值，并且四舍五入到第 d 位，以加大学习难度\n",
    "class defense_layer(nn.Module):\n",
    "    def __init__(self, k=5, d=2, tau=None):\n",
    "        super(defense_layer, self).__init__()\n",
    "        self.k = k\n",
    "        self.d = d\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 四舍五入到第 d 位\n",
    "        x = torch.round(x, decimals=self.d)\n",
    "        # 前 k 大位置的值保留，其余位置设为负无穷\n",
    "        indices = torch.topk(x, self.k, dim=1)[1]\n",
    "        new_x = torch.full_like(x, -float('inf'))        \n",
    "        for i in range(x.shape[0]):\n",
    "            new_x[i, indices[i]] = x[i, indices[i]]\n",
    "        if self.tau is not None:\n",
    "            new_x = new_x / self.tau\n",
    "        return new_x\n",
    "\n",
    "class DefenseModel(nn.Module):\n",
    "    def __init__(self, model, k=5, d=2, tau=None):\n",
    "        super(DefenseModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.defense_layer = defense_layer(k=k, d=d, tau=tau)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.defense_layer(x)\n",
    "        return x\n",
    "\n",
    "defense_model = DefenseModel(victim_model, k=3, d=1, tau=20).to(device)\n",
    "defense_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  93.45 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(defense_model, testloader), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying victim model: 100%|██████████| 47/47 [00:00<00:00, 223.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "替代数据集已保存至: substitute_dataset_defense_cifar10.pt\n",
      "数据集大小: 3000 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建查询集（使用CIFAR-10测试集的3000个样本）\n",
    "query_images = build_query_set(data_size=3000)\n",
    "\n",
    "# 创建替代数据集\n",
    "substitute_dataset_defense = create_substitute_dataset(\n",
    "    victim_model=defense_model,\n",
    "    query_images=query_images,\n",
    "    save_path=\"substitute_dataset_defense_cifar10.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute_model_defense = SubstituteModel(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练替代模型...\n",
      "Epoch 1/20 | Loss: 2.2554 | Acc: 17.63%\n",
      "Saved best model with accuracy: 17.63%\n",
      "Epoch 2/20 | Loss: 2.1517 | Acc: 25.90%\n",
      "Saved best model with accuracy: 25.90%\n",
      "Epoch 3/20 | Loss: 2.1049 | Acc: 30.50%\n",
      "Saved best model with accuracy: 30.50%\n",
      "Epoch 4/20 | Loss: 2.0635 | Acc: 35.87%\n",
      "Saved best model with accuracy: 35.87%\n",
      "Epoch 5/20 | Loss: 2.0418 | Acc: 37.77%\n",
      "Saved best model with accuracy: 37.77%\n",
      "Epoch 6/20 | Loss: 2.0062 | Acc: 40.33%\n",
      "Saved best model with accuracy: 40.33%\n",
      "Epoch 7/20 | Loss: 1.9832 | Acc: 43.13%\n",
      "Saved best model with accuracy: 43.13%\n",
      "Epoch 8/20 | Loss: 1.9555 | Acc: 44.67%\n",
      "Saved best model with accuracy: 44.67%\n",
      "Epoch 9/20 | Loss: 1.9324 | Acc: 47.33%\n",
      "Saved best model with accuracy: 47.33%\n",
      "Epoch 10/20 | Loss: 1.9163 | Acc: 47.93%\n",
      "Saved best model with accuracy: 47.93%\n",
      "Epoch 11/20 | Loss: 1.8979 | Acc: 48.03%\n",
      "Saved best model with accuracy: 48.03%\n",
      "Epoch 12/20 | Loss: 1.8810 | Acc: 50.63%\n",
      "Saved best model with accuracy: 50.63%\n",
      "Epoch 13/20 | Loss: 1.8559 | Acc: 50.13%\n",
      "Epoch 14/20 | Loss: 1.8363 | Acc: 51.83%\n",
      "Saved best model with accuracy: 51.83%\n",
      "Epoch 15/20 | Loss: 1.8164 | Acc: 52.63%\n",
      "Saved best model with accuracy: 52.63%\n",
      "Epoch 16/20 | Loss: 1.8012 | Acc: 52.60%\n",
      "Epoch 17/20 | Loss: 1.7759 | Acc: 52.97%\n",
      "Saved best model with accuracy: 52.97%\n",
      "Epoch 18/20 | Loss: 1.7575 | Acc: 53.67%\n",
      "Saved best model with accuracy: 53.67%\n",
      "Epoch 19/20 | Loss: 1.7410 | Acc: 53.37%\n",
      "Epoch 20/20 | Loss: 1.7182 | Acc: 54.40%\n",
      "Saved best model with accuracy: 54.40%\n",
      "Finished training. Best accuracy: 54.40%\n"
     ]
    }
   ],
   "source": [
    "# 在模糊后的替代数据集上训练替代模型\n",
    "print(\"开始训练替代模型...\")\n",
    "trained_substitute_model_defense = train_substitute_model(\n",
    "    substitute_model=substitute_model_defense,\n",
    "    substitute_dataset=substitute_dataset_defense,\n",
    "    epochs=20,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  49.3 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(substitute_model_defense, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 模型置信度模糊\n",
    "除了取 top-k 的预测类别进行输出，模糊化输出外，防御者还可以通过对模型的logits层进行扰动操作，让模型的输出分布受到改变，进而让攻击者获取到低质量的数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里提供一种方法：根据带温度的softmax来计算每个类别的概率分布，对于某些类别，它的最高概率若不达到阈值，则看作低置信度样本，对其扰动。\n",
    "\n",
    "扰动策略：\n",
    "1. 选择一个与原预测不同的随机类别。\n",
    "2. 将原预测类别的logits缩放（如0.5%）。\n",
    "3. 将随机选择的类别logits放大10倍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def perturb_prediction(outputs, confidence_threshold=0.60, temperature=1.75):\n",
    "    \"\"\"\n",
    "    基于置信度对模型预测结果进行扰动，用于防御模型窃取攻击\n",
    "    \n",
    "    参数:\n",
    "        outputs: 模型原始输出logits (batch_size, num_classes)\n",
    "        confidence_threshold: 置信度阈值，低于此值的预测将被扰动\n",
    "        temperature: softmax温度参数，控制概率分布的平滑度\n",
    "        device: 计算设备\n",
    "        \n",
    "    返回:\n",
    "        扰动后的输出logits\n",
    "    \"\"\"\n",
    "    # 计算softmax概率和最大置信度\n",
    "    probs = F.softmax(outputs / temperature, dim=1)\n",
    "    max_probs, predicted = probs.max(1)\n",
    "    \n",
    "    # 识别需要扰动的低置信度样本\n",
    "    mask = max_probs < confidence_threshold\n",
    "    num_classes = outputs.size(1)\n",
    "    \n",
    "    # print(f\"低置信度样本比例 ({confidence_threshold}): {(mask.sum()/len(mask)):.2%}\")\n",
    "    \n",
    "    # 如果没有低置信度样本，直接返回原始输出\n",
    "    if mask.sum() == 0:\n",
    "        return outputs\n",
    "    \n",
    "    # 对低置信度样本进行扰动\n",
    "    new_outputs = outputs.clone()\n",
    "    \n",
    "    # 为每个需要扰动的样本生成随机标签（确保与原预测不同）\n",
    "    for i in range(len(outputs)):\n",
    "        if mask[i]:\n",
    "            orig_pred = predicted[i].item()\n",
    "            # 生成一个不等于orig_pred的随机标签\n",
    "            candidates = [j for j in range(num_classes) if j != orig_pred]\n",
    "            random_label = candidates[torch.randint(0, len(candidates), (1,)).item()]\n",
    "            \n",
    "            # 应用扰动\n",
    "            new_outputs[i, orig_pred] *= 0.005  # 降低原预测分数\n",
    "            new_outputs[i, random_label] *= 10  # 提高随机标签分数\n",
    "    \n",
    "    return new_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "<function perturb_prediction at 0x7f7ed58d53a0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying victim model: 100%|██████████| 47/47 [00:00<00:00, 153.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "替代数据集已保存至: substitute_dataset_cifar10.pt\n",
      "数据集大小: 3000 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建查询集（使用CIFAR-10测试集的3000个样本）\n",
    "query_images = build_query_set(data_size=3000)\n",
    "\n",
    "# 创建替代数据集\n",
    "substitute_dataset = create_substitute_dataset(\n",
    "    victim_model=victim_model,\n",
    "    query_images=query_images,\n",
    "    save_path=\"substitute_dataset_cifar10.pt\",\n",
    "    # output_perturbation = perturb_prediction\n",
    "    output_perturbation=perturb_prediction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute_model_output_perturbation_defense = SubstituteModel(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练替代模型...\n",
      "Epoch 1/20 | Loss: 2.3638 | Acc: 19.03%\n",
      "Saved best model with accuracy: 19.03%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Loss: 2.2832 | Acc: 27.30%\n",
      "Saved best model with accuracy: 27.30%\n",
      "Epoch 3/20 | Loss: 2.2456 | Acc: 32.87%\n",
      "Saved best model with accuracy: 32.87%\n",
      "Epoch 4/20 | Loss: 2.2252 | Acc: 36.17%\n",
      "Saved best model with accuracy: 36.17%\n",
      "Epoch 5/20 | Loss: 2.1983 | Acc: 38.90%\n",
      "Saved best model with accuracy: 38.90%\n",
      "Epoch 6/20 | Loss: 2.1798 | Acc: 41.77%\n",
      "Saved best model with accuracy: 41.77%\n",
      "Epoch 7/20 | Loss: 2.1498 | Acc: 43.47%\n",
      "Saved best model with accuracy: 43.47%\n",
      "Epoch 8/20 | Loss: 2.1372 | Acc: 45.33%\n",
      "Saved best model with accuracy: 45.33%\n",
      "Epoch 9/20 | Loss: 2.1119 | Acc: 47.90%\n",
      "Saved best model with accuracy: 47.90%\n",
      "Epoch 10/20 | Loss: 2.0834 | Acc: 49.63%\n",
      "Saved best model with accuracy: 49.63%\n",
      "Epoch 11/20 | Loss: 2.0746 | Acc: 50.97%\n",
      "Saved best model with accuracy: 50.97%\n",
      "Epoch 12/20 | Loss: 2.0464 | Acc: 53.33%\n",
      "Saved best model with accuracy: 53.33%\n",
      "Epoch 13/20 | Loss: 2.0315 | Acc: 53.57%\n",
      "Saved best model with accuracy: 53.57%\n",
      "Epoch 14/20 | Loss: 2.0140 | Acc: 53.50%\n",
      "Epoch 15/20 | Loss: 1.9963 | Acc: 55.97%\n",
      "Saved best model with accuracy: 55.97%\n",
      "Epoch 16/20 | Loss: 1.9790 | Acc: 55.30%\n",
      "Epoch 17/20 | Loss: 1.9638 | Acc: 57.60%\n",
      "Saved best model with accuracy: 57.60%\n",
      "Epoch 18/20 | Loss: 1.9509 | Acc: 57.33%\n",
      "Epoch 19/20 | Loss: 1.9449 | Acc: 56.90%\n",
      "Epoch 20/20 | Loss: 1.9199 | Acc: 56.07%\n",
      "Finished training. Best accuracy: 57.60%\n"
     ]
    }
   ],
   "source": [
    "# 在替代数据集上训练替代模型\n",
    "print(\"开始训练替代模型...\")\n",
    "trained_substitute_model = train_substitute_model(\n",
    "    substitute_model=substitute_model_output_perturbation_defense,\n",
    "    substitute_dataset=substitute_dataset,\n",
    "    epochs=20,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  85.15 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(victim_model, testloader, perturbation=perturb_prediction), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  45.85 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(substitute_model_output_perturbation_defense, testloader), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
