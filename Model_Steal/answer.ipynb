{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 课程前言\n",
    "此为 <<人工智能安全>> 课程第四部分: 模型窃取攻击与防御实验部分.\n",
    "\n",
    "**模型窃取攻击**的目标是通过一定手段窃取得到一个跟 受害者模型 功能和性能近似的窃取模型，从而避开昂贵的模型训练并从中获益。\n",
    "\n",
    "<img src=\"./imgs/model steal.png\" alt=\"替代模型窃取攻击示意图\" style=\"height: 300px; max-width: 100%;\">\n",
    "\n",
    "上图为一个简单基础的模型窃取攻击过程，攻击者在黑盒环境下与受害者模型交互，获取模型的输入与输出，并不断调整查询样本来获取模型更多的决策边界信息。攻击者可以将此输入-输出作为数据集，对自己的模型进行模仿学习，得到一个与受害者模型相似的窃取模型。\n",
    "\n",
    "一般来说，模型窃取攻击的主要目标包括：\n",
    "1. 低代价：以远低于受害者模型训练成本的代价获得一个可免费使用的窃取模型；\n",
    "2. 高收益：窃取得到的模型与受害者模型的功能和性能相当；\n",
    "3. 低风险：在窃取过程中可以避开相关检测并在窃取后无法被溯源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 模型窃取攻击\n",
    "模型窃取攻击有多种方式：基于**方程式求解**的模型窃取攻击、基于**替代模型**的窃取攻击、基于**元模型**的窃取攻击。\n",
    "\n",
    "受篇幅影响，本次实验主要将基于替代模型的窃取攻击，有兴趣的同学可自行搜索学习其他类别的攻击方法。\n",
    "\n",
    "## 1.1 基于替代模型的窃取攻击\n",
    "攻击主要思路：攻击者 $A$ 在不知道受害者模型 $f(\\cdot)$ 任何先验知识情况下，向受害者模型输入查询样本 $x$ ，得到受害者模型的预测输出 $f(x)$ 。随后，攻击者根据输入和输出构建替代训练数据集 $\\mathcal D ' = {(x, f(x))}^m_{i=1}$ 。\n",
    "\n",
    "实际上，替代数据集已经完成了对袁术训练数据的（部分）提取。在替代数据集 $\\mathcal D'$ 上多次训练后，即可得到一个与受害者模型 $f(\\cdot)$ 功能和性质类似的替代模型 $f'(\\cdot)$ ，完成模型窃取攻击。\n",
    "\n",
    "<img src=\"./imgs/model steal2.png\" alt=\"替代模型窃取攻击示意图\" style=\"height: 400px; max-width: 100%;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了实现这样的模型窃取方法，我们首先需要加载受害者模型。\n",
    "\n",
    "（在实际中，模型窃取攻击者通常使用受害者API进行查询访问）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datasets\n",
    "\n",
    "import cifar_model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/\"\n",
    "model_list = [\n",
    "    \"cifar10_resnet18.pth\",\n",
    "    \"cifar10_model.pth\"\n",
    "]\n",
    "\n",
    "# 加载模型\n",
    "def load_model(model_path, num_classes, device):\n",
    "    # 加载模型结构\n",
    "    model = cifar_model.ResNet18(num_classes=num_classes)\n",
    "\n",
    "    # 加载模型权重\n",
    "    if device == 'cpu':\n",
    "        state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        state_dict = torch.load(model_path)\n",
    "    \n",
    "    # 加载权重到模型\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()  # 设置为评估模式\n",
    "\n",
    "    print(\"加载模型: \", model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载模型:  ./models/cifar10_resnet18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2143088/168071617.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "victim_model = load_model(model_path + model_list[0], num_classes=10, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对加载的受害者模型进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 加载CIFAR-10训练数据集\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_test)\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 加载CIFAR-10测试数据集\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "def test_model(model, dataloader, perturbation=None):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            if perturbation: outputs = perturbation(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    acc = 100.*correct/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  93.48 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(victim_model, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们作为攻击者，对受害者模型进行轮询访问，以获取其查询-预测对:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在有一个问题：攻击者如何获取用于查询的数据集？\n",
    "\n",
    "虽然在实际中，攻击者并不知道模型的任何先验知识，但是知道其功能是什么。举一个简单的例子：受害者模型是一个对猫狗的二分类问题，攻击者即可收集猫和狗的图像作为对模型的查询数据集。\n",
    "\n",
    "在本次实验中，受害者模型是一个10-分类问题，简单起见，我们直接对 cifar-10 公开数据集进行随机采样，以作为对受害者模型的查询数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query_set(dataset_name=\"cifar10\", data_size=10000, use_public_data=True):\n",
    "    \"\"\"构建用于查询受害者模型的数据集\"\"\"\n",
    "    if use_public_data:\n",
    "        if dataset_name == \"cifar10\":\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            query_dataset = torchvision.datasets.CIFAR10(\n",
    "                root='./data', train=True, download=True, transform=transform)\n",
    "            \n",
    "            # 随机采样一部分数据\n",
    "            indices = np.random.choice(len(query_dataset), data_size, replace=False)\n",
    "            query_images = torch.stack([query_dataset[i][0] for i in indices])\n",
    "            return query_images\n",
    "    \n",
    "    else:\n",
    "        # 生成随机噪声数据\n",
    "        return torch.randn(data_size, 3, 32, 32) * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于是，我们便可以使用查询数据集对受害者模型进行轮询："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_victim_model(victim_model, query_images, batch_size=64, device='cuda', output_perturbation=None):\n",
    "    \"\"\"向受害者模型发送查询并收集预测结果\"\"\"\n",
    "    victim_model.to(device)\n",
    "    victim_model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    dataloader = DataLoader(query_images, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ias = 0\n",
    "        for batch in tqdm(dataloader, desc=\"Querying victim model\"):\n",
    "            batch = batch.to(device)\n",
    "            outputs = victim_model(batch)\n",
    "\n",
    "            # 检查预测结果是否变化\n",
    "            _, orig_preds = torch.max(outputs, 1)\n",
    "\n",
    "            \n",
    "\n",
    "            if output_perturbation:\n",
    "                outputs = output_perturbation(outputs)\n",
    "                \n",
    "                _, pert_preds = torch.max(outputs, 1)\n",
    "                if ias == 0:\n",
    "                    print(f\"扰动导致的预测变化率: {(orig_preds != pert_preds).float().mean().item():.2%}\")\n",
    "                    ias = 1\n",
    "            # 获取预测的类别\n",
    "            # _, predictions = torch.max(outputs, 1)\n",
    "            \n",
    "            # 返回受害者模型预测的概率分布\n",
    "            predictions = F.softmax(outputs, dim=1)\n",
    "            all_predictions.append(predictions.cpu())\n",
    "    \n",
    "    # 合并所有批次的预测结果\n",
    "    all_predictions = torch.cat(all_predictions)\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将获取到的查询-预测对构建成为替代数据集，我们还可以使用数据增强对替代数据集进行增强："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubstituteDataset(Dataset):\n",
    "    def __init__(self, queries, predictions, transform=None):\n",
    "        self.queries = queries\n",
    "        self.predictions = predictions\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, prediction = self.queries[idx], self.predictions[idx]\n",
    "        \n",
    "        if isinstance(img, np.ndarray):\n",
    "            img = torch.tensor(img)\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, prediction\n",
    "\n",
    "def create_substitute_dataset(victim_model, query_images, save_path=\"substitute_dataset.pt\", augment=False, output_perturbation=None):\n",
    "    \"\"\"构建并保存替代数据集\"\"\"\n",
    "    print(output_perturbation)\n",
    "    # 查询受害者模型\n",
    "    predictions = query_victim_model(victim_model, query_images, output_perturbation=output_perturbation)\n",
    "\n",
    "    # # 定义数据增强\n",
    "    # train_transform = transforms.Compose([\n",
    "    #     transforms.ToPILImage(),\n",
    "    #     transforms.RandomCrop(32, padding=4),\n",
    "    #     transforms.RandomHorizontalFlip(),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    # ])\n",
    "    \n",
    "    # 创建替代数据集\n",
    "    substitute_dataset = SubstituteDataset(query_images, predictions, train_transform if augment else None)\n",
    "    \n",
    "    # 保存数据集\n",
    "    torch.save({\n",
    "        'queries': query_images,\n",
    "        'predictions': predictions\n",
    "    }, save_path)\n",
    "    \n",
    "    print(f\"替代数据集已保存至: {save_path}\")\n",
    "    print(f\"数据集大小: {len(substitute_dataset)} 样本\")\n",
    "    return substitute_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying victim model: 100%|██████████| 47/47 [00:00<00:00, 366.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "替代数据集已保存至: substitute_dataset_cifar10.pt\n",
      "数据集大小: 3000 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建查询集（使用CIFAR-10测试集的3000个样本）\n",
    "query_images = build_query_set(data_size=3000)\n",
    "\n",
    "# 创建替代数据集\n",
    "substitute_dataset = create_substitute_dataset(\n",
    "    victim_model=victim_model,\n",
    "    query_images=query_images,\n",
    "    save_path=\"substitute_dataset_cifar10.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来看一下替代数据集是什么样的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_CLASS_NAMES = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "def visualize_substitute_dataset(dataset, num_samples=5, class_names=CIFAR10_CLASS_NAMES):\n",
    "    \"\"\"可视化替代数据集中的样本，显示类别名称而非数字\"\"\"\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, idx in enumerate(indices):\n",
    "        # image, label = dataset[idx]\n",
    "        image, prob = dataset[idx]\n",
    "        label = torch.argmax(prob).item()\n",
    "        # 反归一化以便显示\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "        image = image * np.array([0.2023, 0.1994, 0.2010]) + np.array([0.4914, 0.4822, 0.4465])\n",
    "        image = np.clip(image, 0, 1)\n",
    "        \n",
    "        # 获取类别名称\n",
    "        class_name = class_names[label] if label < len(class_names) else f\"Unknown ({label})\"\n",
    "        \n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Predicted: {class_name}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化样本\n",
    "visualize_substitute_dataset(substitute_dataset)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取替代数据集后，我们便可以对自己的模型进行训练了。\n",
    "\n",
    "作为攻击者，我们并不知道模型内部的架构，因此，我们需要自定义自己的模型架构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubstituteModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SubstituteModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 第一层卷积\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # 第二层卷积\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # 第三层卷积\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        \n",
    "        # 全连接分类器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute_model = SubstituteModel(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们使用窃取构建的数据集对模型进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两个概率分布之间的交叉熵损失函数\n",
    "def loss_ce(p, q):\n",
    "    # 这里的 p 和 q 是经过 softmax 后的概率分布\n",
    "    # 计算交叉熵损失\n",
    "    return -(q * p.log()).sum(dim=1).mean()  \n",
    "\n",
    "def train_substitute_model(substitute_model, substitute_dataset, epochs=50, batch_size=128, lr=0.001, device='cuda', model_name='substitute_model.pth'):\n",
    "    \"\"\"在替代数据集上训练替代模型\"\"\"\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(substitute_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    criterion = loss_ce\n",
    "    optimizer = optim.Adam(substitute_model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "    \n",
    "    # 训练循环\n",
    "    substitute_model.to(device)\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        substitute_model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = substitute_model(inputs)\n",
    "            # loss = criterion(outputs, targets)\n",
    "            loss = criterion(F.softmax(outputs, dim=1), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            # correct += predicted.eq(targets).sum().item()\n",
    "            correct += (predicted == targets.argmax(dim=1)).sum().item()\n",
    "        \n",
    "        # 计算准确率和平均损失\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%')\n",
    "        \n",
    "        # 学习率调度\n",
    "        scheduler.step(epoch_loss)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            torch.save(substitute_model.state_dict(), model_name)\n",
    "            print(f'Saved best model with accuracy: {best_acc:.2f}%')\n",
    "    \n",
    "    print(f'Finished training. Best accuracy: {best_acc:.2f}%')\n",
    "    return substitute_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练替代模型...\n",
      "Epoch 1/30 | Loss: 2.0512 | Acc: 27.80%\n",
      "Saved best model with accuracy: 27.80%\n",
      "Epoch 2/30 | Loss: 1.7532 | Acc: 42.57%\n",
      "Saved best model with accuracy: 42.57%\n",
      "Epoch 3/30 | Loss: 1.6200 | Acc: 50.60%\n",
      "Saved best model with accuracy: 50.60%\n",
      "Epoch 4/30 | Loss: 1.5546 | Acc: 52.87%\n",
      "Saved best model with accuracy: 52.87%\n",
      "Epoch 5/30 | Loss: 1.4413 | Acc: 57.60%\n",
      "Saved best model with accuracy: 57.60%\n",
      "Epoch 6/30 | Loss: 1.3596 | Acc: 62.37%\n",
      "Saved best model with accuracy: 62.37%\n",
      "Epoch 7/30 | Loss: 1.3016 | Acc: 65.03%\n",
      "Saved best model with accuracy: 65.03%\n",
      "Epoch 8/30 | Loss: 1.2318 | Acc: 68.10%\n",
      "Saved best model with accuracy: 68.10%\n",
      "Epoch 9/30 | Loss: 1.1924 | Acc: 71.10%\n",
      "Saved best model with accuracy: 71.10%\n",
      "Epoch 10/30 | Loss: 1.1336 | Acc: 72.80%\n",
      "Saved best model with accuracy: 72.80%\n",
      "Epoch 11/30 | Loss: 1.0919 | Acc: 75.50%\n",
      "Saved best model with accuracy: 75.50%\n",
      "Epoch 12/30 | Loss: 1.0505 | Acc: 78.47%\n",
      "Saved best model with accuracy: 78.47%\n",
      "Epoch 13/30 | Loss: 1.0161 | Acc: 80.40%\n",
      "Saved best model with accuracy: 80.40%\n",
      "Epoch 14/30 | Loss: 0.9799 | Acc: 82.57%\n",
      "Saved best model with accuracy: 82.57%\n",
      "Epoch 15/30 | Loss: 0.9414 | Acc: 83.70%\n",
      "Saved best model with accuracy: 83.70%\n",
      "Epoch 16/30 | Loss: 0.9183 | Acc: 83.97%\n",
      "Saved best model with accuracy: 83.97%\n",
      "Epoch 17/30 | Loss: 0.8901 | Acc: 86.80%\n",
      "Saved best model with accuracy: 86.80%\n",
      "Epoch 18/30 | Loss: 0.8631 | Acc: 88.30%\n",
      "Saved best model with accuracy: 88.30%\n",
      "Epoch 19/30 | Loss: 0.8416 | Acc: 88.93%\n",
      "Saved best model with accuracy: 88.93%\n",
      "Epoch 20/30 | Loss: 0.8265 | Acc: 90.13%\n",
      "Saved best model with accuracy: 90.13%\n",
      "Epoch 21/30 | Loss: 0.7880 | Acc: 92.57%\n",
      "Saved best model with accuracy: 92.57%\n",
      "Epoch 22/30 | Loss: 0.7764 | Acc: 92.80%\n",
      "Saved best model with accuracy: 92.80%\n",
      "Epoch 23/30 | Loss: 0.7652 | Acc: 92.80%\n",
      "Epoch 24/30 | Loss: 0.7604 | Acc: 93.33%\n",
      "Saved best model with accuracy: 93.33%\n",
      "Epoch 25/30 | Loss: 0.7573 | Acc: 93.30%\n",
      "Epoch 26/30 | Loss: 0.7476 | Acc: 94.53%\n",
      "Saved best model with accuracy: 94.53%\n",
      "Epoch 27/30 | Loss: 0.7354 | Acc: 94.43%\n",
      "Epoch 28/30 | Loss: 0.7109 | Acc: 96.07%\n",
      "Saved best model with accuracy: 96.07%\n",
      "Epoch 29/30 | Loss: 0.7143 | Acc: 95.83%\n",
      "Epoch 30/30 | Loss: 0.7078 | Acc: 96.30%\n",
      "Saved best model with accuracy: 96.30%\n",
      "Finished training. Best accuracy: 96.30%\n"
     ]
    }
   ],
   "source": [
    "# 在替代数据集上训练替代模型\n",
    "print(\"开始训练替代模型...\")\n",
    "trained_substitute_model = train_substitute_model(\n",
    "    substitute_model=substitute_model,\n",
    "    substitute_dataset=substitute_dataset,\n",
    "    epochs=30,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们对窃取数据集上训练的模型进行评估："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  65.04 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(substitute_model, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，窃取模型攻击所获取的模型的测试准确率非常高（？），这样，攻击者就可以用极低的时间和训练成本来获取一个高质量的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 模型窃取防御\n",
    "## 2.1 信息模糊\n",
    "对模型的输出进行模糊：将输出向量限制为前k个类、将输出向量四舍五入、增加输出向量的信息熵、正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DefenseModel(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       "  (defense_layer): defense_layer()\n",
       ")"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最后一层只保留前 k 个值，并且四舍五入到第 d 位，以加大学习难度\n",
    "class defense_layer(nn.Module):\n",
    "    def __init__(self, k=5, d=2, tau=None):\n",
    "        super(defense_layer, self).__init__()\n",
    "        self.k = k\n",
    "        self.d = d\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 四舍五入到第 d 位\n",
    "        x = torch.round(x, decimals=self.d)\n",
    "        # 前 k 大位置的值保留，其余位置设为负无穷\n",
    "        indices = torch.topk(x, self.k, dim=1)[1]\n",
    "        new_x = torch.full_like(x, -float('inf'))        \n",
    "        for i in range(x.shape[0]):\n",
    "            new_x[i, indices[i]] = x[i, indices[i]]\n",
    "        if self.tau is not None:\n",
    "            new_x = new_x / self.tau\n",
    "        return new_x\n",
    "\n",
    "class DefenseModel(nn.Module):\n",
    "    def __init__(self, model, k=5, d=2, tau=None):\n",
    "        super(DefenseModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.defense_layer = defense_layer(k=k, d=d, tau=tau)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.defense_layer(x)\n",
    "        return x\n",
    "\n",
    "defense_model = DefenseModel(victim_model, k=3, d=1, tau=20).to(device)\n",
    "defense_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  93.45 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(defense_model, testloader), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying victim model: 100%|██████████| 47/47 [00:00<00:00, 222.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "替代数据集已保存至: substitute_dataset_defense_cifar10.pt\n",
      "数据集大小: 3000 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建查询集（使用CIFAR-10测试集的3000个样本）\n",
    "query_images = build_query_set(data_size=3000)\n",
    "\n",
    "# 创建替代数据集\n",
    "substitute_dataset_defense = create_substitute_dataset(\n",
    "    victim_model=defense_model,\n",
    "    query_images=query_images,\n",
    "    save_path=\"substitute_dataset_defense_cifar10.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute_model_defense = SubstituteModel(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练替代模型...\n",
      "Epoch 1/30 | Loss: 2.2583 | Acc: 17.07%\n",
      "Saved best model with accuracy: 17.07%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 | Loss: 2.1506 | Acc: 24.63%\n",
      "Saved best model with accuracy: 24.63%\n",
      "Epoch 3/30 | Loss: 2.1051 | Acc: 29.30%\n",
      "Saved best model with accuracy: 29.30%\n",
      "Epoch 4/30 | Loss: 2.0627 | Acc: 32.73%\n",
      "Saved best model with accuracy: 32.73%\n",
      "Epoch 5/30 | Loss: 2.0303 | Acc: 37.50%\n",
      "Saved best model with accuracy: 37.50%\n",
      "Epoch 6/30 | Loss: 2.0070 | Acc: 39.17%\n",
      "Saved best model with accuracy: 39.17%\n",
      "Epoch 7/30 | Loss: 1.9782 | Acc: 43.37%\n",
      "Saved best model with accuracy: 43.37%\n",
      "Epoch 8/30 | Loss: 1.9587 | Acc: 43.77%\n",
      "Saved best model with accuracy: 43.77%\n",
      "Epoch 9/30 | Loss: 1.9440 | Acc: 44.23%\n",
      "Saved best model with accuracy: 44.23%\n",
      "Epoch 10/30 | Loss: 1.9177 | Acc: 47.20%\n",
      "Saved best model with accuracy: 47.20%\n",
      "Epoch 11/30 | Loss: 1.8907 | Acc: 49.53%\n",
      "Saved best model with accuracy: 49.53%\n",
      "Epoch 12/30 | Loss: 1.8781 | Acc: 50.00%\n",
      "Saved best model with accuracy: 50.00%\n",
      "Epoch 13/30 | Loss: 1.8638 | Acc: 50.10%\n",
      "Saved best model with accuracy: 50.10%\n",
      "Epoch 14/30 | Loss: 1.8429 | Acc: 50.37%\n",
      "Saved best model with accuracy: 50.37%\n",
      "Epoch 15/30 | Loss: 1.8151 | Acc: 52.43%\n",
      "Saved best model with accuracy: 52.43%\n",
      "Epoch 16/30 | Loss: 1.7996 | Acc: 52.93%\n",
      "Saved best model with accuracy: 52.93%\n",
      "Epoch 17/30 | Loss: 1.7856 | Acc: 53.10%\n",
      "Saved best model with accuracy: 53.10%\n",
      "Epoch 18/30 | Loss: 1.7614 | Acc: 53.07%\n",
      "Epoch 19/30 | Loss: 1.7460 | Acc: 55.37%\n",
      "Saved best model with accuracy: 55.37%\n",
      "Epoch 20/30 | Loss: 1.7300 | Acc: 53.67%\n",
      "Epoch 21/30 | Loss: 1.7245 | Acc: 52.83%\n",
      "Epoch 22/30 | Loss: 1.6945 | Acc: 55.10%\n",
      "Epoch 23/30 | Loss: 1.6820 | Acc: 54.33%\n",
      "Epoch 24/30 | Loss: 1.6646 | Acc: 54.97%\n",
      "Epoch 25/30 | Loss: 1.6521 | Acc: 53.50%\n",
      "Epoch 26/30 | Loss: 1.6256 | Acc: 55.27%\n",
      "Epoch 27/30 | Loss: 1.6151 | Acc: 56.07%\n",
      "Saved best model with accuracy: 56.07%\n",
      "Epoch 28/30 | Loss: 1.5968 | Acc: 54.57%\n",
      "Epoch 29/30 | Loss: 1.5861 | Acc: 55.47%\n",
      "Epoch 30/30 | Loss: 1.5773 | Acc: 54.07%\n",
      "Finished training. Best accuracy: 56.07%\n"
     ]
    }
   ],
   "source": [
    "# 在模糊后的替代数据集上训练替代模型\n",
    "print(\"开始训练替代模型...\")\n",
    "trained_substitute_model_defense = train_substitute_model(\n",
    "    substitute_model=substitute_model_defense,\n",
    "    substitute_dataset=substitute_dataset_defense,\n",
    "    epochs=30,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  45.08 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(substitute_model_defense, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def perturb_prediction(outputs, confidence_threshold=0.58, temperature=1.75, device='cuda'):\n",
    "    \"\"\"\n",
    "    基于置信度对模型预测结果进行扰动，用于防御模型窃取攻击\n",
    "    \n",
    "    参数:\n",
    "        outputs: 模型原始输出logits (batch_size, num_classes)\n",
    "        confidence_threshold: 置信度阈值，低于此值的预测将被扰动\n",
    "        temperature: softmax温度参数，控制概率分布的平滑度\n",
    "        device: 计算设备\n",
    "        \n",
    "    返回:\n",
    "        扰动后的输出logits\n",
    "    \"\"\"\n",
    "    # 计算softmax概率和最大置信度\n",
    "    probs = F.softmax(outputs / temperature, dim=1)\n",
    "    max_probs, predicted = probs.max(1)\n",
    "    \n",
    "    # 识别需要扰动的低置信度样本\n",
    "    mask = max_probs < confidence_threshold\n",
    "    num_classes = outputs.size(1)\n",
    "    \n",
    "    # 打印低置信度样本比例（用于调试）\n",
    "    # print(f\"低置信度样本比例 ({confidence_threshold}): {(mask.sum()/len(mask)):.2%}\")\n",
    "    \n",
    "    # 如果没有低置信度样本，直接返回原始输出\n",
    "    if mask.sum() == 0:\n",
    "        # print(\"警告: 没有样本满足扰动条件，返回原始输出\")\n",
    "        return outputs\n",
    "    \n",
    "    # 对低置信度样本进行扰动\n",
    "    new_outputs = outputs.clone()\n",
    "    \n",
    "    # 为每个需要扰动的样本生成随机标签（确保与原预测不同）\n",
    "    for i in range(len(outputs)):\n",
    "        if mask[i]:\n",
    "            orig_pred = predicted[i].item()\n",
    "            # 生成一个不等于orig_pred的随机标签\n",
    "            candidates = [j for j in range(num_classes) if j != orig_pred]\n",
    "            random_label = candidates[torch.randint(0, len(candidates), (1,)).item()]\n",
    "            \n",
    "            # 应用扰动\n",
    "            new_outputs[i, orig_pred] -= 20.0  # 降低原预测分数\n",
    "            new_outputs[i, random_label] += 20.0  # 提高随机标签分数\n",
    "    \n",
    "    # 计算并打印扰动导致的预测变化率（用于调试）\n",
    "    orig_preds = outputs.argmax(dim=1)\n",
    "    new_preds = new_outputs.argmax(dim=1)\n",
    "    perturbation_effect = ((orig_preds != new_preds) & mask).float().mean().item()\n",
    "    # print(f\"实际扰动效果: {perturbation_effect:.2%} 的目标样本预测被改变\")\n",
    "    \n",
    "    return new_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute_model_output_perturbation_defense = SubstituteModel(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "<function perturb_prediction at 0x7f1232155ee0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying victim model: 100%|██████████| 47/47 [00:00<00:00, 243.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "扰动导致的预测变化率: 6.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "替代数据集已保存至: substitute_dataset_cifar10.pt\n",
      "数据集大小: 3000 样本\n"
     ]
    }
   ],
   "source": [
    "# 构建查询集（使用CIFAR-10测试集的3000个样本）\n",
    "query_images = build_query_set(data_size=3000)\n",
    "\n",
    "# 创建替代数据集\n",
    "substitute_dataset = create_substitute_dataset(\n",
    "    victim_model=victim_model,\n",
    "    query_images=query_images,\n",
    "    save_path=\"substitute_dataset_cifar10.pt\",\n",
    "    output_perturbation = perturb_prediction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练替代模型...\n",
      "Epoch 1/30 | Loss: 2.0972 | Acc: 26.47%\n",
      "Saved best model with accuracy: 26.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 | Loss: 1.8825 | Acc: 37.47%\n",
      "Saved best model with accuracy: 37.47%\n",
      "Epoch 3/30 | Loss: 1.7609 | Acc: 42.73%\n",
      "Saved best model with accuracy: 42.73%\n",
      "Epoch 4/30 | Loss: 1.6795 | Acc: 46.90%\n",
      "Saved best model with accuracy: 46.90%\n",
      "Epoch 5/30 | Loss: 1.6197 | Acc: 50.30%\n",
      "Saved best model with accuracy: 50.30%\n",
      "Epoch 6/30 | Loss: 1.5207 | Acc: 54.53%\n",
      "Saved best model with accuracy: 54.53%\n",
      "Epoch 7/30 | Loss: 1.4688 | Acc: 57.43%\n",
      "Saved best model with accuracy: 57.43%\n",
      "Epoch 8/30 | Loss: 1.4155 | Acc: 60.87%\n",
      "Saved best model with accuracy: 60.87%\n",
      "Epoch 9/30 | Loss: 1.3626 | Acc: 63.47%\n",
      "Saved best model with accuracy: 63.47%\n",
      "Epoch 10/30 | Loss: 1.3062 | Acc: 64.93%\n",
      "Saved best model with accuracy: 64.93%\n",
      "Epoch 11/30 | Loss: 1.2445 | Acc: 68.13%\n",
      "Saved best model with accuracy: 68.13%\n",
      "Epoch 12/30 | Loss: 1.1919 | Acc: 71.83%\n",
      "Saved best model with accuracy: 71.83%\n",
      "Epoch 13/30 | Loss: 1.1452 | Acc: 73.07%\n",
      "Saved best model with accuracy: 73.07%\n",
      "Epoch 14/30 | Loss: 1.0949 | Acc: 74.87%\n",
      "Saved best model with accuracy: 74.87%\n",
      "Epoch 15/30 | Loss: 1.0345 | Acc: 78.40%\n",
      "Saved best model with accuracy: 78.40%\n",
      "Epoch 16/30 | Loss: 0.9901 | Acc: 81.00%\n",
      "Saved best model with accuracy: 81.00%\n",
      "Epoch 17/30 | Loss: 0.9385 | Acc: 82.67%\n",
      "Saved best model with accuracy: 82.67%\n",
      "Epoch 18/30 | Loss: 0.9431 | Acc: 82.67%\n",
      "Epoch 19/30 | Loss: 0.9032 | Acc: 84.23%\n",
      "Saved best model with accuracy: 84.23%\n",
      "Epoch 20/30 | Loss: 0.8707 | Acc: 85.27%\n",
      "Saved best model with accuracy: 85.27%\n",
      "Epoch 21/30 | Loss: 0.8405 | Acc: 87.50%\n",
      "Saved best model with accuracy: 87.50%\n",
      "Epoch 22/30 | Loss: 0.8190 | Acc: 87.97%\n",
      "Saved best model with accuracy: 87.97%\n",
      "Epoch 23/30 | Loss: 0.8015 | Acc: 88.57%\n",
      "Saved best model with accuracy: 88.57%\n",
      "Epoch 24/30 | Loss: 0.7726 | Acc: 91.20%\n",
      "Saved best model with accuracy: 91.20%\n",
      "Epoch 25/30 | Loss: 0.7352 | Acc: 92.50%\n",
      "Saved best model with accuracy: 92.50%\n",
      "Epoch 26/30 | Loss: 0.7327 | Acc: 92.63%\n",
      "Saved best model with accuracy: 92.63%\n",
      "Epoch 27/30 | Loss: 0.7098 | Acc: 93.07%\n",
      "Saved best model with accuracy: 93.07%\n",
      "Epoch 28/30 | Loss: 0.6971 | Acc: 94.53%\n",
      "Saved best model with accuracy: 94.53%\n",
      "Epoch 29/30 | Loss: 0.6974 | Acc: 93.93%\n",
      "Epoch 30/30 | Loss: 0.6828 | Acc: 95.17%\n",
      "Saved best model with accuracy: 95.17%\n",
      "Finished training. Best accuracy: 95.17%\n"
     ]
    }
   ],
   "source": [
    "# 在替代数据集上训练替代模型\n",
    "print(\"开始训练替代模型...\")\n",
    "trained_substitute_model = train_substitute_model(\n",
    "    substitute_model=substitute_model_output_perturbation_defense,\n",
    "    substitute_dataset=substitute_dataset,\n",
    "    epochs=30,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  79.52 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(victim_model, testloader, perturbation=perturb_prediction), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  59.63 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(substitute_model_output_perturbation_defense, testloader), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
