{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 课程前言\n",
    "此为 <<人工智能安全>> 课程第四部分: 模型窃取攻击与防御实验部分.\n",
    "\n",
    "**模型窃取攻击**的目标是通过一定手段窃取得到一个跟 受害者模型 功能和性能近似的窃取模型，从而避开昂贵的模型训练并从中获益。\n",
    "\n",
    "<img src=\"./imgs/model steal.png\" alt=\"替代模型窃取攻击示意图\" style=\"height: 300px; max-width: 100%;\">\n",
    "\n",
    "上图为一个简单基础的模型窃取攻击过程，攻击者在黑盒环境下与受害者模型交互，获取模型的输入与输出，并不断调整查询样本来获取模型更多的决策边界信息。攻击者可以将此输入-输出作为数据集，对自己的模型进行模仿学习，得到一个与受害者模型相似的窃取模型。\n",
    "\n",
    "一般来说，模型窃取攻击的主要目标包括：\n",
    "1. 低代价：以远低于受害者模型训练成本的代价获得一个可免费使用的窃取模型；\n",
    "2. 高收益：窃取得到的模型与受害者模型的功能和性能相当；\n",
    "3. 低风险：在窃取过程中可以避开相关检测并在窃取后无法被溯源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 模型窃取攻击\n",
    "模型窃取攻击有多种方式：基于**方程式求解**的模型窃取攻击、基于**替代模型**的窃取攻击、基于**元模型**的窃取攻击。\n",
    "\n",
    "受篇幅影响，本次实验主要将基于替代模型的窃取攻击，有兴趣的同学可自行搜索学习其他类别的攻击方法。\n",
    "\n",
    "## 1.1 基于替代模型的窃取攻击\n",
    "攻击主要思路：攻击者 $A$ 在不知道受害者模型 $f(\\cdot)$ 任何先验知识情况下，向受害者模型输入查询样本 $x$ ，得到受害者模型的预测输出 $f(x)$ 。随后，攻击者根据输入和输出构建替代训练数据集 $\\mathcal D ' = {(x, f(x))}^m_{i=1}$ 。\n",
    "\n",
    "实际上，替代数据集已经完成了对袁术训练数据的（部分）提取。在替代数据集 $\\mathcal D'$ 上多次训练后，即可得到一个与受害者模型 $f(\\cdot)$ 功能和性质类似的替代模型 $f'(\\cdot)$ ，完成模型窃取攻击。\n",
    "\n",
    "<img src=\"./imgs/model steal2.png\" alt=\"替代模型窃取攻击示意图\" style=\"height: 400px; max-width: 100%;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了实现这样的模型窃取方法，我们首先需要加载受害者模型。\n",
    "\n",
    "（在实际中，模型窃取攻击者通常使用受害者API进行查询访问）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datasets\n",
    "\n",
    "import cifar_model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/\"\n",
    "model_list = [\n",
    "    \"cifar10_resnet18.pth\",\n",
    "    \"cifar10_model.pth\"\n",
    "]\n",
    "\n",
    "# 加载模型\n",
    "def load_model(model_path, num_classes, device):\n",
    "    # 加载模型结构\n",
    "    model = cifar_model.ResNet18(num_classes=num_classes)\n",
    "\n",
    "    # 加载模型权重\n",
    "    if device == 'cpu':\n",
    "        state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        state_dict = torch.load(model_path)\n",
    "    \n",
    "    # 加载权重到模型\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()  # 设置为评估模式\n",
    "\n",
    "    print(\"加载模型: \", model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载模型:  ./models/cifar10_resnet18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2354846/168071617.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "victim_model = load_model(model_path + model_list[0], num_classes=10, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对加载的受害者模型进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 加载CIFAR-10训练数据集\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_test)\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 加载CIFAR-10测试数据集\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "def test_model(model, dataloader, perturbation=None):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            if perturbation: outputs = perturbation(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    acc = 100.*correct/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  93.48 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(victim_model, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们作为攻击者，对受害者模型进行轮询访问，以获取其查询-预测对:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在有一个问题：攻击者如何获取用于查询的数据集？\n",
    "\n",
    "虽然在实际中，攻击者并不知道模型的任何先验知识，但是知道其功能是什么。举一个简单的例子：受害者模型是一个对猫狗的二分类问题，攻击者即可收集猫和狗的图像作为对模型的查询数据集。\n",
    "\n",
    "在本次实验中，受害者模型是一个10-分类问题，简单起见，我们直接对 cifar-10 公开数据集进行随机采样，以作为对受害者模型的查询数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query_set(dataset_name=\"cifar10\", data_size=10000, use_public_data=True):\n",
    "    \"\"\"构建用于查询受害者模型的数据集\"\"\"\n",
    "    if use_public_data:\n",
    "        if dataset_name == \"cifar10\":\n",
    "            query_dataset = trainset\n",
    "            \n",
    "            # 随机采样一部分数据\n",
    "            indices = np.random.choice(len(query_dataset), data_size, replace=False)\n",
    "            query_images = torch.stack([query_dataset[i][0] for i in indices])\n",
    "            return query_images\n",
    "    \n",
    "    else:\n",
    "        # 生成随机噪声数据\n",
    "        return torch.randn(data_size, 3, 32, 32) * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于是，我们便可以使用查询数据集对受害者模型进行轮询："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_victim_model(victim_model, query_images, batch_size=64, device='cuda', output_perturbation=None):\n",
    "    \"\"\"向受害者模型发送查询并收集预测结果\"\"\"\n",
    "    victim_model.to(device)\n",
    "    victim_model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    dataloader = DataLoader(query_images, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Querying victim model\"):\n",
    "            batch = batch.to(device)\n",
    "            outputs = victim_model(batch)\n",
    "\n",
    "            # 检查预测结果是否变化\n",
    "            _, orig_preds = torch.max(outputs, 1)\n",
    "\n",
    "            \n",
    "\n",
    "            if output_perturbation:\n",
    "                outputs = output_perturbation(outputs)\n",
    "                \n",
    "                _, pert_preds = torch.max(outputs, 1)\n",
    "            # 获取预测的类别\n",
    "            # _, predictions = torch.max(outputs, 1)\n",
    "            \n",
    "            # 返回受害者模型预测的概率分布\n",
    "            predictions = F.softmax(outputs, dim=1)\n",
    "            all_predictions.append(predictions.cpu())\n",
    "    \n",
    "    # 合并所有批次的预测概率分布\n",
    "    all_predictions = torch.cat(all_predictions)\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将获取到的查询-预测对构建成为替代数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubstituteDataset(Dataset):\n",
    "    def __init__(self, queries, predictions, transform=None):\n",
    "        self.queries = queries\n",
    "        self.predictions = predictions\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, prediction = self.queries[idx], self.predictions[idx]\n",
    "        \n",
    "        if isinstance(img, np.ndarray):\n",
    "            img = torch.tensor(img)\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, prediction\n",
    "\n",
    "def create_substitute_dataset(victim_model, query_images, save_path=\"substitute_dataset.pt\", augment=False, output_perturbation=None):\n",
    "    \"\"\"构建并保存替代数据集\"\"\"\n",
    "    print(output_perturbation)\n",
    "    # 查询受害者模型\n",
    "    predictions = query_victim_model(victim_model, query_images, output_perturbation=output_perturbation)\n",
    "\n",
    "    # # 定义数据增强\n",
    "    # train_transform = transforms.Compose([\n",
    "    #     transforms.ToPILImage(),\n",
    "    #     transforms.RandomCrop(32, padding=4),\n",
    "    #     transforms.RandomHorizontalFlip(),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    # ])\n",
    "    \n",
    "    # 创建替代数据集\n",
    "    substitute_dataset = SubstituteDataset(query_images, predictions, train_transform if augment else None)\n",
    "    \n",
    "    # 保存数据集\n",
    "    torch.save({\n",
    "        'queries': query_images,\n",
    "        'predictions': predictions\n",
    "    }, save_path)\n",
    "    \n",
    "    print(f\"替代数据集已保存至: {save_path}\")\n",
    "    print(f\"数据集大小: {len(substitute_dataset)} 样本\")\n",
    "    return substitute_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying victim model: 100%|██████████| 47/47 [00:00<00:00, 363.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "替代数据集已保存至: substitute_dataset_cifar10.pt\n",
      "数据集大小: 3000 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建查询集（使用CIFAR-10测试集的3000个样本）\n",
    "query_images = build_query_set(data_size=3000)\n",
    "\n",
    "# 创建替代数据集\n",
    "substitute_dataset = create_substitute_dataset(\n",
    "    victim_model=victim_model,\n",
    "    query_images=query_images,\n",
    "    save_path=\"substitute_dataset_cifar10.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来看一下替代数据集是什么样的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_CLASS_NAMES = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "def visualize_substitute_dataset(dataset, num_samples=5, class_names=CIFAR10_CLASS_NAMES):\n",
    "    \"\"\"可视化替代数据集中的样本\"\"\"\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, idx in enumerate(indices):\n",
    "        # image, label = dataset[idx]\n",
    "        image, prob = dataset[idx]\n",
    "        label = torch.argmax(prob).item()\n",
    "        # 反归一化以便显示\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "        image = image * np.array([0.2023, 0.1994, 0.2010]) + np.array([0.4914, 0.4822, 0.4465])\n",
    "        image = np.clip(image, 0, 1)\n",
    "        \n",
    "        # 获取类别名称\n",
    "        class_name = class_names[label] if label < len(class_names) else f\"Unknown ({label})\"\n",
    "        \n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Predicted: {class_name}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化样本\n",
    "visualize_substitute_dataset(substitute_dataset)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取替代数据集后，我们便可以对自己的模型进行训练了。\n",
    "\n",
    "作为攻击者，我们并不知道模型内部的架构，因此，我们需要自定义自己的模型架构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubstituteModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SubstituteModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 第一层卷积\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # 第二层卷积\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # 第三层卷积\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        \n",
    "        # 全连接分类器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute_model = SubstituteModel(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们使用窃取构建的数据集对模型进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两个概率分布之间的交叉熵损失函数\n",
    "def loss_ce(p, q):\n",
    "    # 这里的 p 和 q 是经过 softmax 后的概率分布\n",
    "    # 计算交叉熵损失\n",
    "    return -(q * p.log()).sum(dim=1).mean()  \n",
    "\n",
    "def train_substitute_model(substitute_model, substitute_dataset, epochs=50, batch_size=128, lr=0.001, device='cuda', model_name='substitute_model.pth'):\n",
    "    \"\"\"在替代数据集上训练替代模型\"\"\"\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(substitute_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    criterion = loss_ce\n",
    "    optimizer = optim.Adam(substitute_model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "    \n",
    "    # 训练循环\n",
    "    substitute_model.to(device)\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        substitute_model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            # 这里的 targets 是受害者模型关于这个 input 预测的概率分布\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = substitute_model(inputs)\n",
    "            # loss = criterion(outputs, targets)\n",
    "            # 根据受害者模型预测的概率分布计算损失\n",
    "            loss = criterion(F.softmax(outputs, dim=1), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            # correct += predicted.eq(targets).sum().item()\n",
    "            correct += (predicted == targets.argmax(dim=1)).sum().item()\n",
    "        \n",
    "        # 计算准确率和平均损失\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%')\n",
    "        \n",
    "        # 学习率调度\n",
    "        scheduler.step(epoch_loss)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            torch.save(substitute_model.state_dict(), model_name)\n",
    "            print(f'Saved best model with accuracy: {best_acc:.2f}%')\n",
    "    \n",
    "    print(f'Finished training. Best accuracy: {best_acc:.2f}%')\n",
    "    return substitute_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练替代模型...\n",
      "Epoch 1/20 | Loss: 2.0532 | Acc: 29.07%\n",
      "Saved best model with accuracy: 29.07%\n",
      "Epoch 2/20 | Loss: 1.7705 | Acc: 40.13%\n",
      "Saved best model with accuracy: 40.13%\n",
      "Epoch 3/20 | Loss: 1.6312 | Acc: 47.67%\n",
      "Saved best model with accuracy: 47.67%\n",
      "Epoch 4/20 | Loss: 1.5711 | Acc: 50.77%\n",
      "Saved best model with accuracy: 50.77%\n",
      "Epoch 5/20 | Loss: 1.4800 | Acc: 55.40%\n",
      "Saved best model with accuracy: 55.40%\n",
      "Epoch 6/20 | Loss: 1.3876 | Acc: 58.60%\n",
      "Saved best model with accuracy: 58.60%\n",
      "Epoch 7/20 | Loss: 1.3287 | Acc: 63.47%\n",
      "Saved best model with accuracy: 63.47%\n",
      "Epoch 8/20 | Loss: 1.2760 | Acc: 65.37%\n",
      "Saved best model with accuracy: 65.37%\n",
      "Epoch 9/20 | Loss: 1.2140 | Acc: 68.67%\n",
      "Saved best model with accuracy: 68.67%\n",
      "Epoch 10/20 | Loss: 1.1513 | Acc: 72.33%\n",
      "Saved best model with accuracy: 72.33%\n",
      "Epoch 11/20 | Loss: 1.1062 | Acc: 74.63%\n",
      "Saved best model with accuracy: 74.63%\n",
      "Epoch 12/20 | Loss: 1.0833 | Acc: 75.30%\n",
      "Saved best model with accuracy: 75.30%\n",
      "Epoch 13/20 | Loss: 1.0507 | Acc: 78.27%\n",
      "Saved best model with accuracy: 78.27%\n",
      "Epoch 14/20 | Loss: 0.9809 | Acc: 81.40%\n",
      "Saved best model with accuracy: 81.40%\n",
      "Epoch 15/20 | Loss: 0.9693 | Acc: 81.83%\n",
      "Saved best model with accuracy: 81.83%\n",
      "Epoch 16/20 | Loss: 0.9290 | Acc: 83.87%\n",
      "Saved best model with accuracy: 83.87%\n",
      "Epoch 17/20 | Loss: 0.9031 | Acc: 85.80%\n",
      "Saved best model with accuracy: 85.80%\n",
      "Epoch 18/20 | Loss: 0.8854 | Acc: 86.73%\n",
      "Saved best model with accuracy: 86.73%\n",
      "Epoch 19/20 | Loss: 0.8643 | Acc: 87.97%\n",
      "Saved best model with accuracy: 87.97%\n",
      "Epoch 20/20 | Loss: 0.8476 | Acc: 88.33%\n",
      "Saved best model with accuracy: 88.33%\n",
      "Finished training. Best accuracy: 88.33%\n"
     ]
    }
   ],
   "source": [
    "# 在替代数据集上训练替代模型\n",
    "print(\"开始训练替代模型...\")\n",
    "trained_substitute_model = train_substitute_model(\n",
    "    substitute_model=substitute_model,\n",
    "    substitute_dataset=substitute_dataset,\n",
    "    epochs=20,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们对窃取数据集上训练的模型进行评估："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  62.83 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(substitute_model, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，窃取模型攻击利用对受害者模型的少量查询，获取了表现“还可以”的模型，这样，攻击者就可以用极低的时间和训练成本来获取一个模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 模型窃取防御\n",
    "\n",
    "模型窃取防御的目的是让攻击者无法通过简单的查询就能获取模型输出分布/模型参数。\n",
    "\n",
    "一般来说，被窃取模型准确率越高，它们输出的信息分布就会过于精确，导致攻击者很容易获取到高质量的 输入-输出 对作为高质量数据集，进而通过高质量的数据集来训练出替代模型。\n",
    "\n",
    "模型窃取防御可以从这个方向出发，通过**模糊化技术**，例如模糊决策边界、模糊输入概率等等方式，对窃取攻击进行防御。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 信息模糊\n",
    "对受害者模型的**输出概率向量**进行模糊化操作，使得输出的向量包含更少、更粗糙的信息，从而增大窃取攻击的学习难度\n",
    "\n",
    "Shokri 等人在 2017 年提出了四种针对模型窃取的防御方法：\n",
    "1. **输出向量限制为前 k 个类**：极端情况下，模型只返回最大可能的类别标签\n",
    "2. **输出向量四舍五入**：将输出向量中的logits值保留 $d$ 位小数，随着 $d$ 值减小，模型泄露的信息也就越小\n",
    "3. **增加输出向量的信息熵**：向 softmax 层增加调节参数 $\\tau$ ，计算 $\\text{softmax}(z)=\\frac {e^{z_i/\\tau}}{\\sum\\limits_j e^{z_j/\\tau}}$ 。随着 $\\tau$ 的增大，输出向量变得更均匀，输出向量的熵增大，泄露的信息也就越少。\n",
    "4. **正则化**：避免模型因为过拟合学习到敏感的决策边界从而泄露敏感信息\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本次实验中，我们尝试前三种方法，即**限制为前 k 个类、输出向量四舍五入到 d 位、增加输出信息熵**来实验其防御效果。下面的代码定义了一层模型的“防御层”，并将其拼接至原模型的最后一层之后形成一个新模型，用于模糊模型的输出信息。而该操作不会影响模型的性能，因为模型预测的最大标签不会改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DefenseModel(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       "  (defense_layer): defense_layer()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class defense_layer(nn.Module):\n",
    "    \"\"\"\n",
    "    自定义一个简单的防御层，用于拼接到原受害者模型最后一层之后\n",
    "    pytorch 通过继承 nn.Module 来定义一个模型层，具体的细节可参考官方文档 `https://docs.pytorch.org/docs/stable/notes/modules.html`\n",
    "    该层只保留输出 x 中的前 k 个值，将每个值四舍五入到第 d 位，并且根据系数 tau 进行缩放（整体除以或乘 tau）\n",
    "    \"\"\"\n",
    "    def __init__(self, k=5, d=2, tau=None):\n",
    "        \"\"\"\n",
    "        __init__ 函数在定义该层时会被调用，用于初始化一些参数\n",
    "        用来初始化这个模型层的参数\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.d = d\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        forward 函数在模型计算（如model(input)）的时候会被调用\n",
    "        x 代表传入这一层的输入，该函数的 return 返回值代表 x 经过这一层之后的结果\n",
    "        在自定义模型层时需要定义\n",
    "        \"\"\"\n",
    "        # 四舍五入到第 d 位\n",
    "        x = torch.round(x, decimals=self.d)\n",
    "        # 前 k 大位置的值保留，其余位置设为负无穷\n",
    "        indices = torch.topk(x, self.k, dim=1)[1]\n",
    "        new_x = torch.full_like(x, -float('inf'))        \n",
    "        for i in range(x.shape[0]):\n",
    "            new_x[i, indices[i]] = x[i, indices[i]]\n",
    "        # 根据 tau 进行缩放\n",
    "        if self.tau is not None:\n",
    "            new_x = new_x / self.tau\n",
    "        return new_x\n",
    "\n",
    "class DefenseModel(nn.Module):\n",
    "    \"\"\"\n",
    "    定义一个防御模型，将受害者模型和防御层拼接在一起\n",
    "    该模型的 forward 函数会先调用受害者模型的 forward 函数，然后将输出传入防御层，再调用防御层的 forward 函数\n",
    "    \"\"\"\n",
    "    def __init__(self, model, k=5, d=2, tau=None):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.defense_layer = defense_layer(k=k, d=d, tau=tau)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.defense_layer(x)\n",
    "        return x\n",
    "\n",
    "defense_model = DefenseModel(victim_model, k=3, d=1, tau=20).to(device)\n",
    "defense_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  93.45 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(defense_model, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，新模型相比原受害者模型的性能几乎一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying victim model: 100%|██████████| 47/47 [00:00<00:00, 351.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "替代数据集已保存至: substitute_dataset_defense_cifar10.pt\n",
      "数据集大小: 3000 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建查询集（使用CIFAR-10测试集的3000个样本）\n",
    "query_images = build_query_set(data_size=3000)\n",
    "\n",
    "# 创建替代数据集\n",
    "substitute_dataset_defense = create_substitute_dataset(\n",
    "    victim_model=defense_model,\n",
    "    query_images=query_images,\n",
    "    save_path=\"substitute_dataset_defense_cifar10.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute_model_defense = SubstituteModel(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练替代模型...\n",
      "Epoch 1/20 | Loss: 2.2681 | Acc: 17.90%\n",
      "Saved best model with accuracy: 17.90%\n",
      "Epoch 2/20 | Loss: 2.1479 | Acc: 24.83%\n",
      "Saved best model with accuracy: 24.83%\n",
      "Epoch 3/20 | Loss: 2.0984 | Acc: 28.70%\n",
      "Saved best model with accuracy: 28.70%\n",
      "Epoch 4/20 | Loss: 2.0666 | Acc: 33.30%\n",
      "Saved best model with accuracy: 33.30%\n",
      "Epoch 5/20 | Loss: 2.0356 | Acc: 36.87%\n",
      "Saved best model with accuracy: 36.87%\n",
      "Epoch 6/20 | Loss: 2.0113 | Acc: 38.93%\n",
      "Saved best model with accuracy: 38.93%\n",
      "Epoch 7/20 | Loss: 1.9794 | Acc: 41.57%\n",
      "Saved best model with accuracy: 41.57%\n",
      "Epoch 8/20 | Loss: 1.9681 | Acc: 42.47%\n",
      "Saved best model with accuracy: 42.47%\n",
      "Epoch 9/20 | Loss: 1.9418 | Acc: 46.03%\n",
      "Saved best model with accuracy: 46.03%\n",
      "Epoch 10/20 | Loss: 1.9195 | Acc: 46.03%\n",
      "Epoch 11/20 | Loss: 1.8952 | Acc: 48.17%\n",
      "Saved best model with accuracy: 48.17%\n",
      "Epoch 12/20 | Loss: 1.8845 | Acc: 48.20%\n",
      "Saved best model with accuracy: 48.20%\n",
      "Epoch 13/20 | Loss: 1.8639 | Acc: 50.47%\n",
      "Saved best model with accuracy: 50.47%\n",
      "Epoch 14/20 | Loss: 1.8439 | Acc: 50.63%\n",
      "Saved best model with accuracy: 50.63%\n",
      "Epoch 15/20 | Loss: 1.8243 | Acc: 51.27%\n",
      "Saved best model with accuracy: 51.27%\n",
      "Epoch 16/20 | Loss: 1.8021 | Acc: 52.90%\n",
      "Saved best model with accuracy: 52.90%\n",
      "Epoch 17/20 | Loss: 1.7868 | Acc: 52.77%\n",
      "Epoch 18/20 | Loss: 1.7694 | Acc: 53.80%\n",
      "Saved best model with accuracy: 53.80%\n",
      "Epoch 19/20 | Loss: 1.7568 | Acc: 53.43%\n",
      "Epoch 20/20 | Loss: 1.7349 | Acc: 54.77%\n",
      "Saved best model with accuracy: 54.77%\n",
      "Finished training. Best accuracy: 54.77%\n"
     ]
    }
   ],
   "source": [
    "# 在模糊后的替代数据集上训练替代模型\n",
    "print(\"开始训练替代模型...\")\n",
    "trained_substitute_model_defense = train_substitute_model(\n",
    "    substitute_model=substitute_model_defense,\n",
    "    substitute_dataset=substitute_dataset_defense,\n",
    "    epochs=20,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时替代模型的训练准确率大幅下降，可见防御层干扰了替代模型的训练过程。我们来看看此时替代模型在测试集上的训练效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  41.07 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(substitute_model_defense, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，新训练的模型在测试集上的准确率有接近 $10\\%$ 的下降，可见防御层起到了一定的效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 模型置信度模糊\n",
    "除了取 top-k 的预测类别进行输出，模糊化输出外，防御者还可以通过对模型的logits层进行扰动操作，让模型的输出分布受到改变，进而让攻击者获取到低质量的数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里提供一种方法：根据带温度的softmax来计算每个类别的概率分布，对于某些类别，它的最高概率若不达到阈值，则看作低置信度样本，对其扰动。\n",
    "\n",
    "扰动策略：\n",
    "1. 选择一个与原预测不同的随机类别。\n",
    "2. 将原预测类别的logits缩放（如0.5%）。\n",
    "3. 将随机选择的类别logits放大10倍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def perturb_prediction(outputs, confidence_threshold=0.60, temperature=1.75):\n",
    "    \"\"\"\n",
    "    基于置信度对模型预测结果进行扰动, 首先是用softmax和温度来计算预测概率分布\n",
    "    , 找出置信度(最大预测概率)低于阈值confidence_threshold的样本, 这些样本属于不易学习的样本.\n",
    "    对这些硬样本进行输出logits层的扰动, 模型原预测类别的logits值降低(如0.5%), 提高随机类别的logits\n",
    "    值(如10倍)。\n",
    "    \n",
    "    参数:\n",
    "        outputs: 模型原始输出logits (batch_size, num_classes)\n",
    "        confidence_threshold: 置信度阈值，低于此值的预测将被扰动\n",
    "        temperature: softmax温度参数，控制概率分布的平滑度\n",
    "        device: 计算设备\n",
    "        \n",
    "    返回:\n",
    "        扰动后的输出logits\n",
    "    \"\"\"\n",
    "    # 计算softmax概率和最大置信度\n",
    "    probs = F.softmax(outputs / temperature, dim=1)\n",
    "    max_probs, predicted = probs.max(1)\n",
    "    \n",
    "    # 识别需要扰动的低置信度样本\n",
    "    mask = max_probs < confidence_threshold\n",
    "    num_classes = outputs.size(1)\n",
    "    \n",
    "    # print(f\"低置信度样本比例 ({confidence_threshold}): {(mask.sum()/len(mask)):.2%}\")\n",
    "    \n",
    "    # 如果没有低置信度样本，直接返回原始输出\n",
    "    if mask.sum() == 0:\n",
    "        return outputs\n",
    "    \n",
    "    # 对低置信度样本进行扰动\n",
    "    new_outputs = outputs.clone()\n",
    "    \n",
    "    # 为每个需要扰动的样本生成随机标签（确保与原预测不同）\n",
    "    for i in range(len(outputs)):\n",
    "        if mask[i]:\n",
    "            orig_pred = predicted[i].item()\n",
    "            # 生成一个不等于orig_pred的随机标签\n",
    "            candidates = [j for j in range(num_classes) if j != orig_pred]\n",
    "            random_label = candidates[torch.randint(0, len(candidates), (1,)).item()]\n",
    "            \n",
    "            # 应用扰动\n",
    "            new_outputs[i, orig_pred] *= 0.005  # 降低原预测logits分数\n",
    "            new_outputs[i, random_label] *= 10  # 提高随机标签logits分数\n",
    "    \n",
    "    return new_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个输出扰动的策略下，我们对受害者模型进行输入-输出数据集的窃取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "<function perturb_prediction at 0x7f6fd4137c10>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying victim model: 100%|██████████| 47/47 [00:00<00:00, 268.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "替代数据集已保存至: substitute_dataset_cifar10.pt\n",
      "数据集大小: 3000 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建查询集（使用CIFAR-10测试集的3000个样本）\n",
    "query_images = build_query_set(data_size=3000)\n",
    "\n",
    "# 创建替代数据集\n",
    "substitute_dataset = create_substitute_dataset(\n",
    "    victim_model=victim_model,\n",
    "    query_images=query_images,\n",
    "    save_path=\"substitute_dataset_cifar10.pt\",\n",
    "    # output_perturbation = perturb_prediction\n",
    "    output_perturbation=perturb_prediction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在这个受到输出扰动的数据集上，对替代模型进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute_model_output_perturbation_defense = SubstituteModel(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练替代模型...\n",
      "Epoch 1/20 | Loss: 2.3503 | Acc: 21.07%\n",
      "Saved best model with accuracy: 21.07%\n",
      "Epoch 2/20 | Loss: 2.2630 | Acc: 32.07%\n",
      "Saved best model with accuracy: 32.07%\n",
      "Epoch 3/20 | Loss: 2.2269 | Acc: 35.43%\n",
      "Saved best model with accuracy: 35.43%\n",
      "Epoch 4/20 | Loss: 2.2060 | Acc: 37.63%\n",
      "Saved best model with accuracy: 37.63%\n",
      "Epoch 5/20 | Loss: 2.1768 | Acc: 41.80%\n",
      "Saved best model with accuracy: 41.80%\n",
      "Epoch 6/20 | Loss: 2.1551 | Acc: 43.87%\n",
      "Saved best model with accuracy: 43.87%\n",
      "Epoch 7/20 | Loss: 2.1396 | Acc: 45.87%\n",
      "Saved best model with accuracy: 45.87%\n",
      "Epoch 8/20 | Loss: 2.1132 | Acc: 48.27%\n",
      "Saved best model with accuracy: 48.27%\n",
      "Epoch 9/20 | Loss: 2.0885 | Acc: 50.57%\n",
      "Saved best model with accuracy: 50.57%\n",
      "Epoch 10/20 | Loss: 2.0657 | Acc: 52.70%\n",
      "Saved best model with accuracy: 52.70%\n",
      "Epoch 11/20 | Loss: 2.0513 | Acc: 52.93%\n",
      "Saved best model with accuracy: 52.93%\n",
      "Epoch 12/20 | Loss: 2.0257 | Acc: 55.87%\n",
      "Saved best model with accuracy: 55.87%\n",
      "Epoch 13/20 | Loss: 2.0151 | Acc: 55.50%\n",
      "Epoch 14/20 | Loss: 1.9884 | Acc: 57.20%\n",
      "Saved best model with accuracy: 57.20%\n",
      "Epoch 15/20 | Loss: 1.9828 | Acc: 57.40%\n",
      "Saved best model with accuracy: 57.40%\n",
      "Epoch 16/20 | Loss: 1.9585 | Acc: 58.53%\n",
      "Saved best model with accuracy: 58.53%\n",
      "Epoch 17/20 | Loss: 1.9392 | Acc: 58.77%\n",
      "Saved best model with accuracy: 58.77%\n",
      "Epoch 18/20 | Loss: 1.9339 | Acc: 60.33%\n",
      "Saved best model with accuracy: 60.33%\n",
      "Epoch 19/20 | Loss: 1.9022 | Acc: 59.47%\n",
      "Epoch 20/20 | Loss: 1.8980 | Acc: 59.87%\n",
      "Finished training. Best accuracy: 60.33%\n"
     ]
    }
   ],
   "source": [
    "# 在替代数据集上训练替代模型\n",
    "print(\"开始训练替代模型...\")\n",
    "trained_substitute_model = train_substitute_model(\n",
    "    substitute_model=substitute_model_output_perturbation_defense,\n",
    "    substitute_dataset=substitute_dataset,\n",
    "    epochs=20,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试受害者模型和替代模型的性能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  85.1 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(victim_model, testloader, perturbation=perturb_prediction), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  50.82 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(substitute_model_output_perturbation_defense, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现受害者模型的准确率会因为logits层输出扰动而受到一定影响，但是攻击者所训练出的替代模型也会受到较大影响，较好地实现了在受害者模型性能影响不高的情况下，对模型安全性的保障。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
