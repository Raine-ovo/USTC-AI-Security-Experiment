{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 课程前言\n",
    "此为 <<人工智能安全>> 课程第四部分: 模型窃取攻击与防御实验部分.\n",
    "\n",
    "**模型窃取攻击**的目标是通过一定手段窃取得到一个跟 受害者模型 功能和性能近似的窃取模型，从而避开昂贵的模型训练并从中获益。\n",
    "\n",
    "<img src=\"./imgs/model steal.png\" alt=\"替代模型窃取攻击示意图\" style=\"height: 300px; max-width: 100%;\">\n",
    "\n",
    "上图为一个简单基础的模型窃取攻击过程，攻击者在黑盒环境下与受害者模型交互，获取模型的输入与输出，并不断调整查询样本来获取模型更多的决策边界信息。攻击者可以将此输入-输出作为数据集，对自己的模型进行模仿学习，得到一个与受害者模型相似的窃取模型。\n",
    "\n",
    "一般来说，模型窃取攻击的主要目标包括：\n",
    "1. 低代价：以远低于受害者模型训练成本的代价获得一个可免费使用的窃取模型；\n",
    "2. 高收益：窃取得到的模型与受害者模型的功能和性能相当；\n",
    "3. 低风险：在窃取过程中可以避开相关检测并在窃取后无法被溯源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 模型窃取攻击\n",
    "模型窃取攻击有多种方式：基于**方程式求解**的模型窃取攻击、基于**替代模型**的窃取攻击、基于**元模型**的窃取攻击。\n",
    "\n",
    "受篇幅影响，本次实验主要将基于替代模型的窃取攻击，有兴趣的同学可自行搜索学习其他类别的攻击方法。\n",
    "\n",
    "## 1.1 基于替代模型的窃取攻击\n",
    "攻击主要思路：攻击者 $A$ 在不知道受害者模型 $f(\\cdot)$ 任何先验知识情况下，向受害者模型输入查询样本 $x$ ，得到受害者模型的预测输出 $f(x)$ 。随后，攻击者根据输入和输出构建替代训练数据集 $\\mathcal D ' = {(x, f(x))}^m_{i=1}$ 。\n",
    "\n",
    "实际上，替代数据集已经完成了对袁术训练数据的（部分）提取。在替代数据集 $\\mathcal D'$ 上多次训练后，即可得到一个与受害者模型 $f(\\cdot)$ 功能和性质类似的替代模型 $f'(\\cdot)$ ，完成模型窃取攻击。\n",
    "\n",
    "<img src=\"./imgs/model steal2.png\" alt=\"替代模型窃取攻击示意图\" style=\"height: 400px; max-width: 100%;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了实现这样的模型窃取方法，我们首先需要加载受害者模型。\n",
    "\n",
    "（在实际中，模型窃取攻击者通常使用受害者API进行查询访问）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datasets\n",
    "\n",
    "import cifar_model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/\"\n",
    "model_list = [\n",
    "    \"cifar10_resnet18.pth\",\n",
    "    \"cifar10_model.pth\"\n",
    "]\n",
    "\n",
    "# 加载模型\n",
    "def load_model(model_path, num_classes, device):\n",
    "    # 加载模型结构\n",
    "    model = cifar_model.ResNet18(num_classes=num_classes)\n",
    "\n",
    "    # 加载模型权重\n",
    "    if device == 'cpu':\n",
    "        state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        state_dict = torch.load(model_path)\n",
    "    \n",
    "    # 加载权重到模型\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()  # 设置为评估模式\n",
    "\n",
    "    print(\"加载模型: \", model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载模型:  ./models/cifar10_resnet18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2143088/168071617.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "victim_model = load_model(model_path + model_list[0], num_classes=10, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对加载的受害者模型进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 加载CIFAR-10训练数据集\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_test)\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 加载CIFAR-10测试数据集\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "def test_model(model, dataloader, perturbation=None):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            if perturbation: outputs = perturbation(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    acc = 100.*correct/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  93.48 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(victim_model, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们作为攻击者，对受害者模型进行轮询访问，以获取其查询-预测对:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在有一个问题：攻击者如何获取用于查询的数据集？\n",
    "\n",
    "虽然在实际中，攻击者并不知道模型的任何先验知识，但是知道其功能是什么。举一个简单的例子：受害者模型是一个对猫狗的二分类问题，攻击者即可收集猫和狗的图像作为对模型的查询数据集。\n",
    "\n",
    "在本次实验中，受害者模型是一个10-分类问题，简单起见，我们直接对 cifar-10 公开数据集进行随机采样，以作为对受害者模型的查询数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query_set(dataset_name=\"cifar10\", data_size=10000, use_public_data=True):\n",
    "    \"\"\"构建用于查询受害者模型的数据集\"\"\"\n",
    "    if use_public_data:\n",
    "        if dataset_name == \"cifar10\":\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "            query_dataset = torchvision.datasets.CIFAR10(\n",
    "                root='./data', train=True, download=True, transform=transform)\n",
    "            \n",
    "            # 随机采样一部分数据\n",
    "            indices = np.random.choice(len(query_dataset), data_size, replace=False)\n",
    "            query_images = torch.stack([query_dataset[i][0] for i in indices])\n",
    "            return query_images\n",
    "    \n",
    "    else:\n",
    "        # 生成随机噪声数据\n",
    "        return torch.randn(data_size, 3, 32, 32) * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于是，我们便可以使用查询数据集对受害者模型进行轮询："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_victim_model(victim_model, query_images, batch_size=64, device='cuda', output_perturbation=None):\n",
    "    \"\"\"向受害者模型发送查询并收集预测结果\"\"\"\n",
    "    victim_model.to(device)\n",
    "    victim_model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    dataloader = DataLoader(query_images, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Querying victim model\"):\n",
    "            batch = batch.to(device)\n",
    "            outputs = victim_model(batch)\n",
    "\n",
    "            # 检查预测结果是否变化\n",
    "            _, orig_preds = torch.max(outputs, 1)\n",
    "\n",
    "            \n",
    "\n",
    "            if output_perturbation:\n",
    "                outputs = output_perturbation(outputs)\n",
    "                \n",
    "                _, pert_preds = torch.max(outputs, 1)\n",
    "            # 获取预测的类别\n",
    "            # _, predictions = torch.max(outputs, 1)\n",
    "            \n",
    "            # 返回受害者模型预测的概率分布\n",
    "            predictions = F.softmax(outputs, dim=1)\n",
    "            all_predictions.append(predictions.cpu())\n",
    "    \n",
    "    # 合并所有批次的预测结果\n",
    "    all_predictions = torch.cat(all_predictions)\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将获取到的查询-预测对构建成为替代数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubstituteDataset(Dataset):\n",
    "    def __init__(self, queries, predictions, transform=None):\n",
    "        self.queries = queries\n",
    "        self.predictions = predictions\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, prediction = self.queries[idx], self.predictions[idx]\n",
    "        \n",
    "        if isinstance(img, np.ndarray):\n",
    "            img = torch.tensor(img)\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, prediction\n",
    "\n",
    "def create_substitute_dataset(victim_model, query_images, save_path=\"substitute_dataset.pt\", augment=False, output_perturbation=None):\n",
    "    \"\"\"构建并保存替代数据集\"\"\"\n",
    "    print(output_perturbation)\n",
    "    # 查询受害者模型\n",
    "    predictions = query_victim_model(victim_model, query_images, output_perturbation=output_perturbation)\n",
    "\n",
    "    # # 定义数据增强\n",
    "    # train_transform = transforms.Compose([\n",
    "    #     transforms.ToPILImage(),\n",
    "    #     transforms.RandomCrop(32, padding=4),\n",
    "    #     transforms.RandomHorizontalFlip(),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    # ])\n",
    "    \n",
    "    # 创建替代数据集\n",
    "    substitute_dataset = SubstituteDataset(query_images, predictions, train_transform if augment else None)\n",
    "    \n",
    "    # 保存数据集\n",
    "    torch.save({\n",
    "        'queries': query_images,\n",
    "        'predictions': predictions\n",
    "    }, save_path)\n",
    "    \n",
    "    print(f\"替代数据集已保存至: {save_path}\")\n",
    "    print(f\"数据集大小: {len(substitute_dataset)} 样本\")\n",
    "    return substitute_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying victim model: 100%|██████████| 47/47 [00:00<00:00, 339.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "替代数据集已保存至: substitute_dataset_cifar10.pt\n",
      "数据集大小: 3000 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建查询集（使用CIFAR-10测试集的3000个样本）\n",
    "query_images = build_query_set(data_size=3000)\n",
    "\n",
    "# 创建替代数据集\n",
    "substitute_dataset = create_substitute_dataset(\n",
    "    victim_model=victim_model,\n",
    "    query_images=query_images,\n",
    "    save_path=\"substitute_dataset_cifar10.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来看一下替代数据集是什么样的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_CLASS_NAMES = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "def visualize_substitute_dataset(dataset, num_samples=5, class_names=CIFAR10_CLASS_NAMES):\n",
    "    \"\"\"可视化替代数据集中的样本，显示类别名称而非数字\"\"\"\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, idx in enumerate(indices):\n",
    "        # image, label = dataset[idx]\n",
    "        image, prob = dataset[idx]\n",
    "        label = torch.argmax(prob).item()\n",
    "        # 反归一化以便显示\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "        image = image * np.array([0.2023, 0.1994, 0.2010]) + np.array([0.4914, 0.4822, 0.4465])\n",
    "        image = np.clip(image, 0, 1)\n",
    "        \n",
    "        # 获取类别名称\n",
    "        class_name = class_names[label] if label < len(class_names) else f\"Unknown ({label})\"\n",
    "        \n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Predicted: {class_name}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化样本\n",
    "visualize_substitute_dataset(substitute_dataset)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取替代数据集后，我们便可以对自己的模型进行训练了。\n",
    "\n",
    "作为攻击者，我们并不知道模型内部的架构，因此，我们需要自定义自己的模型架构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubstituteModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SubstituteModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 第一层卷积\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # 第二层卷积\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # 第三层卷积\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        \n",
    "        # 全连接分类器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute_model = SubstituteModel(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们使用窃取构建的数据集对模型进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两个概率分布之间的交叉熵损失函数\n",
    "def loss_ce(p, q):\n",
    "    # 这里的 p 和 q 是经过 softmax 后的概率分布\n",
    "    # 计算交叉熵损失\n",
    "    return -(q * p.log()).sum(dim=1).mean()  \n",
    "\n",
    "def train_substitute_model(substitute_model, substitute_dataset, epochs=50, batch_size=128, lr=0.001, device='cuda', model_name='substitute_model.pth'):\n",
    "    \"\"\"在替代数据集上训练替代模型\"\"\"\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(substitute_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    criterion = loss_ce\n",
    "    optimizer = optim.Adam(substitute_model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "    \n",
    "    # 训练循环\n",
    "    substitute_model.to(device)\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        substitute_model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = substitute_model(inputs)\n",
    "            # loss = criterion(outputs, targets)\n",
    "            loss = criterion(F.softmax(outputs, dim=1), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            # correct += predicted.eq(targets).sum().item()\n",
    "            correct += (predicted == targets.argmax(dim=1)).sum().item()\n",
    "        \n",
    "        # 计算准确率和平均损失\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%')\n",
    "        \n",
    "        # 学习率调度\n",
    "        scheduler.step(epoch_loss)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            torch.save(substitute_model.state_dict(), model_name)\n",
    "            print(f'Saved best model with accuracy: {best_acc:.2f}%')\n",
    "    \n",
    "    print(f'Finished training. Best accuracy: {best_acc:.2f}%')\n",
    "    return substitute_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练替代模型...\n",
      "Epoch 1/20 | Loss: 2.0623 | Acc: 26.87%\n",
      "Saved best model with accuracy: 26.87%\n",
      "Epoch 2/20 | Loss: 1.7594 | Acc: 41.90%\n",
      "Saved best model with accuracy: 41.90%\n",
      "Epoch 3/20 | Loss: 1.6139 | Acc: 48.83%\n",
      "Saved best model with accuracy: 48.83%\n",
      "Epoch 4/20 | Loss: 1.5178 | Acc: 54.23%\n",
      "Saved best model with accuracy: 54.23%\n",
      "Epoch 5/20 | Loss: 1.4545 | Acc: 56.67%\n",
      "Saved best model with accuracy: 56.67%\n",
      "Epoch 6/20 | Loss: 1.3683 | Acc: 60.97%\n",
      "Saved best model with accuracy: 60.97%\n",
      "Epoch 7/20 | Loss: 1.3148 | Acc: 64.40%\n",
      "Saved best model with accuracy: 64.40%\n",
      "Epoch 8/20 | Loss: 1.2672 | Acc: 67.00%\n",
      "Saved best model with accuracy: 67.00%\n",
      "Epoch 9/20 | Loss: 1.2154 | Acc: 69.60%\n",
      "Saved best model with accuracy: 69.60%\n",
      "Epoch 10/20 | Loss: 1.1509 | Acc: 72.37%\n",
      "Saved best model with accuracy: 72.37%\n",
      "Epoch 11/20 | Loss: 1.0993 | Acc: 76.17%\n",
      "Saved best model with accuracy: 76.17%\n",
      "Epoch 12/20 | Loss: 1.0587 | Acc: 77.63%\n",
      "Saved best model with accuracy: 77.63%\n",
      "Epoch 13/20 | Loss: 1.0350 | Acc: 79.90%\n",
      "Saved best model with accuracy: 79.90%\n",
      "Epoch 14/20 | Loss: 0.9758 | Acc: 81.53%\n",
      "Saved best model with accuracy: 81.53%\n",
      "Epoch 15/20 | Loss: 0.9417 | Acc: 83.87%\n",
      "Saved best model with accuracy: 83.87%\n",
      "Epoch 16/20 | Loss: 0.9164 | Acc: 85.13%\n",
      "Saved best model with accuracy: 85.13%\n",
      "Epoch 17/20 | Loss: 0.8977 | Acc: 86.37%\n",
      "Saved best model with accuracy: 86.37%\n",
      "Epoch 18/20 | Loss: 0.8699 | Acc: 87.60%\n",
      "Saved best model with accuracy: 87.60%\n",
      "Epoch 19/20 | Loss: 0.8479 | Acc: 89.00%\n",
      "Saved best model with accuracy: 89.00%\n",
      "Epoch 20/20 | Loss: 0.8232 | Acc: 89.40%\n",
      "Saved best model with accuracy: 89.40%\n",
      "Finished training. Best accuracy: 89.40%\n"
     ]
    }
   ],
   "source": [
    "# 在替代数据集上训练替代模型\n",
    "print(\"开始训练替代模型...\")\n",
    "trained_substitute_model = train_substitute_model(\n",
    "    substitute_model=substitute_model,\n",
    "    substitute_dataset=substitute_dataset,\n",
    "    epochs=20,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们对窃取数据集上训练的模型进行评估："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  61.13 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(substitute_model, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，窃取模型攻击所获取的模型的测试准确率较高（？），这样，攻击者就可以用极低的时间和训练成本来获取一个高质量的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 模型窃取防御\n",
    "## 2.1 信息模糊\n",
    "对模型的输出进行模糊：将输出向量限制为前k个类、将输出向量四舍五入、增加输出向量的信息熵、正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DefenseModel(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       "  (defense_layer): defense_layer()\n",
       ")"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最后一层只保留前 k 个值，并且四舍五入到第 d 位，以加大学习难度\n",
    "class defense_layer(nn.Module):\n",
    "    def __init__(self, k=5, d=2, tau=None):\n",
    "        super(defense_layer, self).__init__()\n",
    "        self.k = k\n",
    "        self.d = d\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 四舍五入到第 d 位\n",
    "        x = torch.round(x, decimals=self.d)\n",
    "        # 前 k 大位置的值保留，其余位置设为负无穷\n",
    "        indices = torch.topk(x, self.k, dim=1)[1]\n",
    "        new_x = torch.full_like(x, -float('inf'))        \n",
    "        for i in range(x.shape[0]):\n",
    "            new_x[i, indices[i]] = x[i, indices[i]]\n",
    "        if self.tau is not None:\n",
    "            new_x = new_x / self.tau\n",
    "        return new_x\n",
    "\n",
    "class DefenseModel(nn.Module):\n",
    "    def __init__(self, model, k=5, d=2, tau=None):\n",
    "        super(DefenseModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.defense_layer = defense_layer(k=k, d=d, tau=tau)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.defense_layer(x)\n",
    "        return x\n",
    "\n",
    "defense_model = DefenseModel(victim_model, k=3, d=1, tau=20).to(device)\n",
    "defense_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  93.45 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(defense_model, testloader), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying victim model: 100%|██████████| 47/47 [00:00<00:00, 224.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "替代数据集已保存至: substitute_dataset_defense_cifar10.pt\n",
      "数据集大小: 3000 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建查询集（使用CIFAR-10测试集的3000个样本）\n",
    "query_images = build_query_set(data_size=3000)\n",
    "\n",
    "# 创建替代数据集\n",
    "substitute_dataset_defense = create_substitute_dataset(\n",
    "    victim_model=defense_model,\n",
    "    query_images=query_images,\n",
    "    save_path=\"substitute_dataset_defense_cifar10.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute_model_defense = SubstituteModel(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练替代模型...\n",
      "Epoch 1/20 | Loss: 2.2657 | Acc: 17.60%\n",
      "Saved best model with accuracy: 17.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Loss: 2.1661 | Acc: 22.93%\n",
      "Saved best model with accuracy: 22.93%\n",
      "Epoch 3/20 | Loss: 2.1197 | Acc: 30.13%\n",
      "Saved best model with accuracy: 30.13%\n",
      "Epoch 4/20 | Loss: 2.0728 | Acc: 32.77%\n",
      "Saved best model with accuracy: 32.77%\n",
      "Epoch 5/20 | Loss: 2.0416 | Acc: 35.93%\n",
      "Saved best model with accuracy: 35.93%\n",
      "Epoch 6/20 | Loss: 2.0181 | Acc: 36.87%\n",
      "Saved best model with accuracy: 36.87%\n",
      "Epoch 7/20 | Loss: 1.9953 | Acc: 40.50%\n",
      "Saved best model with accuracy: 40.50%\n",
      "Epoch 8/20 | Loss: 1.9770 | Acc: 42.60%\n",
      "Saved best model with accuracy: 42.60%\n",
      "Epoch 9/20 | Loss: 1.9476 | Acc: 44.10%\n",
      "Saved best model with accuracy: 44.10%\n",
      "Epoch 10/20 | Loss: 1.9289 | Acc: 47.27%\n",
      "Saved best model with accuracy: 47.27%\n",
      "Epoch 11/20 | Loss: 1.8973 | Acc: 48.50%\n",
      "Saved best model with accuracy: 48.50%\n",
      "Epoch 12/20 | Loss: 1.8885 | Acc: 48.03%\n",
      "Epoch 13/20 | Loss: 1.8746 | Acc: 49.23%\n",
      "Saved best model with accuracy: 49.23%\n",
      "Epoch 14/20 | Loss: 1.8599 | Acc: 51.93%\n",
      "Saved best model with accuracy: 51.93%\n",
      "Epoch 15/20 | Loss: 1.8295 | Acc: 51.43%\n",
      "Epoch 16/20 | Loss: 1.8205 | Acc: 50.80%\n",
      "Epoch 17/20 | Loss: 1.8030 | Acc: 53.53%\n",
      "Saved best model with accuracy: 53.53%\n",
      "Epoch 18/20 | Loss: 1.7748 | Acc: 52.80%\n",
      "Epoch 19/20 | Loss: 1.7577 | Acc: 54.67%\n",
      "Saved best model with accuracy: 54.67%\n",
      "Epoch 20/20 | Loss: 1.7500 | Acc: 54.47%\n",
      "Finished training. Best accuracy: 54.67%\n"
     ]
    }
   ],
   "source": [
    "# 在模糊后的替代数据集上训练替代模型\n",
    "print(\"开始训练替代模型...\")\n",
    "trained_substitute_model_defense = train_substitute_model(\n",
    "    substitute_model=substitute_model_defense,\n",
    "    substitute_dataset=substitute_dataset_defense,\n",
    "    epochs=20,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  47.69 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(substitute_model_defense, testloader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def perturb_prediction(outputs, confidence_threshold=0.60, temperature=1.75, device='cuda'):\n",
    "    \"\"\"\n",
    "    基于置信度对模型预测结果进行扰动，用于防御模型窃取攻击\n",
    "    \n",
    "    参数:\n",
    "        outputs: 模型原始输出logits (batch_size, num_classes)\n",
    "        confidence_threshold: 置信度阈值，低于此值的预测将被扰动\n",
    "        temperature: softmax温度参数，控制概率分布的平滑度\n",
    "        device: 计算设备\n",
    "        \n",
    "    返回:\n",
    "        扰动后的输出logits\n",
    "    \"\"\"\n",
    "    # 计算softmax概率和最大置信度\n",
    "    probs = F.softmax(outputs / temperature, dim=1)\n",
    "    max_probs, predicted = probs.max(1)\n",
    "    \n",
    "    # 识别需要扰动的低置信度样本\n",
    "    mask = max_probs < confidence_threshold\n",
    "    num_classes = outputs.size(1)\n",
    "    \n",
    "    # print(f\"低置信度样本比例 ({confidence_threshold}): {(mask.sum()/len(mask)):.2%}\")\n",
    "    \n",
    "    # 如果没有低置信度样本，直接返回原始输出\n",
    "    if mask.sum() == 0:\n",
    "        return outputs\n",
    "    \n",
    "    # 对低置信度样本进行扰动\n",
    "    new_outputs = outputs.clone()\n",
    "    \n",
    "    # 为每个需要扰动的样本生成随机标签（确保与原预测不同）\n",
    "    for i in range(len(outputs)):\n",
    "        if mask[i]:\n",
    "            orig_pred = predicted[i].item()\n",
    "            # 生成一个不等于orig_pred的随机标签\n",
    "            candidates = [j for j in range(num_classes) if j != orig_pred]\n",
    "            random_label = candidates[torch.randint(0, len(candidates), (1,)).item()]\n",
    "            \n",
    "            # 应用扰动\n",
    "            new_outputs[i, orig_pred] -= 20.0  # 降低原预测分数\n",
    "            new_outputs[i, random_label] += 20.0  # 提高随机标签分数\n",
    "    \n",
    "    # 计算并打印扰动导致的预测变化率（用于调试）\n",
    "    orig_preds = outputs.argmax(dim=1)\n",
    "    new_preds = new_outputs.argmax(dim=1)\n",
    "    \n",
    "    return new_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "<function perturb_prediction at 0x7f122dfecf70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying victim model: 100%|██████████| 47/47 [00:00<00:00, 155.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "替代数据集已保存至: substitute_dataset_cifar10.pt\n",
      "数据集大小: 3000 样本\n"
     ]
    }
   ],
   "source": [
    "# 构建查询集（使用CIFAR-10测试集的3000个样本）\n",
    "query_images = build_query_set(data_size=3000)\n",
    "\n",
    "# 创建替代数据集\n",
    "substitute_dataset = create_substitute_dataset(\n",
    "    victim_model=victim_model,\n",
    "    query_images=query_images,\n",
    "    save_path=\"substitute_dataset_cifar10.pt\",\n",
    "    output_perturbation = perturb_prediction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "substitute_model_output_perturbation_defense = SubstituteModel(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练替代模型...\n",
      "Epoch 1/20 | Loss: 2.4170 | Acc: 12.43%\n",
      "Saved best model with accuracy: 12.43%\n",
      "Epoch 2/20 | Loss: 2.3432 | Acc: 13.67%\n",
      "Saved best model with accuracy: 13.67%\n",
      "Epoch 3/20 | Loss: 2.3036 | Acc: 15.13%\n",
      "Saved best model with accuracy: 15.13%\n",
      "Epoch 4/20 | Loss: 2.2697 | Acc: 16.67%\n",
      "Saved best model with accuracy: 16.67%\n",
      "Epoch 5/20 | Loss: 2.2413 | Acc: 19.33%\n",
      "Saved best model with accuracy: 19.33%\n",
      "Epoch 6/20 | Loss: 2.2087 | Acc: 20.40%\n",
      "Saved best model with accuracy: 20.40%\n",
      "Epoch 7/20 | Loss: 2.1673 | Acc: 22.23%\n",
      "Saved best model with accuracy: 22.23%\n",
      "Epoch 8/20 | Loss: 2.1317 | Acc: 24.40%\n",
      "Saved best model with accuracy: 24.40%\n",
      "Epoch 9/20 | Loss: 2.0815 | Acc: 27.13%\n",
      "Saved best model with accuracy: 27.13%\n",
      "Epoch 10/20 | Loss: 2.0293 | Acc: 29.27%\n",
      "Saved best model with accuracy: 29.27%\n",
      "Epoch 11/20 | Loss: 1.9944 | Acc: 29.97%\n",
      "Saved best model with accuracy: 29.97%\n",
      "Epoch 12/20 | Loss: 1.9120 | Acc: 34.97%\n",
      "Saved best model with accuracy: 34.97%\n",
      "Epoch 13/20 | Loss: 1.8541 | Acc: 37.37%\n",
      "Saved best model with accuracy: 37.37%\n",
      "Epoch 14/20 | Loss: 1.7855 | Acc: 39.73%\n",
      "Saved best model with accuracy: 39.73%\n",
      "Epoch 15/20 | Loss: 1.7265 | Acc: 42.47%\n",
      "Saved best model with accuracy: 42.47%\n",
      "Epoch 16/20 | Loss: 1.6731 | Acc: 45.00%\n",
      "Saved best model with accuracy: 45.00%\n",
      "Epoch 17/20 | Loss: 1.5661 | Acc: 49.00%\n",
      "Saved best model with accuracy: 49.00%\n",
      "Epoch 18/20 | Loss: 1.4892 | Acc: 52.03%\n",
      "Saved best model with accuracy: 52.03%\n",
      "Epoch 19/20 | Loss: 1.4195 | Acc: 54.40%\n",
      "Saved best model with accuracy: 54.40%\n",
      "Epoch 20/20 | Loss: 1.3396 | Acc: 56.67%\n",
      "Saved best model with accuracy: 56.67%\n",
      "Finished training. Best accuracy: 56.67%\n"
     ]
    }
   ],
   "source": [
    "# 在替代数据集上训练替代模型\n",
    "print(\"开始训练替代模型...\")\n",
    "trained_substitute_model = train_substitute_model(\n",
    "    substitute_model=substitute_model_output_perturbation_defense,\n",
    "    substitute_dataset=substitute_dataset,\n",
    "    epochs=20,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Test Accuracy:  21.37 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Test Accuracy: \", test_model(substitute_model_output_perturbation_defense, testloader), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
