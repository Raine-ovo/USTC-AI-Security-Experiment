{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课程前言\n",
    "\n",
    "此为 <<人工智能安全>> 课程第一部分: 文本对抗攻击实验部分."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此前我们探讨了连续型数据（如图像像素）的扰动方法，本节课将聚焦离散型数据---文本的对抗扰动技术。\n",
    "\n",
    "相较于图像在连续空间的可微特性，文本数据具有离散组合特征，因此其对抗攻击需要使用差异化的设计思路。\n",
    "\n",
    "文本对抗扰动指通过对原始文本进行局部语义保持性修改（如替换、插入或删除特定字符），生成人类可读但能导致NLP模型误判的对抗样本。\n",
    "\n",
    "文本扰动技术核心在于两点：\n",
    "1. 确保扰动后的文本符合语法规范且语义连贯\n",
    "2. 能通过最小化修改幅度使对抗样本逃逸模型检测并维持人类可读性\n",
    "\n",
    "以情感分类任务为例，将负面评价“这部电影非常糟糕”中关键形容词替换为语义弱化的“差强人意”，可能误导模型将其误判为中性情感。此类攻击揭示了NLP模型对语义细微变化的脆弱性。\n",
    "\n",
    "目前主流的文本对抗攻击方法可以按两个维度分类：\n",
    "1. 扰动粒度：根据修改单元分为字符级、词级或短语级攻击\n",
    "2. 生成策略：依据搜索算法分为基于梯度的优化方法或启发式替代策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 实验准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT是由Google提出的基于Transformer架构的预训练语言模型，通过双向上下文理解实现文本表征，bert-base-uncased-imdb 则是BERT在IMDB影评数据集上微调的版本，主要用于情感二分类（负面/正面评价），准确率约为 94%。\n",
    "\n",
    "本次实验，我们使用 bert-base-uncased-imdb 情感分类模型来作为文本对抗攻击的测试基准。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先对一个样本进行攻击，查看攻击效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 20:00:33.021073: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-13 20:00:33.313469: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-13 20:00:33.887639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "model_name = \"textattack/bert-base-uncased-imdb\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# 定义原始文本\n",
    "text = \"The movie was fantastic! The acting was superb and the plot kept me engaged throughout.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基于规则的扰动攻击**\n",
    "\n",
    "这种攻击通过人为设计的规则对文本进行修改，实现方法比较简单。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们来人为定义一个替换策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符串替换规则\n",
    "perturbation_map = {\n",
    "    'a': ['@', 'ä', 'à', 'á'],\n",
    "    'e': ['3', 'é', 'è'],\n",
    "    'i': ['1', '!', 'í'],\n",
    "    'o': ['0', 'ö', 'ó'],\n",
    "    's': ['$', '5'],\n",
    "    't': ['7', '+']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个方法实现了字符级别的扰动。\n",
    "接下来，我们只需要将这个映射到样本中，即可生成对抗样本。\n",
    "\n",
    "为了保持对抗样本的隐蔽性，需要引入一个概率值，文本中满足映射的字符将以某种概率进行替换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符级扰动攻击\n",
    "def char_perturbation(texts, prob=0.2):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "        single_output = True\n",
    "    else:\n",
    "        single_output = False\n",
    "\n",
    "    perturbed_texts = []\n",
    "    for text in texts:\n",
    "        perturbed = []\n",
    "        for char in text.lower():\n",
    "            if char in perturbation_map and torch.rand(1).item() < prob:\n",
    "                choices = perturbation_map[char]\n",
    "                index = torch.multinomial(torch.ones(len(choices)), 1).item()\n",
    "                perturbed.append(choices[index])\n",
    "            else:\n",
    "                perturbed.append(char)\n",
    "        perturbed_texts.append(''.join(perturbed))\n",
    "\n",
    "    if single_output:\n",
    "        return perturbed_texts[0]\n",
    "    else:\n",
    "        return perturbed_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看扰动效果和模型预测结果：\n",
    "\n",
    "> 由于样本太短，若效果不理想可多测试几次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: The movie was fantastic! The acting was superb and the plot kept me engaged throughout.\n",
      "Perturbed Text: +he movie was fantas+ic! the acting was superb and 7hè plot kept me engaged throughout.\n",
      "\n",
      "Original Prediction (neg/pos): [0.00285911 0.9971409 ]\n",
      "Perturbed Prediction (neg/pos): [0.0055841 0.9944159]\n"
     ]
    }
   ],
   "source": [
    "# 测试原始样本和对抗样本的分类结果\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "    return torch.softmax(outputs.logits, dim=1).detach().cpu().numpy()\n",
    "\n",
    "def output_adversarial_example_and_prediction(text, attack):\n",
    "    perturbed_text = attack(text)\n",
    "    print(\"Original Text:\", text)\n",
    "    print(\"Perturbed Text:\", perturbed_text)\n",
    "\n",
    "    original_prob = predict(text)\n",
    "    perturbed_prob = predict(perturbed_text)\n",
    "\n",
    "    print(\"\\nOriginal Prediction (neg/pos):\", original_prob[0])\n",
    "    print(\"Perturbed Prediction (neg/pos):\", perturbed_prob[0])\n",
    "\n",
    "output_adversarial_example_and_prediction(text, char_perturbation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基于嵌入的扰动攻击**\n",
    "\n",
    "这种攻击方法利用词向量空间来生成对抗样本，即连续空间梯度与离散空间语义替换。\n",
    "\n",
    "模型首先通过 $embedding$ 层，将离散词汇映射至连续向量空间，这似乎就与之前所讲的图像对抗攻击优化目标相同了，因此我们现在有两种思路：\n",
    "1. 连续梯度扰动（如 FGSM ）：基于梯度符号法直接在词向量空间施加微小扰动，在数学上能够保证 $\\epsilon-ball$ 的向量邻近性。\n",
    "2. 离散语义替换（如 Word2Vec ）：在词嵌入空间中检索k-邻近有效词汇集合并选取一个进行替换。\n",
    "\n",
    "我们分别阐述这两种方法的实现细节："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_perturbation(model, input_text, labels, epsilon, tokenizer):\n",
    "    '''\n",
    "    使用 FGSM 对输入文本进行扰动\n",
    "    参数：\n",
    "        model: 目标模型\n",
    "        input_text: 输入文本\n",
    "        labels: 对应标签\n",
    "        epsilon: 扰动强度\n",
    "        tokenizer: 分词器\n",
    "    返回\n",
    "        perturbed_text: 扰动后的文本\n",
    "    '''\n",
    "\n",
    "    # 对输入文本进行分词并转换为张量\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # 由于输入input的词向量不属于叶子节点，无法进行梯度计算，因此需要克隆一份作为叶子节点\n",
    "    # 计算时直接使用克隆后的 embeddings 的梯度作为词嵌入的梯度\n",
    "    embeddings = model.get_input_embeddings()(inputs['input_ids'])\n",
    "    embeddings = embeddings.detach().clone()\n",
    "    embeddings.requires_grad = True\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        # 使用嵌入表示作为输入\n",
    "        outputs = model(inputs_embeds=embeddings, attention_mask=inputs['attention_mask'])\n",
    "        loss = nn.CrossEntropyLoss()(outputs.logits, labels.to(model.device))\n",
    "\n",
    "        gradients = torch.autograd.grad(loss, embeddings)[0]\n",
    "        sign_gradients = gradients.sign()\n",
    "\n",
    "        # 对嵌入表示进行扰动\n",
    "        perturbed_embeddings = embeddings + epsilon * sign_gradients\n",
    "\n",
    "    # 将扰动后的嵌入表示转换回输入 ID\n",
    "    perturbed_input_ids = torch.argmax(torch.matmul(perturbed_embeddings, model.get_input_embeddings().weight.t()), dim=-1)\n",
    "\n",
    "    perturbed_text = tokenizer.decode(perturbed_input_ids.squeeze(), skip_special_tokens=True)\n",
    "    return perturbed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: The movie was fantastic! The acting was superb and the plot kept me engaged throughout.\n",
      "Perturbed Text: themori 780rada! 338 670 she superb 670 the plot kept 670 engaged halftime\n",
      "\n",
      "Original Prediction (neg/pos): [0.00285911 0.9971409 ]\n",
      "Perturbed Prediction (neg/pos): [0.5996884 0.4003116]\n"
     ]
    }
   ],
   "source": [
    "output_adversarial_example_and_prediction(text, lambda x: fgsm_perturbation(model, x, torch.tensor([1]), 0.1, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验表明，尽管FGSM攻击能够通过生成对抗样本误导模型分类，但其产生的文本可读性显著降低，违背了对抗扰动攻击需保持人类可读性的约束。\n",
    "\n",
    "这是因为，FGSM在词向量空间中搜索扰动时，虽能保证生成向量与原始词嵌入的几何邻近性（即语义相似性），但词嵌入空间到实际词汇的映射并非双射关系——经扰动后的向量可能落入\"空洞区域\"，无法对应词典中的有效词汇。这种词向量离散化过程中的语义断裂，最终导致对抗样本丧失语言连贯性。\n",
    "\n",
    "因此，直接在词嵌入空间依据梯度符号进行攻击是**不合理**的，我们考虑另外一种思路。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了保证语义的连贯性，我们可以使用基于预训练词向量模型（如Word2Vec）进行替换策略，该策略利用余弦相似度计算在词嵌入空间中检索目标词的Top-K语义邻近词，进而通过概率采样策略选取替代词汇。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: The movie was fantastic! The acting was superb and the plot kept me engaged throughout.\n",
      "Perturbed Text: this sequel was fantastic ! ofthe acting is superb and in plotted Keeping I Engaged throughout .\n",
      "\n",
      "Original Prediction (neg/pos): [0.00285911 0.9971409 ]\n",
      "Perturbed Prediction (neg/pos): [0.00115569 0.99884427]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"word2vec-google-news-300.model\"):\n",
    "    # 加载预训练的 Word2Vec 模型\n",
    "    vec_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "    # 自选下载到本地与否\n",
    "    # vec_model.save(\"word2vec-google-news-300.model\")\n",
    "else:\n",
    "    from gensim.models import KeyedVectors\n",
    "    vec_model = KeyedVectors.load(\"word2vec-google-news-300.model\")\n",
    "\n",
    "def word_embedding_perturbation(vec_model, texts, num_words=10, prob=0.7):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "        single_output = True\n",
    "    else:\n",
    "        single_output = False\n",
    "\n",
    "    perturbed_texts = []\n",
    "    for text in texts:\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        perturbed_tokens = []\n",
    "        for token in tokens:\n",
    "            if token in vec_model and torch.rand(1).item() < prob:\n",
    "                similar_words = vec_model.most_similar(token, topn=num_words)\n",
    "                new_word = similar_words[torch.randint(0, num_words, (1,)).item()][0]\n",
    "                perturbed_tokens.append(new_word)\n",
    "            else:\n",
    "                perturbed_tokens.append(token)\n",
    "        perturbed_texts.append(' '.join(perturbed_tokens))\n",
    "\n",
    "    if single_output:\n",
    "        return perturbed_texts[0]\n",
    "    else:\n",
    "        return perturbed_texts\n",
    "\n",
    "output_adversarial_example_and_prediction(text, lambda x: word_embedding_perturbation(vec_model, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在附加材料 `bert_attack.ipynb` 中提供了 BAE 攻击算法，这是一种基于嵌入的文本扰动攻击算法，与 Word2Vec 相似，感兴趣可进行查阅。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们使用 imdb 数据集中的测试集，来进行 bert-base-uncased-imdb 模型的对抗测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "test_dataset = load_dataset(\"imdb\", split=\"test\")\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "required_columns = ['input_ids', 'attention_mask', 'label', 'text']\n",
    "test_dataset.set_format(type='torch', columns=required_columns)\n",
    "\n",
    "# 为了节省时间，取 64 个样本作测试\n",
    "n_samples = 64\n",
    "subset_test_dataset = test_dataset.shuffle(seed=42).select(range(n_samples))\n",
    "\n",
    "test_dataloader = DataLoader(subset_test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader, attack):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        original_texts = batch[\"text\"]\n",
    "        if attack:\n",
    "            perturbed_texts = attack(original_texts)\n",
    "        else:\n",
    "            perturbed_texts = original_texts\n",
    "        inputs = tokenizer(perturbed_texts, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=128)\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.softmax(logits, dim=1)\n",
    "\n",
    "            # 将预测的概率值转换为类别标签\n",
    "            pred_labels = torch.argmax(preds, dim=1).cpu().tolist()\n",
    "            predictions.extend(pred_labels)\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    return predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型准确率为:  89.06%\n",
      "模型准确率为:  73.44%\n"
     ]
    }
   ],
   "source": [
    "predictions, true_labels = evaluation(model, test_dataloader, None)\n",
    "clean_accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"模型准确率为: {clean_accuracy * 100: .2f}%\")\n",
    "\n",
    "predictions, true_labels = evaluation(model, test_dataloader, char_perturbation)\n",
    "char_perturbation_accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"模型准确率为: {char_perturbation_accuracy * 100: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于字符替换规则较少且相对简单，可能会导致模型准确率较高，这里仅作参考。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions, true_labels \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_embedding_perturbation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m char_perturbation_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(true_labels, predictions)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m模型准确率为: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchar_perturbation_accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 9\u001b[0m, in \u001b[0;36mevaluation\u001b[0;34m(model, dataloader, attack)\u001b[0m\n\u001b[1;32m      7\u001b[0m original_texts \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attack:\n\u001b[0;32m----> 9\u001b[0m     perturbed_texts \u001b[38;5;241m=\u001b[39m \u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     perturbed_texts \u001b[38;5;241m=\u001b[39m original_texts\n",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions, true_labels \u001b[38;5;241m=\u001b[39m evaluation(model, test_dataloader, \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mword_embedding_perturbation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m char_perturbation_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(true_labels, predictions)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m模型准确率为: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchar_perturbation_accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m, in \u001b[0;36mword_embedding_perturbation\u001b[0;34m(vec_model, texts, num_words, prob)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m vec_model \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m prob:\n\u001b[0;32m---> 24\u001b[0m         similar_words \u001b[38;5;241m=\u001b[39m \u001b[43mvec_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m         new_word \u001b[38;5;241m=\u001b[39m similar_words[torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, num_words, (\u001b[38;5;241m1\u001b[39m,))\u001b[38;5;241m.\u001b[39mitem()][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m         perturbed_tokens\u001b[38;5;241m.\u001b[39mappend(new_word)\n",
      "File \u001b[0;32m~/miniconda3/envs/TA/lib/python3.8/site-packages/gensim/models/keyedvectors.py:852\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m topn:\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dists\n\u001b[0;32m--> 852\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mmatutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_keys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;66;03m# ignore (don't return) keys from the input\u001b[39;00m\n\u001b[1;32m    854\u001b[0m result \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    855\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_to_key[sim \u001b[38;5;241m+\u001b[39m clip_start], \u001b[38;5;28mfloat\u001b[39m(dists[sim]))\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sim \u001b[38;5;129;01min\u001b[39;00m best \u001b[38;5;28;01mif\u001b[39;00m (sim \u001b[38;5;241m+\u001b[39m clip_start) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_keys\n\u001b[1;32m    857\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/TA/lib/python3.8/site-packages/gensim/matutils.py:81\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(x, topn, reverse)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(x)[:topn]\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# np >= 1.8 has a fast partial argsort, use that!\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m most_extreme \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[43m)\u001b[49m[:topn]\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m most_extreme\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margsort(x\u001b[38;5;241m.\u001b[39mtake(most_extreme)))\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margpartition\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/TA/lib/python3.8/site-packages/numpy/core/fromnumeric.py:871\u001b[0m, in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argpartition_dispatcher)\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margpartition\u001b[39m(a, kth, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintroselect\u001b[39m\u001b[38;5;124m'\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    794\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;124;03m    Perform an indirect partition along the given axis using the\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;124;03m    algorithm specified by the `kind` keyword. It returns an array of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    869\u001b[0m \n\u001b[1;32m    870\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margpartition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/TA/lib/python3.8/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 基于词嵌入的方法可能运行较慢，感兴趣可运行\n",
    "predictions, true_labels = evaluation(model, test_dataloader, lambda x: word_embedding_perturbation(vec_model, x))\n",
    "char_perturbation_accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"模型准确率为: {char_perturbation_accuracy * 100: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextAttack\n",
    "\n",
    "TextAttack是一个用于自然语言处理对抗攻击的 Python 库，它提供了丰富的攻击方法和模型接口。我们可以利用它实现快速方便的对抗攻击测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextAttack 库还提供了端到端的使用方法，具体可参考 `additional_reading.ipynb` 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/raine/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载模型和分词器...\n",
      "正在加载攻击方法...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在下载数据集...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb2ee40b913445b9d7fcf098cdc0ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Logging to CSV at path attack_log.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始攻击...\n",
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.5\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): PartOfSpeech(\n",
      "        (tagger_type):  nltk\n",
      "        (tagset):  universal\n",
      "        (allow_verb_noun_swap):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (2): UniversalSentenceEncoder(\n",
      "        (metric):  angular\n",
      "        (threshold):  0.840845057\n",
      "        (window_size):  15\n",
      "        (skip_text_shorter_than_window):  True\n",
      "        (compare_against_original):  False\n",
      "      )\n",
      "    (3): RepeatModification\n",
      "    (4): StopwordModification\n",
      "    (5): InputColumnModification(\n",
      "        (matching_column_labels):  ['premise', 'hypothesis']\n",
      "        (columns_to_ignore):  {'premise'}\n",
      "      )\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]2025-04-13 20:40:35.093539: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:35.093723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.418911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.419047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.419139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.419222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.535181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.535315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.535410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.535493: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.535575: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.535656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.541038: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.541159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.541253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.541344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.541430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.541512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9516 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-04-13 20:40:36.541759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-13 20:40:36.541836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 738 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:05:00.0, compute capability: 8.9\n",
      "2025-04-13 20:40:36.897839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:753] failed to allocate 9.29GiB (9978970112 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-04-13 20:40:36.898037: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:753] failed to allocate 8.36GiB (8981072896 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-04-13 20:40:36.898225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:753] failed to allocate 7.53GiB (8082965504 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-04-13 20:40:42.553292: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2025-04-13 20:40:42.553313: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2025-04-13 20:40:42.553350: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:42.553362: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:42.553370: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:42.553379: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:42.553389: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:42.553398: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:42.553410: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:42.553420: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:42.553431: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:42.553441: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:42.553450: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:42.553461: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:42.553474: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:189] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-04-13 20:40:43.730664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "[Succeeded / Failed / Skipped / Total] 4 / 0 / 1 / 5:  50%|█████     | 5/10 [01:17<01:17, 15.46s/it]textattack: Saving checkpoint under \"checkpoints/1744548074567.ta.chkpt\" at 2025-04-13 20:41:14 after 5 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 0 / 1 / 10: 100%|██████████| 10/10 [01:49<00:00, 10.92s/it]textattack: Saving checkpoint under \"checkpoints/1744548106452.ta.chkpt\" at 2025-04-13 20:41:46 after 10 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 9 / 0 / 1 / 10: 100%|██████████| 10/10 [01:49<00:00, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 9      |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 1      |\n",
      "| Original accuracy:            | 90.0%  |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "| Average perturbed word %:     | 12.46% |\n",
      "| Average num. words per input: | 202.2  |\n",
      "| Avg num queries:              | 813.67 |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 499321.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (68%)\u001b[0m\n",
      "\n",
      "\u001b[91mI\u001b[0m \u001b[91mlove\u001b[0m sci-fi and am \u001b[91mwilling\u001b[0m to \u001b[91mput\u001b[0m up with a \u001b[91mlot\u001b[0m. Sci-fi \u001b[91mmovies\u001b[0m/\u001b[91mTV\u001b[0m are \u001b[91musually\u001b[0m underfunded, under-appreciated and misunderstood. I \u001b[91mtried\u001b[0m to like this, I \u001b[91mreally\u001b[0m did, but it is to \u001b[91mgood\u001b[0m \u001b[91mTV\u001b[0m sci-fi as Babylon 5 is to \u001b[91mStar\u001b[0m \u001b[91mTrek\u001b[0m (the \u001b[91moriginal\u001b[0m). \u001b[91mSilly\u001b[0m \u001b[91mprosthetics\u001b[0m, cheap cardboard \u001b[91msets\u001b[0m, \u001b[91mstilted\u001b[0m dialogues, \u001b[91mCG\u001b[0m that doesn't \u001b[91mmatch\u001b[0m the \u001b[91mbackground\u001b[0m, and \u001b[91mpainfully\u001b[0m one-dimensional characters cannot \u001b[91mbe\u001b[0m \u001b[91movercome\u001b[0m with a 'sci-fi' \u001b[91msetting\u001b[0m. (I'm \u001b[91msure\u001b[0m there are those of you out there who \u001b[91mthink\u001b[0m Babylon 5 is \u001b[91mgood\u001b[0m sci-fi \u001b[91mTV\u001b[0m. It's not. It's \u001b[91mclichéd\u001b[0m and \u001b[91muninspiring\u001b[0m.) \u001b[91mWhile\u001b[0m \u001b[91mUS\u001b[0m \u001b[91mviewers\u001b[0m \u001b[91mmight\u001b[0m \u001b[91mlike\u001b[0m \u001b[91memotion\u001b[0m and \u001b[91mcharacter\u001b[0m \u001b[91mdevelopment\u001b[0m, sci-fi is a \u001b[91mgenre\u001b[0m that \u001b[91mdoes\u001b[0m not \u001b[91mtake\u001b[0m itself \u001b[91mseriously\u001b[0m (\u001b[91mcf\u001b[0m. \u001b[91mStar\u001b[0m \u001b[91mTrek\u001b[0m). It may \u001b[91mtreat\u001b[0m \u001b[91mimportant\u001b[0m \u001b[91missues\u001b[0m, yet not as a \u001b[91mserious\u001b[0m \u001b[91mphilosophy\u001b[0m. It's \u001b[91mreally\u001b[0m \u001b[91mdifficult\u001b[0m to \u001b[91mcare\u001b[0m about the \u001b[91mcharacters\u001b[0m here as they are not simply foolish, just \u001b[91mmissing\u001b[0m a \u001b[91mspark\u001b[0m of \u001b[91mlife\u001b[0m. Their \u001b[91mactions\u001b[0m and \u001b[91mreactions\u001b[0m are wooden and predictable, \u001b[91moften\u001b[0m \u001b[91mpainful\u001b[0m to \u001b[91mwatch\u001b[0m. \u001b[91mThe\u001b[0m \u001b[91mmakers\u001b[0m of \u001b[91mEarth\u001b[0m \u001b[91mKNOW\u001b[0m it's rubbish as they \u001b[91mhave\u001b[0m to always say \"\u001b[91mGene\u001b[0m Roddenberry's \u001b[91mEarth\u001b[0m...\" otherwise \u001b[91mpeople\u001b[0m would not \u001b[91mcontinue\u001b[0m \u001b[91mwatching\u001b[0m. Roddenberry's \u001b[91mashes\u001b[0m must \u001b[91mbe\u001b[0m turning in their \u001b[91morbit\u001b[0m as this dull, cheap, poorly \u001b[91medited\u001b[0m (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.\n",
      "\n",
      "\u001b[92mme\u001b[0m \u001b[92menjoyed\u001b[0m sci-fi and am \u001b[92mwish\u001b[0m to \u001b[92mrendered\u001b[0m up with a \u001b[92mnumber\u001b[0m. Sci-fi \u001b[92mteatro\u001b[0m/\u001b[92mTELEVISION\u001b[0m are \u001b[92msometimes\u001b[0m underfunded, under-appreciated and misunderstood. I \u001b[92mstrive\u001b[0m to like this, I \u001b[92mactually\u001b[0m did, but it is to \u001b[92mnice\u001b[0m \u001b[92mGONZALEZ\u001b[0m sci-fi as Babylon 5 is to \u001b[92mSings\u001b[0m \u001b[92mRises\u001b[0m (the \u001b[92maboriginal\u001b[0m). \u001b[92mGrotesque\u001b[0m \u001b[92msurgeon\u001b[0m, cheap cardboard \u001b[92mdetermines\u001b[0m, \u001b[92mmaudlin\u001b[0m dialogues, \u001b[92mFIM\u001b[0m that doesn't \u001b[92mcoincidence\u001b[0m the \u001b[92mregard\u001b[0m, and \u001b[92mpatiently\u001b[0m one-dimensional characters cannot \u001b[92mexists\u001b[0m \u001b[92msurpassed\u001b[0m with a 'sci-fi' \u001b[92mfixture\u001b[0m. (I'm \u001b[92mcertainty\u001b[0m there are those of you out there who \u001b[92mknew\u001b[0m Babylon 5 is \u001b[92mappropriate\u001b[0m sci-fi \u001b[92mBROADCASTING\u001b[0m. It's not. It's \u001b[92mmelodrama\u001b[0m and \u001b[92mdistasteful\u001b[0m.) \u001b[92mDuring\u001b[0m \u001b[92mVS\u001b[0m \u001b[92mfans\u001b[0m \u001b[92mthreats\u001b[0m \u001b[92mamour\u001b[0m \u001b[92mfeeling\u001b[0m and \u001b[92mpersonalities\u001b[0m \u001b[92mprogressed\u001b[0m, sci-fi is a \u001b[92msorting\u001b[0m that \u001b[92mes\u001b[0m not \u001b[92mhaving\u001b[0m itself \u001b[92mintently\u001b[0m (\u001b[92mfc\u001b[0m. \u001b[92mStars\u001b[0m \u001b[92mTrekking\u001b[0m). It may \u001b[92msolved\u001b[0m \u001b[92mimperative\u001b[0m \u001b[92mdots\u001b[0m, yet not as a \u001b[92mdifficult\u001b[0m \u001b[92mphilosophers\u001b[0m. It's \u001b[92mgenuinely\u001b[0m \u001b[92marduous\u001b[0m to \u001b[92mloving\u001b[0m about the \u001b[92mcharacter\u001b[0m here as they are not simply foolish, just \u001b[92mlosing\u001b[0m a \u001b[92mignited\u001b[0m of \u001b[92mresides\u001b[0m. Their \u001b[92mprecautions\u001b[0m and \u001b[92mreply\u001b[0m are wooden and predictable, \u001b[92malways\u001b[0m \u001b[92mpoignant\u001b[0m to \u001b[92mwatching\u001b[0m. \u001b[92mBoth\u001b[0m \u001b[92mcraftsman\u001b[0m of \u001b[92mSoils\u001b[0m \u001b[92mAPPRECIATE\u001b[0m it's rubbish as they \u001b[92mgot\u001b[0m to always say \"\u001b[92mInherited\u001b[0m Roddenberry's \u001b[92mTerre\u001b[0m...\" otherwise \u001b[92mresident\u001b[0m would not \u001b[92mlifelong\u001b[0m \u001b[92mnotes\u001b[0m. Roddenberry's \u001b[92mash\u001b[0m must \u001b[92mes\u001b[0m turning in their \u001b[92morbiting\u001b[0m as this dull, cheap, poorly \u001b[92meditor\u001b[0m (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.\n",
      "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (57%)\u001b[0m\n",
      "\n",
      "Worth the entertainment value of a rental, especially if you like action movies. This one features the usual car chases, fights with the great Van Damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. All of this is entertaining and competently handled but there is nothing that really blows you away if you've seen your share before.<br /><br />The plot is made interesting by the inclusion of a rabbit, which is clever but \u001b[91mhardly\u001b[0m profound. Many of the characters are heavily stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy tough lady station head, the crooked politician, the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the 1940s. All passably acted but again nothing special.<br /><br />I thought the main villains were pretty well done and fairly well acted. By the end of the movie you certainly knew who the good guys were and weren't. There was an emotional lift as the really bad ones got their just deserts. Very simplistic, but then you weren't expecting Hamlet, right? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene.<br /><br />Not bad. \u001b[91mNot\u001b[0m good. Passable 4.\n",
      "\n",
      "Worth the entertainment value of a rental, especially if you like action movies. This one features the usual car chases, fights with the great Van Damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. All of this is entertaining and competently handled but there is nothing that really blows you away if you've seen your share before.<br /><br />The plot is made interesting by the inclusion of a rabbit, which is clever but \u001b[92mmerely\u001b[0m profound. Many of the characters are heavily stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy tough lady station head, the crooked politician, the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the 1940s. All passably acted but again nothing special.<br /><br />I thought the main villains were pretty well done and fairly well acted. By the end of the movie you certainly knew who the good guys were and weren't. There was an emotional lift as the really bad ones got their just deserts. Very simplistic, but then you weren't expecting Hamlet, right? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene.<br /><br />Not bad. \u001b[92mEither\u001b[0m good. Passable 4.\n",
      "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (54%)\u001b[0m\n",
      "\n",
      "its a totally average film with a few semi-alright action sequences that make the plot seem a little better and remind the viewer of the classic van dam films. parts of the plot don't make sense and seem to be added in to use up time. the end plot is that of a very basic type that doesn't leave the viewer guessing and any twists are obvious from the beginning. the end scene with the flask backs don't make sense as they are added in and seem to have little relevance to the history of van dam's character. not really \u001b[91mworth\u001b[0m watching again, bit disappointed in the end production, even though it is apparent it was shot on a low budget certain shots and sections in the film are of poor directed quality\n",
      "\n",
      "its a totally average film with a few semi-alright action sequences that make the plot seem a little better and remind the viewer of the classic van dam films. parts of the plot don't make sense and seem to be added in to use up time. the end plot is that of a very basic type that doesn't leave the viewer guessing and any twists are obvious from the beginning. the end scene with the flask backs don't make sense as they are added in and seem to have little relevance to the history of van dam's character. not really \u001b[92mpena\u001b[0m watching again, bit disappointed in the end production, even though it is apparent it was shot on a low budget certain shots and sections in the film are of poor directed quality\n",
      "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (76%)\u001b[0m\n",
      "\n",
      "\u001b[91mSTAR\u001b[0m \u001b[91mRATING\u001b[0m: ***** Saturday Night **** Friday Night *** Friday Morning ** Sunday Night * Monday Morning <br /><br />Former New Orleans homicide \u001b[91mcop\u001b[0m Jack Robideaux (Jean Claude Van Damme) is re-assigned to Columbus, a small but violent town in Mexico to help the police there with their efforts to stop a major heroin smuggling operation into their town. The culprits turn out to be ex-military, lead by former commander Benjamin Meyers (Stephen Lord, otherwise known as Jase from East Enders) who is using a special method he learned in Afghanistan to fight off his opponents. But Jack has a more personal \u001b[91mreason\u001b[0m for taking him down, that draws the two men into an explosive final showdown where only one will walk away alive.<br /><br />After Until Death, Van Damme \u001b[91mappeared\u001b[0m to \u001b[91mbe\u001b[0m on a high, showing he could \u001b[91mmake\u001b[0m the best straight to \u001b[91mvideo\u001b[0m films in the action market. While that was a far more drama oriented film, with The Shepherd he has returned to the high-kicking, no \u001b[91mbrainer\u001b[0m \u001b[91maction\u001b[0m that first made him famous and has sadly produced his worst film since Derailed. It's nowhere near as \u001b[91mbad\u001b[0m as that film, but what I \u001b[91msaid\u001b[0m still stands.<br /><br />A dull, predictable film, with very little in the way of any exciting action. What little there is mainly \u001b[91mconsists\u001b[0m of some limp fight scenes, trying to look cool and trendy with some cheap slo-mo/sped up effects added to them that sadly instead make them look more desperate. Being a Mexican set film, \u001b[91mdirector\u001b[0m Isaac Florentine has tried to give the film a Robert Rodriguez/Desperado sort of feel, but this only adds to the desperation.<br /><br />\u001b[91mVD\u001b[0m gives a particularly \u001b[91muninspired\u001b[0m \u001b[91mperformance\u001b[0m and given he's never been a Robert De Niro sort of actor, that can't be good. As the villain, \u001b[91mLord\u001b[0m shouldn't \u001b[91mexpect\u001b[0m to leave the beeb anytime soon. \u001b[91mHe\u001b[0m \u001b[91mgets\u001b[0m \u001b[91mlittle\u001b[0m \u001b[91mdialogue\u001b[0m at the \u001b[91mbeginning\u001b[0m as he struggles to muster an American accent but gets mysteriously better towards the \u001b[91mend\u001b[0m. All the supporting cast are equally \u001b[91mbland\u001b[0m, and do nothing to raise the films spirits at all.<br /><br />This is one shepherd that's \u001b[91mstrayed\u001b[0m right from the flock. *\n",
      "\n",
      "\u001b[92mSING\u001b[0m \u001b[92mJUDGED\u001b[0m: ***** Saturday Night **** Friday Night *** Friday Morning ** Sunday Night * Monday Morning <br /><br />Former New Orleans homicide \u001b[92mpatrolman\u001b[0m Jack Robideaux (Jean Claude Van Damme) is re-assigned to Columbus, a small but violent town in Mexico to help the police there with their efforts to stop a major heroin smuggling operation into their town. The culprits turn out to be ex-military, lead by former commander Benjamin Meyers (Stephen Lord, otherwise known as Jase from East Enders) who is using a special method he learned in Afghanistan to fight off his opponents. But Jack has a more personal \u001b[92mmotif\u001b[0m for taking him down, that draws the two men into an explosive final showdown where only one will walk away alive.<br /><br />After Until Death, Van Damme \u001b[92mtalked\u001b[0m to \u001b[92mgot\u001b[0m on a high, showing he could \u001b[92mmaking\u001b[0m the best straight to \u001b[92mmovies\u001b[0m films in the action market. While that was a far more drama oriented film, with The Shepherd he has returned to the high-kicking, no \u001b[92mmethinks\u001b[0m \u001b[92moperation\u001b[0m that first made him famous and has sadly produced his worst film since Derailed. It's nowhere near as \u001b[92munfavorable\u001b[0m as that film, but what I \u001b[92mclaimed\u001b[0m still stands.<br /><br />A dull, predictable film, with very little in the way of any exciting action. What little there is mainly \u001b[92mpresupposes\u001b[0m of some limp fight scenes, trying to look cool and trendy with some cheap slo-mo/sped up effects added to them that sadly instead make them look more desperate. Being a Mexican set film, \u001b[92mdirektor\u001b[0m Isaac Florentine has tried to give the film a Robert Rodriguez/Desperado sort of feel, but this only adds to the desperation.<br /><br />\u001b[92mTS\u001b[0m gives a particularly \u001b[92mhokey\u001b[0m \u001b[92maccomplishment\u001b[0m and given he's never been a Robert De Niro sort of actor, that can't be good. As the villain, \u001b[92mLiege\u001b[0m shouldn't \u001b[92mexpecting\u001b[0m to leave the beeb anytime soon. \u001b[92mHis\u001b[0m \u001b[92mgotten\u001b[0m \u001b[92mslight\u001b[0m \u001b[92mdiscussing\u001b[0m at the \u001b[92minfancy\u001b[0m as he struggles to muster an American accent but gets mysteriously better towards the \u001b[92mcease\u001b[0m. All the supporting cast are equally \u001b[92mprosaic\u001b[0m, and do nothing to raise the films spirits at all.<br /><br />This is one shepherd that's \u001b[92mjourneyed\u001b[0m right from the flock. *\n",
      "\u001b[92mPositive (100%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "First off let me say, If you haven't enjoyed a Van Damme movie since bloodsport, you probably will not like this movie. Most of these movies may not have the best plots or best actors but I enjoy these kinds of movies for what they are. This movie is much better than any of the movies the other action guys (Segal and Dolph) have thought about putting out the past few years. Van Damme is good in the movie, the movie is only worth watching to Van Damme fans. It is not as good as Wake of Death (which i highly recommend to anyone of likes Van Damme) or In hell but, in my opinion it's worth watching. It has the same type of feel to it as Nowhere to Run. Good fun stuff!\n",
      "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (67%)\u001b[0m\n",
      "\n",
      "\u001b[91mI\u001b[0m had high \u001b[91mhopes\u001b[0m for this one until they changed the name to 'The Shepherd : Border Patrol, the lamest movie name ever, what was wrong with just 'The Shepherd'. This is a by the numbers action flick that tips its \u001b[91mhat\u001b[0m at many classic Van Damme films. There is a nice \u001b[91mbit\u001b[0m of action in a \u001b[91mbar\u001b[0m which reminded me of hard target and universal soldier but directed with no intensity or flair which is a shame. There is one great \u001b[91mline\u001b[0m about 'being p*ss drunk and carrying a rabbit' and some OK action scenes \u001b[91mlet\u001b[0m down by the cheapness of it all. A lot of the times the dialogue doesn't match the characters mouth and the stunt men fall down dead a split second before even being shot. \u001b[91mThe\u001b[0m end fight is one of the better Van Damme fights except the Director tries to go a bit too John Woo and fails also introducing \u001b[91mflashbacks\u001b[0m which no one really cares about just gets in the way of the action which is the whole point of a van Damme film.<br /><br />Not good, not bad, just average generic \u001b[91maction\u001b[0m.\n",
      "\n",
      "\u001b[92mme\u001b[0m had high \u001b[92mexpecting\u001b[0m for this one until they changed the name to 'The Shepherd : Border Patrol, the lamest movie name ever, what was wrong with just 'The Shepherd'. This is a by the numbers action flick that tips its \u001b[92mchapeau\u001b[0m at many classic Van Damme films. There is a nice \u001b[92mpiece\u001b[0m of action in a \u001b[92mbarre\u001b[0m which reminded me of hard target and universal soldier but directed with no intensity or flair which is a shame. There is one great \u001b[92mpursuant\u001b[0m about 'being p*ss drunk and carrying a rabbit' and some OK action scenes \u001b[92mlicensed\u001b[0m down by the cheapness of it all. A lot of the times the dialogue doesn't match the characters mouth and the stunt men fall down dead a split second before even being shot. \u001b[92mBoth\u001b[0m end fight is one of the better Van Damme fights except the Director tries to go a bit too John Woo and fails also introducing \u001b[92mreliving\u001b[0m which no one really cares about just gets in the way of the action which is the whole point of a van Damme film.<br /><br />Not good, not bad, just average generic \u001b[92mmeasure\u001b[0m.\n",
      "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (67%)\u001b[0m\n",
      "\n",
      "Isaac Florentine has made some of the best western Martial Arts action movies ever produced. In particular US Seals 2, Cold Harvest, Special Forces and Undisputed 2 are all action classics. You can tell Isaac has a real passion for the genre and his films are always eventful, creative and sharp affairs, with some of the best fight sequences an action fan could hope for. In particular he has found a muse with Scott Adkins, as talented an actor and action performer as you could hope for. This is borne out with Special Forces and Undisputed 2, but unfortunately The Shepherd just doesn't \u001b[91mlive\u001b[0m up to their abilities.<br /><br />There is no doubt that JCVD looks better here fight-wise than he has done in years, especially in the fight he has (for pretty much no reason) in a prison cell, and in the final showdown with Scott, but look in his eyes. JCVD seems to be dead inside. There's nothing in his eyes at all. It's like he just doesn't \u001b[91mcare\u001b[0m about anything throughout the whole film. And this is the \u001b[91mleading\u001b[0m man.<br /><br />There are other \u001b[91mdodgy\u001b[0m \u001b[91maspects\u001b[0m to the film, script-wise and visually, but the main problem is that you are utterly unable to empathise with the hero of the film. A genuine shame as I know we all wanted this film to be as special as it genuinely could have been. There are some good bits, mostly the action scenes themselves. This film \u001b[91mhad\u001b[0m a terrific director and action choreographer, and an awesome opponent for JCVD to face down. This could have been the one to bring the veteran action star back up to scratch in the balls-out action movie stakes.<br /><br />Sincerely a shame that this didn't happen.\n",
      "\n",
      "Isaac Florentine has made some of the best western Martial Arts action movies ever produced. In particular US Seals 2, Cold Harvest, Special Forces and Undisputed 2 are all action classics. You can tell Isaac has a real passion for the genre and his films are always eventful, creative and sharp affairs, with some of the best fight sequences an action fan could hope for. In particular he has found a muse with Scott Adkins, as talented an actor and action performer as you could hope for. This is borne out with Special Forces and Undisputed 2, but unfortunately The Shepherd just doesn't \u001b[92mresident\u001b[0m up to their abilities.<br /><br />There is no doubt that JCVD looks better here fight-wise than he has done in years, especially in the fight he has (for pretty much no reason) in a prison cell, and in the final showdown with Scott, but look in his eyes. JCVD seems to be dead inside. There's nothing in his eyes at all. It's like he just doesn't \u001b[92mzorg\u001b[0m about anything throughout the whole film. And this is the \u001b[92mculminate\u001b[0m man.<br /><br />There are other \u001b[92msketchy\u001b[0m \u001b[92mrespects\u001b[0m to the film, script-wise and visually, but the main problem is that you are utterly unable to empathise with the hero of the film. A genuine shame as I know we all wanted this film to be as special as it genuinely could have been. There are some good bits, mostly the action scenes themselves. This film \u001b[92mhaya\u001b[0m a terrific director and action choreographer, and an awesome opponent for JCVD to face down. This could have been the one to bring the veteran action star back up to scratch in the balls-out action movie stakes.<br /><br />Sincerely a shame that this didn't happen.\n",
      "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (53%)\u001b[0m\n",
      "\n",
      "It actually pains me to say it, but this movie was horrible on \u001b[91mevery\u001b[0m \u001b[91mlevel\u001b[0m. The blame does not lie entirely with Van Damme as you can see he tried his best, but let's face it, he's almost \u001b[91mfifty\u001b[0m, how much more can you ask of him? \u001b[91mI\u001b[0m find it so hard to believe that the same people who put together Undisputed 2; arguably the best (\u001b[91mwestern\u001b[0m) martial arts movie in \u001b[91myears\u001b[0m, \u001b[91mcreated\u001b[0m this. Everything from the plot, to the dialog, to the editing, to the overall acting was just \u001b[91mhorribly\u001b[0m \u001b[91mput\u001b[0m together and in \u001b[91mmany\u001b[0m \u001b[91mcases\u001b[0m \u001b[91moutright\u001b[0m \u001b[91mboring\u001b[0m and \u001b[91mnonsensical\u001b[0m. Scott \u001b[91mAdkins\u001b[0m who's fight scenes \u001b[91mseemed\u001b[0m more \u001b[91mlike\u001b[0m a \u001b[91mdemo\u001b[0m reel, was also terribly underused and not even the \u001b[91mmain\u001b[0m villain which is such a shame because 1) \u001b[91mHe\u001b[0m is more than \u001b[91mcapable\u001b[0m of playing that \u001b[91mrole\u001b[0m and 2) The \u001b[91mactual\u001b[0m \u001b[91mmain\u001b[0m \u001b[91mvillain\u001b[0m was not only not \u001b[91mintimidating\u001b[0m at all but also \u001b[91mquite\u001b[0m \u001b[91mannoying\u001b[0m. \u001b[91mAgain\u001b[0m, not blaming \u001b[91mVan\u001b[0m Damme. \u001b[91mI\u001b[0m \u001b[91mwill\u001b[0m always \u001b[91mbe\u001b[0m a \u001b[91mfan\u001b[0m, but \u001b[91mavoid\u001b[0m this one.\n",
      "\n",
      "It actually pains me to say it, but this movie was horrible on \u001b[92many\u001b[0m \u001b[92mladder\u001b[0m. The blame does not lie entirely with Van Damme as you can see he tried his best, but let's face it, he's almost \u001b[92mfortieth\u001b[0m, how much more can you ask of him? \u001b[92mme\u001b[0m find it so hard to believe that the same people who put together Undisputed 2; arguably the best (\u001b[92mouest\u001b[0m) martial arts movie in \u001b[92maging\u001b[0m, \u001b[92mengender\u001b[0m this. Everything from the plot, to the dialog, to the editing, to the overall acting was just \u001b[92mterrifically\u001b[0m \u001b[92mbringing\u001b[0m together and in \u001b[92mdiverse\u001b[0m \u001b[92mtrial\u001b[0m \u001b[92mabsolute\u001b[0m \u001b[92mblunt\u001b[0m and \u001b[92mwanton\u001b[0m. Scott \u001b[92mMcgee\u001b[0m who's fight scenes \u001b[92mconsidered\u001b[0m more \u001b[92manalog\u001b[0m a \u001b[92mshow\u001b[0m reel, was also terribly underused and not even the \u001b[92mprime\u001b[0m villain which is such a shame because 1) \u001b[92mIt\u001b[0m is more than \u001b[92mable\u001b[0m of playing that \u001b[92mroles\u001b[0m and 2) The \u001b[92mauthentic\u001b[0m \u001b[92mcritical\u001b[0m \u001b[92mvillainous\u001b[0m was not only not \u001b[92mthreaten\u001b[0m at all but also \u001b[92mvery\u001b[0m \u001b[92mfrustrating\u001b[0m. \u001b[92mTill\u001b[0m, not blaming \u001b[92mMinibus\u001b[0m Damme. \u001b[92mme\u001b[0m \u001b[92mdedication\u001b[0m always \u001b[92mis\u001b[0m a \u001b[92mfans\u001b[0m, but \u001b[92mbypassing\u001b[0m this one.\n",
      "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (68%)\u001b[0m\n",
      "\n",
      "Technically I'am a Van Damme Fan, or I was. this movie is so \u001b[91mbad\u001b[0m that I hated myself for \u001b[91mwasting\u001b[0m those 90 \u001b[91mminutes\u001b[0m. Do not \u001b[91mlet\u001b[0m the name Isaac Florentine (Undisputed II) fool you, \u001b[91mI\u001b[0m had big \u001b[91mhopes\u001b[0m for this one, depending on what I saw in (Undisputed II), man.. was I \u001b[91mwrong\u001b[0m ??! all action fans \u001b[91mwanted\u001b[0m a big comeback for the classic action hero, but i guess we wont be able to see that soon, as our hero keep coming with those (going -to-a-border - far-away-town-and -kill -the-bad-guys- than-comeback- home) movies I mean for God's sake, we are in 2008, and they insist on doing those \u001b[91mdisappointing\u001b[0m movies on every \u001b[91mlevel\u001b[0m. Why ??!!! Do your self a \u001b[91mfavor\u001b[0m, \u001b[91mskip\u001b[0m it.. seriously.\n",
      "\n",
      "Technically I'am a Van Damme Fan, or I was. this movie is so \u001b[92mwicked\u001b[0m that I hated myself for \u001b[92mlose\u001b[0m those 90 \u001b[92mmoments\u001b[0m. Do not \u001b[92mgonna\u001b[0m the name Isaac Florentine (Undisputed II) fool you, \u001b[92mme\u001b[0m had big \u001b[92mdesires\u001b[0m for this one, depending on what I saw in (Undisputed II), man.. was I \u001b[92mimperfect\u001b[0m ??! all action fans \u001b[92mdidnt\u001b[0m a big comeback for the classic action hero, but i guess we wont be able to see that soon, as our hero keep coming with those (going -to-a-border - far-away-town-and -kill -the-bad-guys- than-comeback- home) movies I mean for God's sake, we are in 2008, and they insist on doing those \u001b[92mregretful\u001b[0m movies on every \u001b[92mclass\u001b[0m. Why ??!!! Do your self a \u001b[92mprefers\u001b[0m, \u001b[92mleaps\u001b[0m it.. seriously.\n",
      "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (57%)\u001b[0m\n",
      "\n",
      "Honestly \u001b[91mawful\u001b[0m film, \u001b[91mbad\u001b[0m \u001b[91mediting\u001b[0m, \u001b[91mawful\u001b[0m lighting, \u001b[91mdire\u001b[0m dialog and \u001b[91mscrappy\u001b[0m \u001b[91mscreenplay\u001b[0m.<br /><br />The lighting at is \u001b[91mso\u001b[0m \u001b[91mbad\u001b[0m there's \u001b[91mmoments\u001b[0m you can't even \u001b[91msee\u001b[0m what's going on, \u001b[91mI\u001b[0m even tried to \u001b[91mplaying\u001b[0m with the \u001b[91mcontrast\u001b[0m and \u001b[91mbrightness\u001b[0m so I could \u001b[91msee\u001b[0m something but that didn't \u001b[91mhelp\u001b[0m.<br /><br />They must \u001b[91mhave\u001b[0m \u001b[91mfound\u001b[0m the script in a bin, the \u001b[91mcharacter\u001b[0m \u001b[91mdevelopment\u001b[0m is just as awful and while you hardly \u001b[91mexpect\u001b[0m \u001b[91mmuch\u001b[0m from a Jean-Claude \u001b[91mVan\u001b[0m Damme \u001b[91mfilm\u001b[0m this one \u001b[91mmanages\u001b[0m to \u001b[91mhit\u001b[0m an all time low. You can't even laugh at the cheesy'ness.<br /><br />\u001b[91mThe\u001b[0m \u001b[91mdirecting\u001b[0m and \u001b[91mediting\u001b[0m are also \u001b[91mterrible\u001b[0m, the whole \u001b[91mfilm\u001b[0m \u001b[91mfollows\u001b[0m an \u001b[91mextremely\u001b[0m \u001b[91mtired\u001b[0m \u001b[91mroutine\u001b[0m and \u001b[91mfails\u001b[0m at every \u001b[91mturn\u001b[0m as it bumbles through the \u001b[91mplot\u001b[0m that is \u001b[91mso\u001b[0m weak it's just \u001b[91munreal\u001b[0m.<br /><br />There's not a \u001b[91mlot\u001b[0m else to \u001b[91msay\u001b[0m other than it's \u001b[91mreally\u001b[0m \u001b[91mbad\u001b[0m and nothing like Jean-Claude Van Damme's \u001b[91mearlier\u001b[0m \u001b[91mwork\u001b[0m which you could \u001b[91menjoy\u001b[0m.<br /><br />\u001b[91mAvoid\u001b[0m like the \u001b[91mplaque\u001b[0m, \u001b[91mfrankly\u001b[0m \u001b[91mwords\u001b[0m \u001b[91mfail\u001b[0m me in condemning this \"film\".\n",
      "\n",
      "Honestly \u001b[92mhorrific\u001b[0m film, \u001b[92mfilthy\u001b[0m \u001b[92meditor\u001b[0m, \u001b[92mnasty\u001b[0m lighting, \u001b[92mterrifying\u001b[0m dialog and \u001b[92mfeisty\u001b[0m \u001b[92mdashes\u001b[0m.<br /><br />The lighting at is \u001b[92malso\u001b[0m \u001b[92mnaughty\u001b[0m there's \u001b[92mminute\u001b[0m you can't even \u001b[92mlisten\u001b[0m what's going on, \u001b[92mme\u001b[0m even tried to \u001b[92mplayback\u001b[0m with the \u001b[92mreverse\u001b[0m and \u001b[92mlight\u001b[0m so I could \u001b[92mpeek\u001b[0m something but that didn't \u001b[92msupported\u001b[0m.<br /><br />They must \u001b[92menjoys\u001b[0m \u001b[92mdiscovering\u001b[0m the script in a bin, the \u001b[92mqualities\u001b[0m \u001b[92melaborated\u001b[0m is just as awful and while you hardly \u001b[92mexpecting\u001b[0m \u001b[92mseverely\u001b[0m from a Jean-Claude \u001b[92mVans\u001b[0m Damme \u001b[92mteatro\u001b[0m this one \u001b[92mhandles\u001b[0m to \u001b[92mbeating\u001b[0m an all time low. You can't even laugh at the cheesy'ness.<br /><br />\u001b[92mBoth\u001b[0m \u001b[92mleadership\u001b[0m and \u001b[92meditors\u001b[0m are also \u001b[92mscary\u001b[0m, the whole \u001b[92mproductions\u001b[0m \u001b[92mfollowed\u001b[0m an \u001b[92mremarkably\u001b[0m \u001b[92mweary\u001b[0m \u001b[92mfrequent\u001b[0m and \u001b[92mfault\u001b[0m at every \u001b[92minflection\u001b[0m as it bumbles through the \u001b[92mplots\u001b[0m that is \u001b[92mwhy\u001b[0m weak it's just \u001b[92mawesome\u001b[0m.<br /><br />There's not a \u001b[92mlots\u001b[0m else to \u001b[92mmention\u001b[0m other than it's \u001b[92mdecidedly\u001b[0m \u001b[92mnaughty\u001b[0m and nothing like Jean-Claude Van Damme's \u001b[92manterior\u001b[0m \u001b[92macted\u001b[0m which you could \u001b[92mlikes\u001b[0m.<br /><br />\u001b[92mEvasion\u001b[0m like the \u001b[92mplaques\u001b[0m, \u001b[92msincerely\u001b[0m \u001b[92mmots\u001b[0m \u001b[92mlack\u001b[0m me in condemning this \"film\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import textattack\n",
    "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
    "from textattack.attack_recipes import TextFoolerJin2019\n",
    "from textattack.datasets import HuggingFaceDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 将模型和分词器包装到 HuggingFaceModelWrapper 中\n",
    "model_wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
    "\n",
    "# 选择攻击方法，这里使用 TextFooler\n",
    "attack = TextFoolerJin2019.build(model_wrapper)\n",
    "\n",
    "# 手动加载数据集并添加 tqdm 进度条\n",
    "ds = load_dataset(\"imdb\", split=\"test\")\n",
    "# 转换为 textattack 的数据集格式\n",
    "dataset = HuggingFaceDataset(ds)\n",
    "ds.save_to_disk(\"./imdb_test_dataset\")\n",
    "\n",
    "# 进行攻击\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=10,  # 攻击的样本数量\n",
    "    log_to_csv=\"attack_log.csv\",  # 保存攻击日志到 CSV 文件\n",
    "    checkpoint_interval=5,\n",
    "    checkpoint_dir=\"checkpoints\",\n",
    "    disable_stdout=True\n",
    ")\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "\n",
    "# 使用 tqdm 显示攻击进度\n",
    "print(\"开始攻击...\")\n",
    "results = []\n",
    "for result in tqdm(attacker.attack_dataset(), total=min(attack_args.num_examples, len(dataset))):\n",
    "    results.append(result)\n",
    "\n",
    "# 输出攻击结果\n",
    "for result in results:\n",
    "    print(result.__str__(color_method=\"ansi\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
