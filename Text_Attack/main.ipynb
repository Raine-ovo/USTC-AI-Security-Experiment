{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课程前言\n",
    "\n",
    "此为 <<人工智能安全>> 课程第一部分: 文本对抗攻击实验部分."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介绍bert，用来进行文本对抗攻击(victim model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先对一个样本进行攻击，查看攻击效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"textattack/bert-base-uncased-imdb\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# 定义原始文本\n",
    "text = \"The movie was fantastic! The acting was superb and the plot kept me engaged throughout.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与图像等连续数据不同，文本是离散的，因此需要采用不同的攻击思路。\n",
    "常用的文本扰动攻击分为**基于规则的扰动攻击**、**基于嵌入的扰动攻击**、**语义保持攻击**等。\n",
    "\n",
    "本次实验介绍两种文本扰动攻击方法：基于规则的扰动攻击、基于嵌入的扰动攻击、语义保持攻击。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基于规则的扰动攻击**\n",
    "\n",
    "这种攻击通过人为设计的规则对文本进行修改，常见方法包括：\n",
    "1. 字符级扰动\n",
    "    + 替换字符（如字母大小写、形近字替换）\n",
    "    + 插入/删除无关字符（如空格、标点）\n",
    "    + 拼写错误生成（如 \"hello\" -> \"h3llo\"\n",
    "2. 词汇级扰动\n",
    "    + 同义词替换\n",
    "    + 反义词替换\n",
    "    + 命名实体替换\n",
    "3. 句法级扰动\n",
    "    + 调整语序（如主动句 -> 被动句）\n",
    "    + 插入/删除冗余短语（如 \"非常\"、\"十分\"）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们来人为定义一个替换策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符串替换规则\n",
    "perturbation_map = {\n",
    "    'a': ['@', 'ä', 'à', 'á'],\n",
    "    'e': ['3', 'é', 'è'],\n",
    "    'i': ['1', '!', 'í'],\n",
    "    'o': ['0', 'ö', 'ó'],\n",
    "    's': ['$', '5'],\n",
    "    't': ['7', '+']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个方法实现了字符级别的扰动。\n",
    "接下来，我们只需要将这个映射到样本中，即可生成对抗样本。\n",
    "\n",
    "为了保持对抗样本的隐蔽性，需要引入一个概率值，文本中满足映射的字符将以某种概率进行替换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符级扰动攻击\n",
    "def char_perturbation(text, prob=0.2):\n",
    "    perturbed = []\n",
    "    for char in text.lower():\n",
    "        if char in perturbation_map and torch.rand(1).item() < prob:\n",
    "            choices = perturbation_map[char]\n",
    "            index = torch.multinomial(torch.ones(len(choices)), 1).item()\n",
    "            perturbed.append(choices[index])\n",
    "        else:\n",
    "            perturbed.append(char)\n",
    "    return ''.join(perturbed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看扰动效果和模型预测结果：\n",
    "\n",
    "> 由于样本太短，若效果不理想可多测试几次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: The movie was fantastic! The acting was superb and the plot kept me engaged throughout.\n",
      "Perturbed Text: 7hé movié was fàntas7ic! the ac7!ng wàs 5uperb änd 7he plo7 k3p+ me 3ngaged thróughöut.\n",
      "\n",
      "Original Prediction (neg/pos): [0.00285912 0.9971409 ]\n",
      "Perturbed Prediction (neg/pos): [0.988427   0.01157302]\n"
     ]
    }
   ],
   "source": [
    "# 测试原始样本和对抗样本的分类结果\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return torch.softmax(outputs.logits, dim=1).detach().numpy()\n",
    "\n",
    "def output_adversarial_example_and_prediction(text, attack):\n",
    "    perturbed_text = attack(text)\n",
    "    print(\"Original Text:\", text)\n",
    "    print(\"Perturbed Text:\", perturbed_text)\n",
    "\n",
    "    original_prob = predict(text)\n",
    "    perturbed_prob = predict(perturbed_text)\n",
    "\n",
    "    print(\"\\nOriginal Prediction (neg/pos):\", original_prob[0])\n",
    "    print(\"Perturbed Prediction (neg/pos):\", perturbed_prob[0])\n",
    "\n",
    "output_adversarial_example_and_prediction(text, char_perturbation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**基于嵌入的扰动攻击**\n",
    "\n",
    "这种攻击利用词嵌入来生成对抗样本：具体来说，模型会将输入样本变成一个向量，这个向量就代表这个词，这样就回到了连续空间的扰动了。我们可以采取连续空间对抗扰动方法如FGSM，或使用Word2Vec模型来找出距离词向量语义最近的词来替换单词，实现词汇级别的扰动。\n",
    "\n",
    "我们接下来介绍这两种方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_perturbation(model, input_text, labels, epsilon, tokenizer):\n",
    "    '''\n",
    "    使用 FGSM 对输入文本进行扰动\n",
    "    参数：\n",
    "        model: 目标模型\n",
    "        input_text: 输入文本\n",
    "        labels: 对应标签\n",
    "        epsilon: 扰动强度\n",
    "        tokenizer: 分词器\n",
    "    返回\n",
    "        perturbed_text: 扰动后的文本\n",
    "    '''\n",
    "\n",
    "    # 对输入文本进行分词并转换为张量\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # 由于输入input的词向量不属于叶子节点，无法进行梯度计算，因此需要克隆一份作为叶子节点\n",
    "    # 计算时直接使用克隆后的 embeddings 的梯度作为词嵌入的梯度\n",
    "    embeddings = model.get_input_embeddings()(inputs['input_ids'])\n",
    "    embeddings = embeddings.detach().clone()\n",
    "    embeddings.requires_grad = True\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        # 使用嵌入表示作为输入\n",
    "        outputs = model(inputs_embeds=embeddings, attention_mask=inputs['attention_mask'])\n",
    "        loss = nn.CrossEntropyLoss()(outputs.logits, labels.to(model.device))\n",
    "\n",
    "        gradients = torch.autograd.grad(loss, embeddings)[0]\n",
    "        sign_gradients = gradients.sign()\n",
    "\n",
    "        # 对嵌入表示进行扰动\n",
    "        perturbed_embeddings = embeddings + epsilon * sign_gradients\n",
    "\n",
    "    # 将扰动后的嵌入表示转换回输入 ID\n",
    "    perturbed_input_ids = torch.argmax(torch.matmul(perturbed_embeddings, model.get_input_embeddings().weight.t()), dim=-1)\n",
    "\n",
    "    perturbed_text = tokenizer.decode(perturbed_input_ids.squeeze(), skip_special_tokens=True)\n",
    "    return perturbed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: The movie was fantastic! The acting was superb and the plot kept me engaged throughout.\n",
      "Perturbed Text: themori 780rada! 338 670 she superb 670 the plot kept 670 engaged halftime\n",
      "\n",
      "Original Prediction (pos/neg): [0.00285912 0.9971409 ]\n",
      "Perturbed Prediction (pos/neg): [0.59968483 0.40031517]\n"
     ]
    }
   ],
   "source": [
    "output_adversarial_example_and_prediction(text, lambda x: fgsm_perturbation(model, x, torch.tensor([1]), 0.1, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FGSM是白盒攻击算法，在黑盒场景下，我们也可以借助现有的词嵌入器如 Word2Vec 模型来进行词汇级替换，具体而言，Word2Vec筛选出每个词汇的语义最近的若干个词汇，然后随机挑选一个进行替换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: The movie was fantastic! The acting was superb and the plot kept me engaged throughout.\n",
      "Perturbed Text: the movie seemed fantastic ! that acting felt excellent and in plot remained yeah engages through .\n",
      "\n",
      "Original Prediction (neg/pos): [0.00285912 0.9971409 ]\n",
      "Perturbed Prediction (neg/pos): [0.71860474 0.28139523]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"word2vec-google-news-300.model\"):\n",
    "    # 加载预训练的 Word2Vec 模型\n",
    "    vec_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "    # 自选下载到本地与否\n",
    "    # vec_model.save(\"word2vec-google-news-300.model\")\n",
    "else:\n",
    "    from gensim.models import KeyedVectors\n",
    "    vec_model = KeyedVectors.load(\"word2vec-google-news-300.model\")\n",
    "\n",
    "def word_embedding_perturbation(vec_model, text, num_words=15, prob=0.7):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    perturbed_tokens = []\n",
    "    for token in tokens:\n",
    "        if token in vec_model and torch.rand(1).item() < prob:\n",
    "            similar_words = vec_model.most_similar(token, topn=num_words)\n",
    "            new_word = similar_words[torch.randint(0, num_words, (1,)).item()][0]\n",
    "            perturbed_tokens.append(new_word)\n",
    "        else:\n",
    "            perturbed_tokens.append(token)\n",
    "    return \" \".join(perturbed_tokens)\n",
    "\n",
    "output_adversarial_example_and_prediction(text, lambda x: word_embedding_perturbation(vec_model, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextAttack\n",
    "\n",
    "TextAttack是一个用于自然语言理解（NLP）领域的开源框架，它支持对抗性攻击、数据增强和模型训练。该框架提供了一种标准化的方法构建和执行针对NLP模型的攻击，具体可参考 `additional_reading.ipynb` 文件。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
