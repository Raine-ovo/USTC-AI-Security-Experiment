{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课程前言\n",
    "\n",
    "此为 <<人工智能安全>> 课程第一部分: 文本对抗攻击实验部分."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此前我们探讨了连续型数据（如图像像素）的扰动方法，本节课将聚焦离散型数据---文本的对抗扰动技术。\n",
    "\n",
    "相较于图像在连续空间的可微特性，文本数据具有离散组合特征，因此其对抗攻击需要使用差异化的设计思路。\n",
    "\n",
    "文本对抗扰动指通过对原始文本进行局部语义保持性修改（如替换、插入或删除特定字符），生成人类可读但能导致NLP模型误判的对抗样本。\n",
    "\n",
    "文本扰动技术核心在于两点：\n",
    "1. 确保扰动后的文本符合语法规范且语义连贯\n",
    "2. 能通过最小化修改幅度使对抗样本逃逸模型检测并维持人类可读性\n",
    "\n",
    "以情感分类任务为例，将负面评价“这部电影非常糟糕”中关键形容词替换为语义弱化的“差强人意”，可能误导模型将其误判为中性情感。此类攻击揭示了NLP模型对语义细微变化的脆弱性。\n",
    "\n",
    "目前主流的文本对抗攻击方法可以按两个维度分类：\n",
    "1. 扰动粒度：根据修改单元分为字符级、词级或短语级攻击\n",
    "2. 生成策略：依据搜索算法分为基于梯度的优化方法或启发式替代策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 实验准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT是由Google提出的基于Transformer架构的预训练语言模型，通过双向上下文理解实现文本表征，bert-base-uncased-imdb 则是BERT在IMDB影评数据集上微调的版本，主要用于情感二分类（负面/正面评价），准确率约为 94%。\n",
    "\n",
    "本次实验，我们使用 bert-base-uncased-imdb 情感分类模型来作为文本对抗攻击的测试基准。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先对一个样本进行攻击，查看攻击效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 17:36:33.622969: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-13 17:36:33.860390: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-13 17:36:34.637411: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "model_name = \"textattack/bert-base-uncased-imdb\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# 定义原始文本\n",
    "text = \"The movie was fantastic! The acting was superb and the plot kept me engaged throughout.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基于规则的扰动攻击**\n",
    "\n",
    "这种攻击通过人为设计的规则对文本进行修改，实现方法比较简单。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们来人为定义一个替换策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符串替换规则\n",
    "perturbation_map = {\n",
    "    'a': ['@', 'ä', 'à', 'á'],\n",
    "    'e': ['3', 'é', 'è'],\n",
    "    'i': ['1', '!', 'í'],\n",
    "    'o': ['0', 'ö', 'ó'],\n",
    "    's': ['$', '5'],\n",
    "    't': ['7', '+']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个方法实现了字符级别的扰动。\n",
    "接下来，我们只需要将这个映射到样本中，即可生成对抗样本。\n",
    "\n",
    "为了保持对抗样本的隐蔽性，需要引入一个概率值，文本中满足映射的字符将以某种概率进行替换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符级扰动攻击\n",
    "def char_perturbation(texts, prob=0.2):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "        single_output = True\n",
    "    else:\n",
    "        single_output = False\n",
    "\n",
    "    perturbed_texts = []\n",
    "    for text in texts:\n",
    "        perturbed = []\n",
    "        for char in text.lower():\n",
    "            if char in perturbation_map and torch.rand(1).item() < prob:\n",
    "                choices = perturbation_map[char]\n",
    "                index = torch.multinomial(torch.ones(len(choices)), 1).item()\n",
    "                perturbed.append(choices[index])\n",
    "            else:\n",
    "                perturbed.append(char)\n",
    "        perturbed_texts.append(''.join(perturbed))\n",
    "\n",
    "    if single_output:\n",
    "        return perturbed_texts[0]\n",
    "    else:\n",
    "        return perturbed_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看扰动效果和模型预测结果：\n",
    "\n",
    "> 由于样本太短，若效果不理想可多测试几次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: The movie was fantastic! The acting was superb and the plot kept me engaged throughout.\n",
      "Perturbed Text: th3 movie w@s fant@stic! the ac+ing was 5uperb and the plot kept me engagèd throughout.\n",
      "\n",
      "Original Prediction (neg/pos): [0.00285911 0.9971409 ]\n",
      "Perturbed Prediction (neg/pos): [0.04222588 0.9577741 ]\n"
     ]
    }
   ],
   "source": [
    "# 测试原始样本和对抗样本的分类结果\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "    return torch.softmax(outputs.logits, dim=1).detach().cpu().numpy()\n",
    "\n",
    "def output_adversarial_example_and_prediction(text, attack):\n",
    "    perturbed_text = attack(text)\n",
    "    print(\"Original Text:\", text)\n",
    "    print(\"Perturbed Text:\", perturbed_text)\n",
    "\n",
    "    original_prob = predict(text)\n",
    "    perturbed_prob = predict(perturbed_text)\n",
    "\n",
    "    print(\"\\nOriginal Prediction (neg/pos):\", original_prob[0])\n",
    "    print(\"Perturbed Prediction (neg/pos):\", perturbed_prob[0])\n",
    "\n",
    "output_adversarial_example_and_prediction(text, char_perturbation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基于嵌入的扰动攻击**\n",
    "\n",
    "这种攻击方法利用词向量空间来生成对抗样本，即连续空间梯度与离散空间语义替换。\n",
    "\n",
    "模型首先通过 $embedding$ 层，将离散词汇映射至连续向量空间，这似乎就与之前所讲的图像对抗攻击优化目标相同了，因此我们现在有两种思路：\n",
    "1. 连续梯度扰动（如 FGSM ）：基于梯度符号法直接在词向量空间施加微小扰动，在数学上能够保证 $\\epsilon-ball$ 的向量邻近性。\n",
    "2. 离散语义替换（如 Word2Vec ）：在词嵌入空间中检索k-邻近有效词汇集合并选取一个进行替换。\n",
    "\n",
    "我们分别阐述这两种方法的实现细节："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_perturbation(model, input_text, labels, epsilon, tokenizer):\n",
    "    '''\n",
    "    使用 FGSM 对输入文本进行扰动\n",
    "    参数：\n",
    "        model: 目标模型\n",
    "        input_text: 输入文本\n",
    "        labels: 对应标签\n",
    "        epsilon: 扰动强度\n",
    "        tokenizer: 分词器\n",
    "    返回\n",
    "        perturbed_text: 扰动后的文本\n",
    "    '''\n",
    "\n",
    "    # 对输入文本进行分词并转换为张量\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    # 由于输入input的词向量不属于叶子节点，无法进行梯度计算，因此需要克隆一份作为叶子节点\n",
    "    # 计算时直接使用克隆后的 embeddings 的梯度作为词嵌入的梯度\n",
    "    embeddings = model.get_input_embeddings()(inputs['input_ids'])\n",
    "    embeddings = embeddings.detach().clone()\n",
    "    embeddings.requires_grad = True\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        # 使用嵌入表示作为输入\n",
    "        outputs = model(inputs_embeds=embeddings, attention_mask=inputs['attention_mask'])\n",
    "        loss = nn.CrossEntropyLoss()(outputs.logits, labels.to(model.device))\n",
    "\n",
    "        gradients = torch.autograd.grad(loss, embeddings)[0]\n",
    "        sign_gradients = gradients.sign()\n",
    "\n",
    "        # 对嵌入表示进行扰动\n",
    "        perturbed_embeddings = embeddings + epsilon * sign_gradients\n",
    "\n",
    "    # 将扰动后的嵌入表示转换回输入 ID\n",
    "    perturbed_input_ids = torch.argmax(torch.matmul(perturbed_embeddings, model.get_input_embeddings().weight.t()), dim=-1)\n",
    "\n",
    "    perturbed_text = tokenizer.decode(perturbed_input_ids.squeeze(), skip_special_tokens=True)\n",
    "    return perturbed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: The movie was fantastic! The acting was superb and the plot kept me engaged throughout.\n",
      "Perturbed Text: themori 780rada! 338 670 she superb 670 the plot kept 670 engaged halftime\n",
      "\n",
      "Original Prediction (neg/pos): [0.00285911 0.9971409 ]\n",
      "Perturbed Prediction (neg/pos): [0.5996884 0.4003116]\n"
     ]
    }
   ],
   "source": [
    "output_adversarial_example_and_prediction(text, lambda x: fgsm_perturbation(model, x, torch.tensor([1]), 0.1, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验表明，尽管FGSM攻击能够通过生成对抗样本误导模型分类，但其产生的文本可读性显著降低，违背了对抗扰动攻击需保持人类可读性的约束。\n",
    "\n",
    "这是因为，FGSM在词向量空间中搜索扰动时，虽能保证生成向量与原始词嵌入的几何邻近性（即语义相似性），但词嵌入空间到实际词汇的映射并非双射关系——经扰动后的向量可能落入\"空洞区域\"，无法对应词典中的有效词汇。这种词向量离散化过程中的语义断裂，最终导致对抗样本丧失语言连贯性。\n",
    "\n",
    "因此，直接在词嵌入空间依据梯度符号进行攻击是**不合理**的，我们考虑另外一种思路。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了保证语义的连贯性，我们可以使用基于预训练词向量模型（如Word2Vec）进行替换策略，该策略利用余弦相似度计算在词嵌入空间中检索目标词的Top-K语义邻近词，进而通过概率采样策略选取替代词汇。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: The movie was fantastic! The acting was superb and the plot kept me engaged throughout.\n",
      "Perturbed Text: the films was fantastic ! the acting seemed faultless and the plot Kept ÔI involved through .\n",
      "\n",
      "Original Prediction (neg/pos): [0.00285911 0.9971409 ]\n",
      "Perturbed Prediction (neg/pos): [0.00522057 0.99477947]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"word2vec-google-news-300.model\"):\n",
    "    # 加载预训练的 Word2Vec 模型\n",
    "    vec_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "    # 自选下载到本地与否\n",
    "    # vec_model.save(\"word2vec-google-news-300.model\")\n",
    "else:\n",
    "    from gensim.models import KeyedVectors\n",
    "    vec_model = KeyedVectors.load(\"word2vec-google-news-300.model\")\n",
    "\n",
    "def word_embedding_perturbation(vec_model, texts, num_words=10, prob=0.7):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "        single_output = True\n",
    "    else:\n",
    "        single_output = False\n",
    "\n",
    "    perturbed_texts = []\n",
    "    for text in texts:\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        perturbed_tokens = []\n",
    "        for token in tokens:\n",
    "            if token in vec_model and torch.rand(1).item() < prob:\n",
    "                similar_words = vec_model.most_similar(token, topn=num_words)\n",
    "                new_word = similar_words[torch.randint(0, num_words, (1,)).item()][0]\n",
    "                perturbed_tokens.append(new_word)\n",
    "            else:\n",
    "                perturbed_tokens.append(token)\n",
    "        perturbed_texts.append(' '.join(perturbed_tokens))\n",
    "\n",
    "    if single_output:\n",
    "        return perturbed_texts[0]\n",
    "    else:\n",
    "        return perturbed_texts\n",
    "\n",
    "output_adversarial_example_and_prediction(text, lambda x: word_embedding_perturbation(vec_model, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们使用 imdb 数据集中的测试集，来进行 bert-base-uncased-imdb 模型的对抗测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "test_dataset = load_dataset(\"imdb\", split=\"test\")\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "required_columns = ['input_ids', 'attention_mask', 'label', 'text']\n",
    "test_dataset.set_format(type='torch', columns=required_columns)\n",
    "\n",
    "# 取 1024 个样本作测试\n",
    "n_samples = 1024\n",
    "subset_test_dataset = test_dataset.shuffle(seed=42).select(range(n_samples))\n",
    "\n",
    "test_dataloader = DataLoader(subset_test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader, attack):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        original_texts = batch[\"text\"]\n",
    "        if attack:\n",
    "            perturbed_texts = attack(original_texts)\n",
    "        else:\n",
    "            perturbed_texts = original_texts\n",
    "        inputs = tokenizer(perturbed_texts, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=128)\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.softmax(logits, dim=1)\n",
    "\n",
    "            # 将预测的概率值转换为类别标签\n",
    "            pred_labels = torch.argmax(preds, dim=1).cpu().tolist()\n",
    "            predictions.extend(pred_labels)\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    return predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型准确率为:  88.48%\n",
      "模型准确率为:  79.00%\n"
     ]
    }
   ],
   "source": [
    "predictions, true_labels = evaluation(model, test_dataloader, None)\n",
    "clean_accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"模型准确率为: {clean_accuracy * 100: .2f}%\")\n",
    "\n",
    "predictions, true_labels = evaluation(model, test_dataloader, char_perturbation)\n",
    "char_perturbation_accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"模型准确率为: {char_perturbation_accuracy * 100: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于字符替换规则较少且相对简单，可能会导致模型准确率较高，这里仅作参考。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions, true_labels \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m(model, test_dataloader, \u001b[38;5;28;01mlambda\u001b[39;00m x: word_embedding_perturbation(vec_model, x))\n\u001b[1;32m      2\u001b[0m char_perturbation_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(true_labels, predictions)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m模型准确率为: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchar_perturbation_accuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluation' is not defined"
     ]
    }
   ],
   "source": [
    "predictions, true_labels = evaluation(model, test_dataloader, lambda x: word_embedding_perturbation(vec_model, x))\n",
    "char_perturbation_accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"模型准确率为: {char_perturbation_accuracy * 100: .2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextAttack\n",
    "\n",
    "TextAttack是一个用于自然语言处理对抗攻击的 Python 库，它提供了丰富的攻击方法和模型接口。我们可以利用它实现快速方便的对抗攻击测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 16:28:53.963691: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-13 16:28:54.322066: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-13 16:28:55.822352: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/raine/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载模型和分词器...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m正在加载模型和分词器...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 将模型和分词器包装到 HuggingFaceModelWrapper 中\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m model_wrapper \u001b[38;5;241m=\u001b[39m HuggingFaceModelWrapper(\u001b[43mmodel\u001b[49m, tokenizer)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m正在加载攻击方法...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 选择攻击方法，这里使用 TextFooler\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import textattack\n",
    "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
    "from textattack.attack_recipes import TextFoolerJin2019\n",
    "from textattack.datasets import HuggingFaceDataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "print(\"正在加载模型和分词器...\")\n",
    "# 将模型和分词器包装到 HuggingFaceModelWrapper 中\n",
    "model_wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
    "\n",
    "print(\"正在加载攻击方法...\")\n",
    "# 选择攻击方法，这里使用 TextFooler\n",
    "attack = TextFoolerJin2019.build(model_wrapper)\n",
    "\n",
    "# 手动加载数据集并添加 tqdm 进度条\n",
    "print(\"正在下载数据集...\")\n",
    "ds = load_dataset(\"imdb\", split=\"test\")\n",
    "# 转换为 textattack 的数据集格式\n",
    "dataset = HuggingFaceDataset(ds)\n",
    "ds.save_to_disk(\"./imdb_test_dataset\")\n",
    "\n",
    "# 进行攻击\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=10,  # 攻击的样本数量\n",
    "    log_to_csv=\"attack_log.csv\",  # 保存攻击日志到 CSV 文件\n",
    "    checkpoint_interval=5,\n",
    "    checkpoint_dir=\"checkpoints\",\n",
    "    disable_stdout=True\n",
    ")\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "\n",
    "# 使用 tqdm 显示攻击进度\n",
    "print(\"开始攻击...\")\n",
    "results = []\n",
    "for result in tqdm(attacker.attack_dataset(), total=min(attack_args.num_examples, len(dataset))):\n",
    "    results.append(result)\n",
    "\n",
    "# 输出攻击结果\n",
    "for result in results:\n",
    "    print(result.__str__(color_method=\"ansi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TextAttack 库还提供了端到端的使用方法，具体可参考 `additional_reading.ipynb` 文件。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
