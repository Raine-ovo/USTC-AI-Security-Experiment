{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99a32b6",
   "metadata": {},
   "source": [
    "# 数据安全攻击"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0415f",
   "metadata": {},
   "source": [
    "## 成员推理攻击（Membership Inference Attack）\n",
    "成员推理攻击的攻击目标是判断一个输入样本**是否存在于模型的训练数据集**中，可能会导致数据泄露、隐私泄露等风险。由于人工智能模型易过拟合训练数据、训练数据与测试数据分布的差异性等原因，使得深度学习模型易遭受成员推理攻击。\n",
    "\n",
    "本节实验使用影子模型攻击来实现简单的成员推理攻击。其主要想法是，训练多个“影子模型”，通过影子模型来模拟受害者模型的表现，然后根据影子模型的训练情况构建攻击数据集。使用该攻击数据集训练的二分类模型可以判断一个输入样本是否是来自受害者模型的训练集。\n",
    "\n",
    "其主要流程如下图所示：\n",
    "<p align=\"center\">\n",
    "<img src=\"./src/overview.png\" style=\"center\" width=\"70%\">\n",
    "<center>影子模型攻击流程</center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d977ba",
   "metadata": {},
   "source": [
    "### 1. 训练受害者模型\n",
    "首先使用 sklearn.datasets.load_wine() 加载葡萄酒分类数据集。\n",
    "\n",
    "葡萄酒分类数据集是一个非常小且简单的数据集，其具体信息如下：\n",
    "数据集包含 178 个样本，每个样本拥有 13 种不同的化学特征（即每个样本有 13 维特征），包括酸度、灰分，酒精浓度等。然后一共有三种不同类别的葡萄酒，对应标签0到2。\n",
    "\n",
    "详细信息可参考[这个网页](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3766c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载葡萄酒分类数据集\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "data, target = load_wine(return_X_y=True)\n",
    "# 将每一维度缩放至0到1\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "# 查看数据集的形状\n",
    "print(\"数据集的形状:\", data.shape)\n",
    "# 查看数据集的前5行\n",
    "print(\"数据集的前5行:\\n\", data[:5])\n",
    "# 查看数据集的标签\n",
    "print(\"数据集的标签:\", target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73440f4d",
   "metadata": {},
   "source": [
    "使用随机森林分类器来作为被攻击的目标模型（受害者模型）。\n",
    "随机森林分类器的具体api参数内容可以参考[sklearn的官方网站](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "\n",
    "该分类器使用 .fit(X, y) 函数进行训练，使用 .predict(X) 函数来预测对应标签，使用 .predict_proba(X) 函数来获取每个标签的预测概率值。其中 X 的形状为（批次，特征数）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f10bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_model = RandomForestClassifier(n_estimators=100)\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.4, random_state=42)\n",
    "# 训练模型\n",
    "victim_model.fit(X_train, y_train)\n",
    "# 测试模型准确性\n",
    "accuracy = victim_model.score(X_test, y_test)\n",
    "print(\"模型准确性:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a9a23",
   "metadata": {},
   "source": [
    "定义查询模型的函数：输入样本 $x \\rightarrow$ 预测概率向量 $prob$ ，来模拟通过api访问模型的应用场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟通过api访问模型，得到模型的概率预测输出\n",
    "def query_model(model, x):\n",
    "    return model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d93d73",
   "metadata": {},
   "source": [
    "### 2. 合成数据集\n",
    "由于攻击者无从得知受害者模型的训练集，而训练一个判断输入样本是否属于训练集的二分类模型需要相应的数据。因此，文章借助爬山算法来合成影子模型的训练数据集。具体算法如下：\n",
    "<p align=\"center\">\n",
    "<img src=\"./src/synthesis.png\" style=\"center\" width=\"40%\">\n",
    "<center>合成数据集的算法</center>\n",
    "</p>\n",
    "值得注意的是，该算法运行时间较长，面对具有更多特征的数据集（如图像数据集）并不适用。文章提出在那些场景下，攻击者可能需要具有部分训练数据集的知识，如获得同分布但是无交集的数据集、或者可以得到扰动后的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合成数据集，适用于无法获取真实数据集的情况\n",
    "# 对于 features 较多的情况不适用\n",
    "def synthesize_data(model, label, num_iter, conf_min, rej_max, k_max, k_min, num_features):\n",
    "    \"\"\"\n",
    "    合成数据集算法\n",
    "    \n",
    "    参数:\n",
    "    model: 目标模型\n",
    "    label: 想要合成的样本标签\n",
    "    num_iter: 最大迭代次数\n",
    "    conf_min: 接受合成样本的最小置信度阈值\n",
    "    rej_max: 连续拒绝的最大次数\n",
    "    k_max, k_min: 每次迭代中随机改变的特征数量范围\n",
    "    num_features: 特征总数\n",
    "    \n",
    "    返回:\n",
    "    合成的样本特征向量或None\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO：根据伪代码实现合成数据集算法\n",
    "\n",
    "    \n",
    "    # 达到最大迭代次数仍未找到合适样本，返回None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbdd242",
   "metadata": {},
   "source": [
    "合成影子模型训练所需数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synthetic_data(num_samples, num_features, model, num_classes, num_iter=1000, conf_min=0.8, rej_max=10, k_max=3, k_min=1):\n",
    "    # 生成合成数据\n",
    "    synthesize_data_list = []\n",
    "    label_list = []\n",
    "    for i in tqdm(range(num_samples // num_classes)):\n",
    "        for label in range(num_classes):\n",
    "            x = None\n",
    "            while x is None:\n",
    "                x = synthesize_data(model, label, num_iter\n",
    "                                    , conf_min, rej_max, k_max, k_min, num_features)\n",
    "            synthesize_data_list.append(x)\n",
    "            label_list.append(label)\n",
    "    return synthesize_data_list, label_list\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "synthesize_data_train, synthesize_label_train = get_synthetic_data(num_samples=100, num_features=X_train.shape[1], model=victim_model, num_classes=num_classes)\n",
    "# 将合成数据转换为 numpy 数组\n",
    "synthesize_data_train, synthesize_label_train = np.array(synthesize_data_train), np.array(synthesize_label_train)\n",
    "\n",
    "synthesize_data_test, synthesize_label_test = get_synthetic_data(num_samples=100, num_features=X_test.shape[1], model=victim_model, num_classes=num_classes)\n",
    "synthesize_data_test, synthesize_label_test = np.array(synthesize_data_test), np.array(synthesize_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d33eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存合成数据集\n",
    "import os\n",
    "if not os.path.exists('./data'):\n",
    "    os.makedirs('./data')\n",
    "np.save('./data/synthesize_data_train.npy', synthesize_data_train)\n",
    "np.save(\"./data/synthesis_label_train.npy\", synthesize_label_train)\n",
    "np.save('./data/synthesize_data_test.npy', synthesize_data_test)\n",
    "np.save(\"./data/synthesis_label_test.npy\", synthesize_label_test)\n",
    "print(\"合成数据集已保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a89940",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesize_data_train = np.load('./data/synthesize_data_train.npy')\n",
    "synthesize_label_train = np.load(\"./data/synthesis_label_train.npy\")\n",
    "synthesize_data_test = np.load('./data/synthesize_data_test.npy')\n",
    "synthesize_label_test = np.load(\"./data/synthesis_label_test.npy\")\n",
    "print(\"合成数据集已加载\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7debf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(synthesize_data_train.shape)\n",
    "print(synthesize_label_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b43be9",
   "metadata": {},
   "source": [
    "### 3. 训练影子模型\n",
    "使用合成数据集训练影子模型，并且构建训练攻击模型所用的二分类数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26461df9",
   "metadata": {},
   "source": [
    "由于攻击者不知道受害者模型训练的具体信息，而为了训练攻击的二分类模型（用于判断一个给定的输入是否在训练集中），攻击者需要构建一个（预测向量，是否在训练数据集中）的数据集来训练攻击模型。\n",
    "\n",
    "攻击者可以通过构建多个影子模型，并且将合成数据集分为多份（彼此可重叠）来训练不同的影子模型，使得构建的攻击数据集更多样化。\n",
    "\n",
    "而对于影子模型，攻击者知道一个样本是否是来自其训练数据集，因此可以构建训练攻击模型所需的数据集。影子模型的数量越多，产生的样本对越多，越利于攻击的二分类模型的训练。\n",
    "\n",
    "对于攻击数据集，其每一个样本包含三部分，模型的预测向量 $\\mathbf{y}$，真实标签 $y$，以及其是否在训练数据集中（0代表不在训练集中，1代表在训练集中）：\n",
    "$$\n",
    "D_{attack}=\\{(\\mathbf{y} ,y) , \\text{in-or-out} \\}_{i=1}^n\n",
    "$$\n",
    "其中 in-or-out 是0-1变量，代表该样本对是否在训练集中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4479b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将合成数据集分成 num_shared 份，可重叠\n",
    "def split_dataset(dataset, true_label, num_shadows, num_classes, length):\n",
    "    splits = []\n",
    "    labels = []\n",
    "    for i in range(num_shadows):\n",
    "        split = []\n",
    "        label = []\n",
    "        for j in range(num_classes):\n",
    "            idx = np.where(true_label == j)[0]\n",
    "            if len(idx) < length:\n",
    "                length = len(idx)\n",
    "            selected_idx = np.random.choice(idx, size=length, replace=False)\n",
    "            split.append(dataset[selected_idx])\n",
    "            label.append(true_label[selected_idx])\n",
    "        splits.append(np.concatenate(split, axis=0))\n",
    "        labels.append(np.concatenate(label, axis=0))\n",
    "    return splits, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640efdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(synthesize_label_train))\n",
    "num_shadows = 20\n",
    "attack_X = []\n",
    "attack_y = []\n",
    "\n",
    "shadow_train_list, train_label_list = split_dataset(synthesize_data_train, synthesize_label_train, num_shadows, num_classes, len(synthesize_data_train) // 2)\n",
    "shadow_test_list, test_label_list = split_dataset(synthesize_data_test, synthesize_label_test, num_shadows, num_classes, len(synthesize_data_test) // 2)\n",
    "# 训练影子模型\n",
    "for i in range(num_shadows):\n",
    "    shadow_model = RandomForestClassifier(n_estimators=100, random_state=i)\n",
    "    shadow_model.fit(shadow_train_list[i], train_label_list[i])\n",
    "    # 测试影子模型的准确性\n",
    "    shadow_model_accuracy = shadow_model.score(shadow_test_list[i], test_label_list[i])\n",
    "    print(f\"Shadow model {i} accuracy: {shadow_model_accuracy}\")\n",
    "\n",
    "    # 使用影子模型生成攻击二分类数据集\n",
    "    in_pred = query_model(shadow_model, shadow_train_list[i])\n",
    "    in_features = np.hstack((in_pred, train_label_list[i].reshape(-1, 1)))\n",
    "    attack_X.append(in_features)\n",
    "    attack_y.append(np.ones((in_pred.shape[0], 1)))\n",
    "\n",
    "    out_pred = query_model(shadow_model, shadow_test_list[i])\n",
    "    out_features = np.hstack((out_pred, test_label_list[i].reshape(-1, 1)))\n",
    "    attack_X.append(out_features)\n",
    "    attack_y.append(np.zeros((out_pred.shape[0], 1)))\n",
    "print(\"successfully generate attack dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c959a5",
   "metadata": {},
   "source": [
    "使用合成数据集构建二分类所用数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_X = np.vstack(attack_X)\n",
    "attack_y = np.vstack(attack_y).reshape(-1)\n",
    "print(\"attack_X shape:\", attack_X.shape)\n",
    "print(\"attack_y shape:\", attack_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa22dac",
   "metadata": {},
   "source": [
    "### 4. 训练攻击二分类模型\n",
    "接下来，借助影子模型构建的攻击数据集，我们可以训练二分类模型。提出影子模型攻击的论文指出，该二分类模型是独立于之前的影子模型训练过程的，因此可以根据任务需求选择适合的模型进行训练。\n",
    "\n",
    "这里我们依然采用随机森林分类器作为二分类的攻击模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b121193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练攻击模型\n",
    "attack_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "attack_model.fit(attack_X, attack_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0b0957",
   "metadata": {},
   "source": [
    "接下来在真实的训练集以及测试集（即受害者模型所训练的数据集以及测试集）上测试我们的攻击效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试攻击模型\n",
    "def test_attack_model(attack_model, victim_model, X_train, y_train, X_test, y_test):\n",
    "    num_train = 0\n",
    "    num_test = 0\n",
    "    acc_train = 0\n",
    "    acc_test = 0\n",
    "    \n",
    "    preds = query_model(victim_model, X_train)\n",
    "    features = np.hstack((preds, y_train.reshape(-1, 1)))\n",
    "    train_pred = attack_model.predict(features)\n",
    "    num_train += len(train_pred)\n",
    "    acc_train += np.sum(train_pred == 1)\n",
    "\n",
    "    preds = query_model(victim_model, X_test)\n",
    "    features = np.hstack((preds, y_test.reshape(-1, 1)))\n",
    "    test_pred = attack_model.predict(features)\n",
    "    num_test += len(test_pred)\n",
    "    acc_test += np.sum(test_pred == 0)\n",
    "    print(\"训练集攻击模型准确率:\", acc_train / num_train)\n",
    "    print(\"测试集攻击模型准确率:\", acc_test / num_test)\n",
    "    print(\"\\n一些指标：\")\n",
    "    accuracy = (acc_train + acc_test) / (num_train + num_test)\n",
    "    print(\"攻击模型准确率 accuracy:\", accuracy)\n",
    "    precision = acc_train / (acc_train + num_test - acc_test)\n",
    "    print(\"精确率 precision:\", precision)\n",
    "    recall = acc_train / num_train\n",
    "    print(\"召回率 recall:\", recall)\n",
    "    print(\"F1-score:\", 2 * precision * recall / (precision + recall))\n",
    "    \n",
    "test_attack_model(attack_model, victim_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d5738",
   "metadata": {},
   "source": [
    "一个随机猜测的二分类判断器准确率为 $50%$，而我们的攻击分类器达到了 $60\\%+$，说明该攻击有一定效果。\n",
    "\n",
    "此外，影子模型攻击存在诸多限制：\n",
    "- 攻击者需要知道目标模型结构\n",
    "- 目标模型需要过拟合才能达到较好的攻击效果\n",
    "- 局限于特征数少的分类任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9749442f",
   "metadata": {},
   "source": [
    "### 5. 简单的防御思路\n",
    "同上一次实验中模型窃取的防御思路一致。可以采取模糊化模型输出向量的方式进行防御，使模型输出包含尽可能少的信息。可以将 query_model() 函数的输出换成模糊后的概率向量来模拟模糊化输出的过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟通过api访问模型，得到模糊化后的概率预测输出\n",
    "def query_model(model, x):\n",
    "    result = model.predict_proba(x)\n",
    "    # 模糊化处理，保留 1 位小数\n",
    "    # 最大的预测向量不变，其余均设置为 0\n",
    "    max_idx = np.argmax(result, axis=1)\n",
    "    result = np.round(result, 1)\n",
    "    # 将最大值以外的元素设置为 0\n",
    "    for i in range(result.shape[0]):\n",
    "        for j in range(result.shape[1]):\n",
    "            if j != max_idx[i]:\n",
    "                result[i, j] = 0.0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a32e20",
   "metadata": {},
   "source": [
    "# 数据安全防御"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae605d8",
   "metadata": {},
   "source": [
    "## 差分隐私（DP）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a56c27f",
   "metadata": {},
   "source": [
    "差分隐私是一类重要的模型隐私保护技术，其通过**对样本注入噪声噪声**，使得差别只有一条记录的相邻数据集在模型推理时产生近似一致的输出概率，也就是“抹除”单个样本在模型中的区分度，从而保护模型隐私。\n",
    "\n",
    "差分隐私对**单个样本隐私**的保护逻辑如下：假设数据集 $D$ 删除某样本 $y$ 后变为 $D'$ ，攻击者可能通过观察 $D$ 与 $D'$ 输入模型后输出结果的差异，推断样本 $y$ 的敏感信息（如收入、年龄等）。而差分隐私通过在**数据处理**的关键环节添加噪声（如数据收集、查询、发布阶段），使得攻击者无法通过模型输出的变化准确反推出特定样本的存在或属性--因为噪声的干扰会导致信息提取出现不可控偏差，从而将单个样本的隐私信息**模糊化**。\n",
    "\n",
    "![差分隐私示意图](./imgs/dp1.jpg)\n",
    "\n",
    "比如，对于 data-1 和 data-2 两次查询，未加差分隐私保护，则模型会输出 2 和 3 ，明显存在区别，则可以从这个区别分析特定样本属性，而加了差分隐私技术，模型可能会输出 2.5 左右的数据，使得 $D$ 和 $D'$ 相差的那个特定样本模糊化。\n",
    "\n",
    "从数学角度出发，差分隐私确保了相邻数据集 $D$ 与 $D'$ 对任意输出结果 $O$ 的概率分布满足 $P[F(D) \\in O] \\le e^{\\epsilon} \\cdot P[F(D') \\in O]$ （F是模型推理过程），也就是：$D$ 和 $D'$ 产生同一输出 $O$ 的**概率比值**被严格限制在 $[e^{-\\epsilon}, e^{\\epsilon}]$ 范围内， 通过严格的概率约束“抹除”单个样本对模型输出的决定性影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 固定随机种子\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 设置随机种子以确保结果可复现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 设置中文字体，确保图表中的中文能正常显示\n",
    "plt.rcParams[\"font.family\"] = [\"SimHei\", \"Noto Sans CJK JP\", \"AR PL UMing JP\"]\n",
    "# plt.rcParams[\"font.family\"] = [\"Noto Sans CJK JP\"]\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "\n",
    "# 确保在Jupyter Notebook中可以正常显示图表\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Differential_Privacy():\n",
    "    # 可视化ε对隐私保护的影响\n",
    "    epsilons = [0.1, 1, 5]\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for eps in epsilons:\n",
    "        plt.plot(x, np.exp(eps) * x, label=f'ε = {eps}')\n",
    "    \n",
    "    plt.plot(x, x, 'k--', label='无隐私保护')\n",
    "    plt.xlabel('原始概率 P[M(D\\'∈S)]')\n",
    "    plt.ylabel('扰动后概率上限 e^ε * P[M(D\\'∈S)]')\n",
    "    plt.title('不同ε值对差分隐私约束的影响')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e30994",
   "metadata": {},
   "outputs": [],
   "source": [
    "Differential_Privacy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a7b4d",
   "metadata": {},
   "source": [
    "图为不同 $\\epsilon$ 值对原始概率 $P$ 的影响，$\\epsilon$ 值越小，概率约束越严格，例如图中 $\\epsilon=0.1$ 时，扰动后的概率最多是原始概率的 $e^{0.1} \\approx 1.105$ 倍。\n",
    "\n",
    "举个简单的例子：成员推理攻击（MIA）判断某个成员是否在数据集中，对于某个成员 A，在不添加扰动时很容易通过相邻数据集来进行判断。加入 $\\epsilon=0.1$ 扰动，即使 A 在数据中，结果概率最多比没有 A 时高 $10.5\\%$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bb756",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 差分隐私实现\n",
    "实现差分隐私，最重要的即是添加噪声，拉普拉斯机制（Laplace Mechanism）和高斯机制（Gaussian Mechanism）是两种在差分隐私中常见的**添加噪声**的方法。\n",
    "\n",
    "下面我们对这两种方法进行逐一学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cefabc",
   "metadata": {},
   "source": [
    "### 拉普拉斯机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e795e87",
   "metadata": {},
   "source": [
    "拉普拉斯机制通过向数据查询结果中**添加符合拉普拉斯分布($f(x|\\mu, b) = \\frac 1 {2b} e^{-\\frac{|x - \\mu|}{b}}$)的噪声**，来实现差分隐私保护。\n",
    "\n",
    "拉普拉斯机制添加噪声小，且严格满足差分隐私定义，因此在简单的差分隐私保护场景中，通常使用拉普拉斯机制来实现差分隐私。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217fa513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_mechanism(true_value, sensitivity, epsilon):\n",
    "    \"\"\"\n",
    "    实现Laplace机制\n",
    "    \n",
    "    参数:\n",
    "    true_value (float): 真实查询值\n",
    "    sensitivity (float): 查询的敏感度\n",
    "    epsilon (float): 隐私预算\n",
    "    \n",
    "    返回:\n",
    "    float: 添加噪声后的查询结果\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO：实现拉普拉斯机制\n",
    "\n",
    "    # 计算Laplace分布的参数b = 敏感度/ε\n",
    "    \n",
    "    # 从Laplace分布中采样噪声\n",
    "    \n",
    "    # 添加噪声到真实值\n",
    "    \n",
    "    return noisy_value\n",
    "\n",
    "\n",
    "def visualize_laplace_mechanism():\n",
    "    # 真实值\n",
    "    true_value = 100\n",
    "    # 敏感度\n",
    "    sensitivity = 1\n",
    "    # 不同的隐私预算\n",
    "    epsilons = [0.1, 1, 10]\n",
    "    # 生成噪声样本\n",
    "    num_samples = 1000\n",
    "    samples = {}\n",
    "    \n",
    "    for eps in epsilons:\n",
    "        samples[eps] = [laplace_mechanism(true_value, sensitivity, eps) for _ in range(num_samples)]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for i, eps in enumerate(epsilons):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        sns.histplot(samples[eps], kde=True)\n",
    "        plt.axvline(x=true_value, color='r', linestyle='--', label='真实值')\n",
    "        plt.title(f'ε = {eps}')\n",
    "        plt.xlabel('查询结果')\n",
    "        plt.ylabel('频率')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d012629",
   "metadata": {},
   "source": [
    "我们来查看一下拉普拉斯机制的效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_laplace_mechanism()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d084cef",
   "metadata": {},
   "source": [
    "实验结果符合差分隐私的定义：随着隐私预算 $\\epsilon$ 的增大，噪声减小，查询结果会更接近真实值，但这样也会导致隐私保护程度降低；反之，隐私预算减小会增大隐私保护程度，但也会对模型的性能产生较大的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d7797b",
   "metadata": {},
   "source": [
    "### 高斯机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8555ad3a",
   "metadata": {},
   "source": [
    "与拉普拉斯机制类似，高斯机制通过向查询结果中添加高斯噪声来实现差分隐私。\n",
    "\n",
    "对于函数 $f(D)$ （D为数据集），高斯机制 $M(D)$ 定义为：$M(D) = f(D) + \\mathcal N(0, \\delta ^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524dd8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mechanism(true_value, sensitivity, epsilon, delta):\n",
    "    \"\"\"\n",
    "    实现高斯机制\n",
    "    \n",
    "    参数:\n",
    "    true_value (float): 真实查询值\n",
    "    sensitivity (float): 查询的敏感度\n",
    "    epsilon (float): 隐私预算\n",
    "    delta (float): 失败概率\n",
    "    \n",
    "    返回:\n",
    "    float: 添加噪声后的查询结果\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO：实现高斯机制\n",
    "\n",
    "    # 计算高斯分布的标准差\n",
    "    \n",
    "    # 从高斯分布中采样噪声\n",
    "    \n",
    "    # 添加噪声到真实值\n",
    "    \n",
    "    return noisy_value\n",
    "\n",
    "def visualize_gaussian_mechanism():\n",
    "    # 真实值\n",
    "    true_value = 100\n",
    "    # 敏感度\n",
    "    sensitivity = 1\n",
    "    # 隐私参数\n",
    "    epsilon = 1\n",
    "    deltas = [1e-3, 1e-5, 1e-7]\n",
    "    # 生成噪声样本\n",
    "    num_samples = 1000\n",
    "    samples = {}\n",
    "    \n",
    "    for delta in deltas:\n",
    "        samples[delta] = [gaussian_mechanism(true_value, sensitivity, epsilon, delta) for _ in range(num_samples)]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for i, delta in enumerate(deltas):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        sns.histplot(samples[delta], kde=True)\n",
    "        plt.axvline(x=true_value, color='r', linestyle='--', label='真实值')\n",
    "        plt.title(f'δ = {delta}')\n",
    "        plt.xlabel('查询结果')\n",
    "        plt.ylabel('频率')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6dd129",
   "metadata": {},
   "source": [
    "我们来查看一下高斯机制的效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52069d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_gaussian_mechanism()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6358e307",
   "metadata": {},
   "source": [
    "高斯机制通过 $\\delta$ 参数实现了松弛差分隐私 $(\\epsilon, \\delta)-DP$ ， $\\delta$ 给差分隐私提供了一个小概率隐私泄露的可能性，这样的好处是提高了数据的可用性。\n",
    "\n",
    "高斯机制对高维数据或需要精确梯度的场景更加友好，因此更适合深度学习等场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6873dd74",
   "metadata": {},
   "source": [
    "## 差分隐私应用--人口数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80808c58",
   "metadata": {},
   "source": [
    "这一小节中，我们针对现实场景：**人口数据分析场景**，来展示差分隐私的实际应用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_data_example():\n",
    "    \"\"\"人口数据分析中的应用 + 差分隐私保护\"\"\"\n",
    "    \n",
    "    # 生成模拟人口数据\n",
    "    n = 1000  # 样本量\n",
    "    ages = np.random.normal(35, 10, n).astype(int)\n",
    "    incomes = np.random.lognormal(10, 0.5, n).astype(int)\n",
    "    education_levels = np.random.choice(['高中', '本科', '硕士', '博士'], size=n, \n",
    "                                     p=[0.4, 0.4, 0.15, 0.05])\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        '年龄': ages,\n",
    "        '收入': incomes,\n",
    "        '教育程度': education_levels\n",
    "    })\n",
    "    \n",
    "    # 计算真实统计量\n",
    "    true_mean_age = data['年龄'].mean()\n",
    "    true_income_sum = data['收入'].sum()\n",
    "    true_education_counts = data['教育程度'].value_counts()\n",
    "    \n",
    "    # 敏感度计算\n",
    "    age_sensitivity = 1  # 均值查询的敏感度为1（添加或删除一个人的影响）\n",
    "    income_sensitivity = data['收入'].max()  # 求和查询的敏感度为最大值\n",
    "    education_sensitivity = 1  # 计数查询的敏感度为1\n",
    "    \n",
    "    # 设置隐私预算\n",
    "    epsilon_total = 1.0\n",
    "    \n",
    "    # 分配隐私预算（简单平均分配）\n",
    "    epsilon_age = epsilon_total / 3\n",
    "    epsilon_income = epsilon_total / 3\n",
    "    epsilon_education = epsilon_total / 3\n",
    "    \n",
    "    # 应用Laplace机制添加噪声\n",
    "    noisy_mean_age = laplace_mechanism(true_mean_age, age_sensitivity, epsilon_age)\n",
    "    noisy_income_sum = laplace_mechanism(true_income_sum, income_sensitivity, epsilon_income)\n",
    "    \n",
    "    # 对分类计数应用差分隐私\n",
    "    noisy_education_counts = {}\n",
    "    for level, count in true_education_counts.items():\n",
    "        noisy_count = laplace_mechanism(count, education_sensitivity, epsilon_education)\n",
    "        noisy_education_counts[level] = max(0, noisy_count)  # 确保计数非负\n",
    "    \n",
    "    # 结果可视化\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 年龄均值\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.bar(['真实值', '差分隐私值'], [true_mean_age, noisy_mean_age])\n",
    "    plt.title('平均年龄')\n",
    "    plt.ylabel('年龄')\n",
    "    \n",
    "    # 收入总和\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.bar(['真实值', '差分隐私值'], [true_income_sum, noisy_income_sum])\n",
    "    plt.title('总收入')\n",
    "    plt.ylabel('收入')\n",
    "    \n",
    "    # 教育程度分布\n",
    "    plt.subplot(1, 3, 3)\n",
    "    levels = list(true_education_counts.index)\n",
    "    true_counts = [true_education_counts[level] for level in levels]\n",
    "    noisy_counts = [noisy_education_counts[level] for level in levels]\n",
    "    \n",
    "    x = np.arange(len(levels))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, true_counts, width, label='真实值')\n",
    "    plt.bar(x + width/2, noisy_counts, width, label='差分隐私值')\n",
    "    plt.xticks(x, levels)\n",
    "    plt.title('教育程度分布')\n",
    "    plt.ylabel('人数')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 打印结果\n",
    "    print(f\"真实平均年龄: {true_mean_age:.2f}, 差分隐私平均年龄: {noisy_mean_age:.2f}\")\n",
    "    print(f\"真实总收入: {true_income_sum:,}, 差分隐私总收入: {int(noisy_income_sum):,}\")\n",
    "    print(\"\\n教育程度分布:\")\n",
    "    for level in levels:\n",
    "        print(f\"  {level}: 真实值={true_education_counts[level]}, 差分隐私值={int(noisy_education_counts[level])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_data_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f92c93",
   "metadata": {},
   "source": [
    "使用差分隐私后，数据整体特征在保持不变的前提下，对数据进行了一定程度的扰动，在数据保持分析价值的情况下，对于单个样本来说，不是那么容易从相邻数据集中推断出来了，实现了对单个样本的隐私保护。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c026b",
   "metadata": {},
   "source": [
    "## 深度学习中的差分隐私"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c62199",
   "metadata": {},
   "source": [
    "我们可以将差分隐私理论应用到深度学习中，保护深度学习模型训练和应用过程中的用户隐私，并尽可能维护模型性能。\n",
    "\n",
    "在深度学习中，差分隐私的实现方式不是对数据样本直接添加噪声，也不是对模型输出添加噪声，而是在**模型训练过程**中，对模型的**梯度空间**进行**添加噪声**，**限制单个样本对梯度产生的影响**，防止攻击者通过梯度的变化推断出单个样本的属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在深度学习中，差分隐私训练逻辑为： 原始数据 $\\xrightarrow{前向传播}$ 模型输出 $\\xrightarrow{损失函数}$ 损失值 $\\xrightarrow{反向传播}$ 原始梯度 $\\xrightarrow[添加噪声]{梯度裁剪}$ 隐私合规梯度 $\\xrightarrow{优化器}$ 模型参数更新"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af6820",
   "metadata": {},
   "source": [
    "我们使用MNIST数据集来实现深度学习中的差分隐私："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cafa483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(batch_size=64, val_ratio=0.2):\n",
    "    \"\"\"加载MNIST数据集并分割训练/验证集\"\"\"\n",
    "    # 数据预处理（标准化）\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))  # MNIST均值/标准差\n",
    "    ])\n",
    "    \n",
    "    # 加载训练集\n",
    "    train_dataset = datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=transform\n",
    "    )\n",
    "    val_size = int(len(train_dataset) * val_ratio)\n",
    "    train_size = len(train_dataset) - val_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        train_dataset, [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    # 测试集\n",
    "    test_dataset = datasets.MNIST(\n",
    "        root='./data', train=False, download=True, transform=transform\n",
    "    )\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def plot_mnist_examples(dataset, num_examples=6):\n",
    "    fig, axes = plt.subplots(1, num_examples, figsize=(15, 2))\n",
    "    for i in range(num_examples):\n",
    "        img, label = dataset[i]\n",
    "        axes[i].imshow(img.squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Label: {label}')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683605d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载MNIST数据\n",
    "train_loader, val_loader, test_loader = load_mnist_data(batch_size=128)\n",
    "\n",
    "# 查看示例图像\n",
    "plot_mnist_examples(datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd07a9",
   "metadata": {},
   "source": [
    "由于在差分隐私深度学习中，模型梯度的敏感性 $Sensitivity = max_{D, D'} ||\\nabla L(D) - \\nabla L(D')||$ 定义了相邻数据集的梯度的最大可能差异。\n",
    "\n",
    "我们需要限制这个差异，否则梯度可能会因为个别样本而剧烈波动，导致需要添加**大量噪声**才能满足差分隐私，但是这样又会因为**过多噪声**导致模型性能严重下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb547082",
   "metadata": {},
   "source": [
    "一个有效的方法是在梯度空间进行加噪前，先设置梯度范数的上限（如 $L_2$ 范数不超过 1.0 ，把所有样本的梯度敏感性限制在固定范围内：\n",
    "\n",
    "$$\n",
    "clipped\\_{grad} = grad \\cdot min(1, \\frac{clip\\_norm}{||grad||})\n",
    "$$\n",
    "\n",
    "这样，无论某单个样本梯度有多大，其对整体梯度的贡献都会被限制在一个合理区间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度 L2 范数裁剪\n",
    "def clip_gradient(grads, max_norm=1.0):\n",
    "    \"\"\"对梯度进行L2范数裁剪\"\"\"\n",
    "\n",
    "    # TODO：补全梯度裁剪函数\n",
    "\n",
    "    clipped = []\n",
    "    for g in grads:\n",
    "        if g is not None:\n",
    "            # 计算梯度的L2范数\n",
    "            # 如果范数大于 max_norm，则进行裁剪\n",
    "            # 裁剪公式: clipped_g = g * (max_norm / norm)\n",
    "        else:\n",
    "            # 否则不进行裁剪\n",
    "    return clipped\n",
    "\n",
    "\n",
    "# 深度学习下的加噪函数\n",
    "\n",
    "# 高斯噪声\n",
    "def add_gaussian_noise(tensor, epsilon=1.0, delta=1e-5, sensitivity=1.0, **kargs):\n",
    "    if delta <= 0:\n",
    "        raise ValueError(\"Delta must be greater than 0\")\n",
    "    sigma = (math.sqrt(2 * math.log(1.25 / delta)) * sensitivity) / epsilon\n",
    "    grad_std = max(torch.std(tensor).item(), 1e-6)\n",
    "    sigma_adj = sigma * min(grad_std, 0.1)\n",
    "    return tensor + torch.normal(0, sigma_adj, size=tensor.shape, device=tensor.device)\n",
    "\n",
    "# 拉普拉斯噪声\n",
    "def add_laplace_noise(tensor, epsilon=1.0, sensitivity=1.0, **kargs):\n",
    "    scale = sensitivity / epsilon\n",
    "    grad_std = max(torch.std(tensor).item(), 1e-6)\n",
    "    scale_adj = scale * min(grad_std, 0.1)\n",
    "    noise = np.random.laplace(0, scale_adj, size=tensor.shape)\n",
    "    return tensor + torch.tensor(noise, device=tensor.device, dtype=tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ccda0b",
   "metadata": {},
   "source": [
    "然后我们定义一个CNN模型用于差分隐私训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f6d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(32 * 7 * 7, 128), nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(128, 10)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4069509",
   "metadata": {},
   "source": [
    "深度学习中，差分隐私主要是对梯度空间进行加噪，使得观察到的梯度和任何单个样本的真实梯度 $\\nabla _\\theta L$ 不可区分。\n",
    "\n",
    "在模型训练函数中，我们根据差分隐私的定义，在模型**原始梯度**上进行裁剪和加噪，使得其符合隐私合规的梯度，再使用优化器来更新模型参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c4f41",
   "metadata": {},
   "source": [
    "在训练阶段，我们平均为每一个epoch的训练分配合适的隐私预算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc46386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_epoch(model, data_loader, loss_fn, optimizer, dp_config, max_grad=1.0):\n",
    "    \"\"\"执行一个epoch的差分隐私训练\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for X_batch, y_batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        # TODO: 完成差分隐私训练部分\n",
    "\n",
    "        # 1. 对反向传播求出的梯度进行裁剪\n",
    "\n",
    "        # 2. 对梯度空间添加噪声（可自行选择 laplace 或 gaussian 噪声）\n",
    "\n",
    "        # 3. 使用优化器对模型参数进行更新\n",
    "        \n",
    "        # 统计指标\n",
    "        total_loss += loss.item()\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (pred == y_batch).sum().item()\n",
    "    \n",
    "    return total_loss / len(data_loader), (correct / total) * 100\n",
    "\n",
    "# 完整训练\n",
    "def train_dp_model(train_loader, val_loader, dp_config, lr=0.01, max_grad=1.0, epochs=10):\n",
    "    \"\"\"差分隐私训练函数\"\"\"\n",
    "    model = build_cnn_model()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'privacy': []}\n",
    "    \n",
    "    print(f\"开始训练 | ε={dp_config['epsilon']}, 机制={dp_config['mechanism']}\")\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # 训练阶段\n",
    "        train_loss, train_acc = run_training_epoch(\n",
    "            model, train_loader, loss_fn, optimizer, dp_config, max_grad\n",
    "        )\n",
    "        \n",
    "        # 验证阶段\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, loss_fn)\n",
    "        \n",
    "        # 记录隐私预算\n",
    "        privacy_spent = epoch * (dp_config['epsilon'] / epochs)  # 平均分配预算\n",
    "        \n",
    "        # 打印进度\n",
    "        print(f\"Epoch {epoch:2d}/{epochs:2d} | \"\n",
    "              f\"Train: Loss {train_loss:.4f} Acc {train_acc:.2f}% | \"\n",
    "              f\"Val:   Loss {val_loss:.4f} Acc {val_acc:.2f}% | \"\n",
    "              f\"隐私消耗: {privacy_spent:.4f}\")\n",
    "        \n",
    "        # 保存历史记录\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['privacy'].append(privacy_spent)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# 评估函数\n",
    "def evaluate_model(model, data_loader, loss_fn):\n",
    "    \"\"\"评估模型在验证集上的性能\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = loss_fn(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (pred == y_batch).sum().item()\n",
    "    \n",
    "    return total_loss / len(data_loader), (correct / total) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18039f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练曲线\n",
    "def plot_training_history(history: dict):\n",
    "    \"\"\"绘制训练/验证损失和准确率曲线\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # 损失曲线\n",
    "    axes[0].plot(history['train_loss'], label='训练损失', c='blue')\n",
    "    axes[0].plot(history['val_loss'], label='验证损失', c='orange', linestyle='--')\n",
    "    axes[0].set_xlabel('Epoch'), axes[0].set_ylabel('Loss'), axes[0].grid(True), axes[0].legend()\n",
    "    \n",
    "    # 准确率曲线\n",
    "    axes[1].plot(history['train_acc'], label='训练准确率', c='blue')\n",
    "    axes[1].plot(history['val_acc'], label='验证准确率', c='orange', linestyle='--')\n",
    "    axes[1].set_xlabel('Epoch'), axes[1].set_ylabel('Accuracy (%)'), axes[1].grid(True), axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout(), plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71f63ee",
   "metadata": {},
   "source": [
    "以MNIST数据集为例，可视化训练一个中等隐私的CNN模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2099b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置差分隐私参数\n",
    "dp_params = {\n",
    "    'epsilon': 1.0,       # 隐私预算\n",
    "    'delta': 1e-5,        # 高斯机制必需\n",
    "    'sensitivity': 1.0,   # 梯度敏感度\n",
    "    'mechanism': 'gaussian'  # 噪声类型\n",
    "}\n",
    "\n",
    "# 训练模型\n",
    "model, history = train_dp_model(train_loader, val_loader, dp_params, epochs=8)\n",
    "\n",
    "# 可视化训练过程\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270e1b1",
   "metadata": {},
   "source": [
    "可以发现，使用差分隐私进行训练后，损失反而会随着每个Epoch的训练而增大，这是差分隐私训练导致的正常现象。\n",
    "\n",
    "梯度裁剪、噪声都会对模型性能产生一定影响。所以在实际进行差分隐私训练时，需要做好性能和隐私保护的平衡。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a69eb3",
   "metadata": {},
   "source": [
    "接下来，我们对不同隐私配置进行差分隐私训练，观察模型的表现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d06bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对比不同隐私级别的实验\n",
    "def compare_privacy_effect():\n",
    "    \"\"\"测试不同epsilon值对MNIST分类性能的影响\"\"\"\n",
    "    \n",
    "    # 加载数据\n",
    "    train_loader, val_loader, test_loader = load_mnist_data(batch_size=128)\n",
    "    \n",
    "    # 隐私配置\n",
    "    privacy_settings = [\n",
    "        {'name': '无隐私', 'epsilon': float('inf'), 'delta': 0, 'mechanism': 'gaussian'},\n",
    "        {'name': '弱隐私', 'epsilon': 10.0, 'delta': 1e-5, 'mechanism': 'gaussian'},\n",
    "        {'name': '中隐私', 'epsilon': 1.0, 'delta': 1e-5, 'mechanism': 'gaussian'},\n",
    "        {'name': '强隐私', 'epsilon': 0.1, 'delta': 1e-5, 'mechanism': 'gaussian'},\n",
    "    ]\n",
    "    \n",
    "    # 运行实验\n",
    "    results = []\n",
    "    for cfg in privacy_settings:\n",
    "        print(f\"\\n=== 训练 {cfg['name']} (ε={cfg['epsilon']}) ===\")\n",
    "        if cfg['epsilon'] == float('inf'):\n",
    "            # 无隐私情况：直接训练\n",
    "            model = build_cnn_model()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "            for _ in range(10):\n",
    "                run_training_epoch(model, train_loader, nn.CrossEntropyLoss(), optimizer,\n",
    "                                  {'epsilon':1.0, 'delta':1e-5, 'sensitivity':1.0, 'mechanism':'gaussian'},\n",
    "                                  max_grad=1.0)  # 不添加噪声\n",
    "            _, test_acc = evaluate_model(model, test_loader, nn.CrossEntropyLoss())\n",
    "            results.append({'name': cfg['name'], 'acc': test_acc, 'epsilon': cfg['epsilon']})\n",
    "        else:\n",
    "            # 差分隐私训练\n",
    "            dp_cfg = {\n",
    "                'epsilon': cfg['epsilon'],\n",
    "                'delta': cfg['delta'],\n",
    "                'sensitivity': 1.0,\n",
    "                'mechanism': cfg['mechanism']\n",
    "            }\n",
    "            model, _ = train_dp_model(train_loader, val_loader, dp_cfg, lr=0.001, epochs=8)\n",
    "            _, test_acc = evaluate_model(model, test_loader, nn.CrossEntropyLoss())\n",
    "            results.append({'name': cfg['name'], 'acc': test_acc, 'epsilon': cfg['epsilon']})\n",
    "    \n",
    "    # 打印结果\n",
    "    print(\"\\n MNIST隐私保护对比：\")\n",
    "    for res in results:\n",
    "        eps = \"∞\" if res['epsilon'] == float('inf') else f\"{res['epsilon']:.1f}\"\n",
    "        print(f\"{res['name']}: 测试准确率 {res['acc']:.2f}% (ε={eps})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50976ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对比不同隐私级别\n",
    "compare_privacy_effect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
